<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="http://zecong.hu/feed.xml" rel="self" type="application/atom+xml" /><link href="http://zecong.hu/" rel="alternate" type="text/html" /><updated>2019-11-21T01:49:11+00:00</updated><id>http://zecong.hu/feed.xml</id><title type="html">Zecong Hu’s blog</title><subtitle>The personal blog of Zecong Hu. Contains diaries, tech articles, and gibberish.
</subtitle><author><name>Zecong Hu</name></author><entry><title type="html">大四下总结</title><link href="http://zecong.hu/2019/08/26/my-8th-semester-in-college/" rel="alternate" type="text/html" title="大四下总结" /><published>2019-08-26T15:36:00+00:00</published><updated>2019-08-26T15:36:00+00:00</updated><id>http://zecong.hu/2019/08/26/my-8th-semester-in-college</id><content type="html" xml:base="http://zecong.hu/2019/08/26/my-8th-semester-in-college/">&lt;style&gt;
  .hide { display: none; }
&lt;/style&gt;

&lt;p&gt;系列八篇中的最后一篇。本应在暑假就写完的，结果断断续续拖了整整一年，到现在五字班都毕业了。&lt;/p&gt;

&lt;p&gt;请允许我先用几个词概括我的大四下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;忙碌。&lt;/strong&gt;在我的想象中，毕设不过就是几个大作业的分量，大四下应该比较轻松才对。实际的体验却并非如此。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;淡出。&lt;/strong&gt;四年来习以为常在身边的同学们，并不是像文学作品中那样，在毕业典礼之后有说有笑相互道别的。在北京工作的同学们在学期中就逐渐搬出了宿舍，其他同学则在毕业后清理了寝室，陆续离开了。这种退场方式，相比起前者更加令人感到难过。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;不舍。&lt;/strong&gt;毫不夸张地，这四年是我至今的人生中最丰富多彩、也最专注耐心的四年。有欢笑，有伤心，有许多长进，也有诸多遗憾。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;tl;dr: 以上就是本篇文章的主旨。赶时间的话，读到这里就可以了。下文中有大量图片，请注意流量。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;毕设&quot;&gt;毕设&lt;/h2&gt;

&lt;p&gt;我们系的毕设其实挺烦的。既不能用实习替代，也不能在其它院系或者学校完成。加之，之前没有进过实验室、没有提前套磁的同学会被随机分配导师，可以说是惊险刺激。图1展示了一位不幸中招的同学。我因为提前和导师商量好了，所以没有如此惊险刺激的体验，可喜可贺。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/徐老板xilinx.jpg&quot; alt=&quot;徐老板xilinx&quot; width=&quot;300px&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图1： 被随机分配到网络所的徐老板。大家想起了大三上被造计算机支配的恐惧，纷纷献上 Xilinx ISE 的祝福。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我对毕设整体持有较为负面的态度。明明培养方案中完全没有涉及科研的部分，却要让大家在最后一学期完成一项学术研究并撰写篇幅极为冗长的论文。然而，这一要求看似严格，但实际上标准却极其宽松，哪怕到最后写出来的只是文献综述也能通过。毫不夸张地说，只有少数人能完成一份真正有价值的学术论文，大多数人（包括我在内）生产出来的都是学术垃圾，在过程中学习到的无非就是如何将垃圾包装为论文而已。&lt;/p&gt;

&lt;p class=&quot;hide&quot;&gt;另一方面则是老师们对毕设的态度，那就是：不在乎。诚然有不少老师是认真对待学生们的毕设的，但从我带偏差的采样的结果来看，有近乎一半的老师是不管事的。学生做了什么，写了啥，与我何干？就如同系里一部分老师对待教学的态度一样，于我无益的事情，我为什么要上心呢？开题时得不到指导，过程中得不到监督，结束时得不到评价。这样的毕设，意义何在？&lt;/p&gt;

&lt;p&gt;说得有点过分，但这是我真实的想法。我对自己的毕设也完全不满意，但另一方面也庆幸没有投入更多精力做自己根本不想做的事。因此，下面的流水账记录了我在毕设中划水吃瘪的过程。&lt;/p&gt;

&lt;h3 id=&quot;开题&quot;&gt;开题&lt;/h3&gt;

&lt;p&gt;开题的时间其实是大四上的期末。从美国回来后，我和导师谈了谈选题的事。实验室最年长的 PhD 即将毕业，而他毕业后准备创业做法律 NLP，因此导师也希望我毕设能做这方面的东西。具体来说有三个选题，分别是类案匹配、法律领域的网络表示学习，以及法律事件抽取。&lt;/p&gt;

&lt;p&gt;说实话，我之前只做过语言模型和词/句表示，对这三个方向我都一无所知，而且总的来说都不是很感兴趣。相比之下我觉得第一个课题要&lt;ruby&gt;&lt;rb&gt;好&lt;/rb&gt;&lt;rt&gt;水&lt;/rt&gt;&lt;/ruby&gt;一点，于是选择了第一个。最后确定下的题目是《面向法律文书与新闻语料的跨领域语义匹配》。&lt;/p&gt;

&lt;p class=&quot;hide&quot;&gt;但实际上，这个题目的正确解读应该是《面向答辩的无监督实验设计与论文写作》。这是后话了。&lt;/p&gt;

&lt;h3 id=&quot;寒假&quot;&gt;寒假&lt;/h3&gt;

&lt;p&gt;寒假我们全家到了海南避寒。值得一提的是，我们所在的五指山市，是一个完全看不到海，连电影院也没有，房价比长沙还低的国家级贫困县。不过这里四季温暖如春，没有空气污染，十分适合养老。我每天的娱乐活动就是上网和在小区里散步。&lt;/p&gt;

&lt;p&gt;虽然开题时列的进度安排里写的是“寒假期间完成文献调研”诸如此类，但是寒假中一点活也没干。需要说明的是，这并不代表毕设真的很水。恰恰相反，这个题目其实一点也不简单，至少对于我这个完全没做过信息抽取的人来说是这样。&lt;/p&gt;

&lt;p&gt;首先，我手头的数据只有实验室之前从网上爬下来的大量法律文书而已。那么第一，我得自己获得一些新闻语料，这意味着写爬虫。第二，除非有什么有用的无监督方法，我还得找人标数据，这意味着写数据标注网站。&lt;/p&gt;

&lt;p&gt;其次，不知道大家有没有读过法律文书。这是一种文本量巨大，虽然有明确格式要求但仍然乱得一塌糊涂，到处都是错别字，连“中华人民共和国”都能写错&lt;sup id=&quot;fnref:case-docs&quot;&gt;&lt;a href=&quot;#fn:case-docs&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;的文本数据。而且，实验室的数据量实在是太大了，存成 JSON 格式总共有 230G。230G 的文本。&lt;/p&gt;

&lt;p&gt;最后，我错误估计了题目的难度。这导致我在上半学期极其散漫，每周组会进度堪忧，中期答辩后每天活在毕不了业的恐惧之中。不过这是也后话了。&lt;/p&gt;

&lt;h3 id=&quot;中期答辩&quot;&gt;中期答辩&lt;/h3&gt;

&lt;p&gt;正如上文所述，前半个学期完全是荒废过去的。虽然每天也有在干活，但是在咖啡厅悠闲地干活和一般意义上的干活是完全不同的两种状态。总之，到中期答辩为止，我只是把新闻数据爬了下来，然后对文书稍微做了一下预处理而已。&lt;/p&gt;

&lt;p&gt;在这种几乎什么都没做的状态下，迎来了中期答辩。我还记得中期答辩的头一天晚上，在校门口的咖啡厅刷夜准备。回忆起来，真的是十分痛苦。怎么形容呢？明知已无济于事，却还得垂死挣扎；明知自己做的事情百无一用，却只能硬着头皮做下去。痛苦的并不是加班干活，而是加班干没有意义的活。&lt;/p&gt;

&lt;p&gt;另一方面的压力来源于系里的规定。虽然心里清楚，毕设做得再怎么差劲也不至于毕不了业&lt;sup id=&quot;fnref:cannot-graduate&quot;&gt;&lt;a href=&quot;#fn:cannot-graduate&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;，但传言说中期答辩太差会被发黄牌，然后保送全系答辩&lt;sup id=&quot;fnref:yellow-card&quot;&gt;&lt;a href=&quot;#fn:yellow-card&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;。全系答辩的设定是这样的：在最终答辩之后，每个组会选表现倒数的若干名同学送到全系进行&lt;del&gt;公开处刑&lt;/del&gt; &lt;del&gt;死刑复核&lt;/del&gt;第二轮答辩。再怎么说，我也不希望这件事发生在自己身上。&lt;/p&gt;

&lt;p&gt;那天应该是三点多才回到寝室。第二天早上七点就起床准备答辩。万幸的是，那天我的导师不在。前面的同学一个个上场，每个人做得都比我多。到我讲的时候，虽然我努力将自己的工作吹嘘了一番，但和其它人相比也底气不足。奇迹般地，不知道是不是我吹得比较成功&lt;sup id=&quot;fnref:successful-boast&quot;&gt;&lt;a href=&quot;#fn:successful-boast&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;，老师们觉得项目难度挺高，就没有深究我的工作量到底有多少。&lt;/p&gt;

&lt;p&gt;不过越是装逼，就越会发现装逼的能力是有极限的。下一次组会的时候，导师来了。不凑巧的是，这天是倩倩的生日，因为相关的安排我必须提前从组会离开。火上浇油的是，之前从实验室同学处了解，导师在看到上一周的周报&lt;sup id=&quot;fnref:weekly-report&quot;&gt;&lt;a href=&quot;#fn:weekly-report&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;后对和我一样在大四下还选了两门专业课的人非常恼火。或许这就是对我划水的惩罚吧。&lt;/p&gt;

&lt;p&gt;对此，我选择的态度是：认怂。提前承认错误，并在被训话时虚心接受。果不其然，导师对我的进度十分不满，但训斥归训斥，还是允许我提前离开了。代价就是，我承诺之后每天在实验室认真干活。不过至少，生日是过成了。&lt;/p&gt;

&lt;h3 id=&quot;下半学期&quot;&gt;下半学期&lt;/h3&gt;

&lt;p&gt;自那以后，我每周工作日几乎都在 FIT 楼度过了。早上搭乘四年间头一次乘上的校园巴士（自行车在四月的一次大风中遗失）来到 FIT 楼，中午在五道口吃饭，到晚饭时间再回到寝室。其实也是正常的一天工作，但对我来说尤为煎熬，因为：我真的很讨厌这个题目；而且，FIT 楼处于一种废土状态，非常不适合生存，如图2所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/fit废墟.jpg&quot; alt=&quot;fit废墟&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图2：FIT楼装修实况。炎炎夏日也&lt;a href=&quot;https://github.com/meta-inf/are-FIT-ACs-on&quot;&gt;没有空调&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我之前做文献调研的时候，完全没有找到相关的工作。绝大多数法律相关的工作都是判决预测或者法律问答，即便是英美法系的类案推荐也没找到什么论文；一般的语义相似度的模型则根本不会考虑如此长的文本。在胡思乱想后，我确定的思路是分两步 coarse-to-fine 地做，第一步从所有文书里找到排名前10的，第二步做重排序。如果第二步想用炼丹解决，那么就得收集相应的数据。让标注人员从所有文书中找到最相似的必然不现实，因此只能以第一步的结果作为候选，让标注人员从中选择最优匹配。这意味着第一步得用无监督的方法。但是面对这种长度的文本，传统的提取关键词的方法效果非常平凡，尝试的一些新方法也不奏效。不仅如此，文书的数据量极大而且格式混乱，使得我在预处理上花了非常久的时间。&lt;/p&gt;

&lt;p&gt;当然，到头来还是我自己经验不足。比如，我到很后面才知道有这么个叫 ElasticSearch 的东西，可以解决我遇到的很多问题。总之，这段时间我基本上如图3所示。这一段时间是我大四下最压抑的一段时间。正如前面所说，做毫无意义的事情是痛苦的，而这件毫无意义的事情如果还难做，则是雪上加霜。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/放弃思考.jpg&quot; alt=&quot;放弃思考&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图3：当我在做毕设时，我在想什么。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这一步做完之后就好多了。之后我花了一个星期，基于 Django Admin 造了一个数据标注的网站。这一周对我来说简直是救赎，写工程代码比写什么破毕设舒服多了。之后则是标数据相关的杂事，比如拉群宣传、回答标注人员的问题、维护网站&lt;del&gt;并且不手抖删库&lt;/del&gt;、垫付标注费并一个一个转账给标注人员。对，标注费要我自己垫付。一共花了一万多，多亏实验室师兄赞助了我一半的钱。&lt;/p&gt;

&lt;h3 id=&quot;论文撰写&quot;&gt;论文撰写&lt;/h3&gt;

&lt;p&gt;写论文也是令人头疼的一部分。虽然没有明确的字数要求，但根据流传的几份上古论文和坊间传说，最好能达到40页。字数其实不是问题，毕竟用了炼丹的方法，背景介绍想怎么展开都行（“长短时记忆神经网络是由 Hochreiter 和 Schmidhuber 在 [233] 中提出的一种神经网络结构……”）。问题是写得烦，因为所有人都知道，写出来的这份玩意儿没有人会看，导师也好答辩委员会也好，都不会看。&lt;/p&gt;

&lt;p&gt;为了调节心情，大家分分干起了各种与目的无关的事情，比如寻找搞笑的凑字数方法（图4），编写 QQ 群查重 DDL 小助手（图5），或者（仅对我而言）研究各种 &lt;a href=&quot;https://tex.stackexchange.com/questions/436689/shifting-baseline-of-cjk-characters&quot;&gt;LaTeX 小技巧&lt;/a&gt;，以及。但正如图6中所述，这本质上都是在拖延。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/凑字数.jpg&quot; alt=&quot;凑字数&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图4：第 1.3.2 节  机械键盘与写作质量的关系&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/qq群bot.jpg&quot; alt=&quot;qq群bot&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图5：大家好，我是本群的提醒查重 DDL 小助手，希望此刻看到消息的人可以和我一起来写论文。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/黄老板朋友圈.jpg&quot; alt=&quot;当你拖延的时候&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图6：一句经过转述的真理。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了让身边的人顺利毕业，我在寝室中设立了如图7的死亡倒计时。现在看着可能觉得没什么，在当时的环境下可是十分触目惊心的。最终，所有人都可喜可贺地在查重 DDL 前凑出了像样的页数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/死亡倒计时.jpg&quot; alt=&quot;死亡倒计时&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图7：死亡倒计时。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;印象比较深刻的是查重 DDL 的前一天晚上，我2点从校门口的桥咖啡&lt;sup id=&quot;fnref:bridge-cafe&quot;&gt;&lt;a href=&quot;#fn:bridge-cafe&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;回寝室。回来发现大家都没睡，都在进行最后的挣扎（或是看大家进行最后的挣扎）。我正好写完，于是在大家的注视下用了个第三方平台查重了一下。出结果后，大家凑过来看了看，随即哄笑起来，寝室里充满了快活的空气。我被查出来重复比较严重的部分有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“俗话说，‘没有规矩，不成方圆’。法律作为约束人们行为的规范，是巩固政权，维护社会秩序的必要手段。”&lt;/li&gt;
  &lt;li&gt;“本院认为，被告人某某某违反国家有关野生动物保护法规，非法出售国家II级重点保护野生动物大壁虎，其行为已构成非法出售珍贵、濒危野生动物罪。判决如下：判处有期徒刑十年。”&lt;/li&gt;
  &lt;li&gt;“朴素贝叶斯分类器（naïve Bayes classifier）是最简单的分类模型之一。”&lt;/li&gt;
  &lt;li&gt;“实验结果显示，我们的模型在任务上取得了不错的效果。”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不得不承认，第一句话确实是我抄的，第二部分也确实是原文，但剩下的都不太讲道理。我们在屏幕前笑得前仰后合，随后开始相互奇文共赏，分享写论文过程中难得的快乐。&lt;/p&gt;

&lt;p&gt;查重结束并不代表毕设就做完了。我送去查重的版本缺了大概三分之一的实验结果，而这些实验的代码我甚至还没写。我们组是最早答辩的，因此在仅剩的几天里，我只能一边看着大家划水，一边生死时速亡命实验。同时，这也说明了我做的东西有多水：写代码加跑实验，一共只要三天。&lt;/p&gt;

&lt;h3 id=&quot;最终答辩&quot;&gt;最终答辩&lt;/h3&gt;

&lt;p&gt;最终答辩其实没什么可以说的。因为我的工作比较分散而肤浅，所以我可以每部分讲一点而又不用讲得很深入，反而具有非常好的装逼效果。总之，最后无功无过，于我而言是最好的结果了。&lt;/p&gt;

&lt;p class=&quot;hide&quot;&gt;值得一提的是，在答辩一个半小时前，我突然收到一条答辩组的通知，说因为答辩总时间不够，每个人的展示时间从10分钟缩短为8分钟。合着一开始安排答辩的时候没数人数？这真是我大学四年来做展示遇到的最令人窒息的操作。类似的操作还有，同学赶到答辩的教室，发现教室被拆了，一看群才知道临时改地点了。&lt;/p&gt;

&lt;p&gt;至此，毕设终于平安无事地画上了一个句号。&lt;/p&gt;

&lt;p class=&quot;hide&quot;&gt;至于这个工作到底有没有意义，实验室会不会有人接着做下去，就是另一回事了。&lt;/p&gt;

&lt;h2 id=&quot;生活&quot;&gt;生活&lt;/h2&gt;

&lt;h3 id=&quot;寝室&quot;&gt;寝室&lt;/h3&gt;

&lt;p&gt;正如一开始所说，身边的同学是渐渐淡出我的生活的。上学期期末的时候，天龙率先正式搬离寝室，和王老师合租住进了华清嘉园。那天我回到寝室，看到原本被天龙的组合柜占据的中厅一角变得空荡荡的，竟然觉得有些不舍。其实华清嘉园到寝室不过两公里，平时也能经常聚会，但是和在寝室的感觉是完全不一样的。原本约吃饭只是回个头的事，现在必须网上联系了。&lt;/p&gt;

&lt;p&gt;第二个搬离宿舍的是隔壁的韦师，这一下就少了一员吹逼的大将。以往韦师总是会深夜来我们寝室侃天侃地，谈一些只有我们俩会感兴趣的技术话题。不得不说，很多学习曲线陡峭的技术（如 vim 和 git 的高端操作），都是韦师在吹逼中带我入门的。也是在写下这一段的时候我才意识到，已经很久没有人和我讨论各种语言中的黑科技了。&lt;/p&gt;

&lt;p&gt;第三个搬离宿舍的是钦老板。钦老板是个非常有娱乐精神的人，在寝室的时候为大家传播和创造了许多梗。说实话，我与钦老板平日的交集算不上多，但有他在的寝室还是要热闹许多。&lt;/p&gt;

&lt;p&gt;当然，寝室的人员变动也并不只有搬出。苏老板因为自己寝室条件恶化，在学期中搬来了我们寝室，征用了天龙的位子。苏老板寝室这件事也让我体会到，能有志趣相投、三观相似的室友是多么难得的事情。也正是因此，我们寝室才能成为我们这帮人的“餐饮娱乐中心”&lt;sup id=&quot;fnref:recreation-center&quot;&gt;&lt;a href=&quot;#fn:recreation-center&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;，我才能拥有如此精彩而欢乐的大学四年。&lt;/p&gt;

&lt;h3 id=&quot;日常&quot;&gt;日常&lt;/h3&gt;

&lt;p&gt;大四下的日常，主要就是毕设和谈恋爱。毕设的部分讲过了，谈恋爱的部分不准备讲，所以日常没什么好讲的了。不过值得一提的是，这学期看了不少演出。在新清看了《吉赛尔》，在蒙民伟看了《第十二夜》和两场《Rent》，在天桥剧场看了《深夜小狗离奇事件》，还在北京喜剧院看了《雅各比与雷弹头》。虽然还是没什么鉴赏能力，但确实能从话剧和音乐剧中体会到乐趣，也算是有进步吧。&lt;/p&gt;

&lt;p&gt;剩下还有一些日常聊天的截图，我觉得非常有意思，在这里一并发出来：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/thulaw.jpg&quot; alt=&quot;实验室刺激日常&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图8：法律 NLP 的刺激日常。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/被申请逼疯.jpg&quot; alt=&quot;被申请逼疯&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图9：被申请逼疯的留学党。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/如何清理git仓库.jpg&quot; alt=&quot;git骚操作&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图10：如何清理你的 git 仓库。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;学习&quot;&gt;学习&lt;/h3&gt;

&lt;p&gt;这学期我还有两门大三下退的课：操作系统和计算机系统结构。此外，我还担任了OOP的助教。&lt;/p&gt;

&lt;h4 id=&quot;操作系统&quot;&gt;操作系统&lt;/h4&gt;

&lt;p&gt;其实我对这课还是有兴趣的，而且也学到了东西，最后分数也不算差。回头想想，大三下退这门课其实挺没必要的。操作系统的难点在于它的学习曲线非常陡峭，知识点散而杂，要完成第一次作业就得了解很多概念，很多人（包括曾今的我）就因此被劝退了。但说实在的，作为计算机体系里的重要组成部分，操作系统是十分有必要学习的，对于底层优化也能起到指导作用。&lt;/p&gt;

&lt;h4 id=&quot;系统结构&quot;&gt;系统结构&lt;/h4&gt;

&lt;p&gt;大三下因为觉得学的东西太傻逼而退课。这学期选了另一个老师开的课，发现内容同等傻逼，而且也有签到环节。布置作业的方式也直逼徐明星，反正就是不知道要做的是哪些题，你得上课去才明白。作业全都是抄的，考试也不难，稍微复习一下就行。&lt;/p&gt;

&lt;p&gt;这门课一度打消了我对系统结构的兴趣。直到我上学期（研一下）在 CMU 上了一门并行计算课，其中也有相似的内容，我才发现，这玩意并不枯燥，也不难理解，以前学得那么痛苦纯粹是 PPT 做得太差。说实话，我并没有觉得美帝老师的平均讲课水平比国内高，但在对待课程的认真程度，和课件的精致程度上真的要高出一个档次。&lt;/p&gt;

&lt;h4 id=&quot;oop助教&quot;&gt;OOP助教&lt;/h4&gt;

&lt;p&gt;当助教其实挺有意思的，能够切身感受到长江后浪推前浪。好几个组的大作业真的震撼到我了，比如有支持高阶导数的计算图，还有支持闭包、能编译到字节码的简易 Python 解释器（最骚的是他们还自己&lt;em&gt;手写&lt;/em&gt; 了 lex 和 yacc）。当然大家的水平差距还是挺大的，也有被我打了接近零分的脑残大作业。&lt;/p&gt;

&lt;p&gt;助教的另一个工作就是出考卷和批考卷。因为我们系 OOP 课程很重要的一个内容是学习高端 C++ 特性，所以考试题目大部分都是在考察 C++ 知识。考前我们会聚在一起讨论题目有没有什么漏洞，大家都觉得没毛病的题才会往试卷上放，但即便如此，也经常会漏掉一些 corner case。比如说，下面是一道考试原题：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;以下说法不正确的是：&lt;/p&gt;
  &lt;ol style=&quot;list-style-type: upper-latin;&quot;&gt;
&lt;li&gt;被声明为友元的函数或类，对出具友元声明的类的一切成员有访问权限。&lt;/li&gt;
&lt;li&gt;A 函数是 B 类的友元函数，B 类是 C 类的友元类，A 函数对 C 类没有特殊访问权限。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;编译器认为某个函数不值得内联，就会忽略内联修饰符。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;编译期间建立虚函数表 VTABLE 和虚函数指针 VPTR。&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;其实看题很容易想明白想考察的知识点是什么。A 是友元的定义，B 是友元关系不具有传递性，C 是 inline 不是强制内联，D 是虚函数机制的实现。只有 VTABLE 是编译期建立的，VPTR 是运行时在构造函数里赋值的，所以答案是 D。但考试结束后，同学们指出 A 和 C 也存在错误。A 是因为出具友元声明的类可能包含其自身也无法访问到的成员，比如其父类的私有成员；C 是因为内联修饰符 inline 有另一个语义，即函数不会跨翻译单元，而这一语义是不会被忽略的。怎么说呢，C++ 是真能锻炼记忆力和思辨能力的。&lt;/p&gt;

&lt;p&gt;除此之外，助教的工作包括做课件、布置作业、改作业等等。我自认为课件做得还不错。我负责的是单例和工厂模式的部分，介绍了单例相关的争议、CRTP，以及工厂模式的一些现实例子。我当时学设计模式的时候就苦于没有实际应用，每看一个模式都只会觉得“这个有啥用”。希望结合自身学习经历做出来的课件能帮到一些学弟学妹吧。&lt;/p&gt;

&lt;h3 id=&quot;女生节&quot;&gt;女生节&lt;/h3&gt;

&lt;p&gt;不知道前文中是否提过，我们班大四的班长是曾任大三副班长的白教员。虽然大家常常拿他打趣，但不可否认的是，在没人愿意管事的大四学年&lt;del&gt;连任&lt;/del&gt;接下了班长的摊子，就已经很了不起了。&lt;/p&gt;

&lt;p&gt;我们班的女生节活动是前往古北水镇游玩。女生们其实不太满意，因为二班在一周前刚去过，白教员的灵感从何而来比较明显。但对我来说，去哪玩不重要，和班里同学这多半最后一次的活动才重要。&lt;/p&gt;

&lt;p&gt;过程没什么可说的，放一张爬司马台长城的图吧。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/女生节.jpg&quot; alt=&quot;女生节&quot; width=&quot;700&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图11：最后一次班级活动的合照。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;马拉松&quot;&gt;马拉松&lt;/h3&gt;

&lt;p&gt;趁毕业前挑战了一次校园半马。之前跑过两次 10km，感觉虽然累但也能撑下来，可这次半马就完全不一样了。前 10km 觉得还比较轻松（甚至比去年快），但从第 13km 开始就感到体力不支，从 16km 开始感觉右腿膝盖有点疼，最后 3km 走一阵跑一阵，咬牙坚持才跑完的。跑下来一共2小时40分，属于重在参与的成绩。&lt;/p&gt;

&lt;p&gt;这次跑完之后腿疼了好一阵子，具体表现是右腿膝盖不能在弯曲的时候用力，比如上楼时不能用右脚做支撑。为此，我发明了一种特殊的上楼方法：左脚处于比右脚高两级台阶的位置，随后每上一级台阶时，左脚先上一级，然后右脚再上一级。那阵子只有用这种方法上楼腿才不会疼。令我没想到的是，这次腿疼的影响远高于我的预期，直到半年之后才完全复原。看来还是不能盲目挑战要求比较高的运动。&lt;/p&gt;

&lt;h3 id=&quot;毕业旅行&quot;&gt;毕业旅行&lt;/h3&gt;

&lt;p&gt;出于一些原因，我们班的毕业旅行没搞起来。白教员尽心尽力准备了几套旅行方案，但无奈参与的人数过少，只好遗憾作罢。&lt;/p&gt;

&lt;p&gt;但再怎么咸鱼，旅行还是要旅行的。我们几个平时玩得好的决定自驾游去附近的城市。经过一些讨论和放鸽之后，我们决定租两辆车开去北戴河。出行前，我和另外两位司机被按在椅子上接受了&lt;a href=&quot;https://space.bilibili.com/28152409/video&quot;&gt;交通事故video&lt;/a&gt;的安全教育。&lt;/p&gt;

&lt;p&gt;我们的旅行其实没啥亮点。死宅自驾出游会带什么？两台 PS4、一台 Switch、两盒方便火锅。这些东西塞满了后备箱。一路上的过程就是：开车吹逼，下车吃饭，到旅馆打游戏。不得不说北戴河的住宿是真的便宜，我们定了两间复式公寓，目测每间有差不多100平，一晚上才二百来块。我们也没去什么景点，就在海边吹了吹风，沙滩上躺了躺，然后回房间玩游戏去了。听着很咸鱼，但对我们来说就是快乐的本质。&lt;/p&gt;

&lt;p&gt;旅行没拍什么游客照，拍的全都是大家的表情包和鬼畜视频，所以不放图了。&lt;/p&gt;

&lt;h3 id=&quot;毕联&quot;&gt;毕联&lt;/h3&gt;

&lt;p&gt;虽说带有浓厚的主观滤镜，但我还是认为，我们这一届毕联是近几年来最棒的，没有之一。这届毕联的主题是《天下大计》，是一个颇有页游风格的霸气名字。按照官方说法，这个名字的含义是“计4年级即将毕业，前往世界各地的工作岗位上担起自己的职责”，而且还“与去年毕联主题‘酒歌烁世’&lt;sup id=&quot;fnref:nine-masters&quot;&gt;&lt;a href=&quot;#fn:nine-masters&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;形成呼应，我系同学将继续学长学姐所留下的优秀文化，不忘初心不忘使命”。玩笑归玩笑，我还是很喜欢这个名字的，有一种敢为天下先的豪迈感。&lt;/p&gt;

&lt;h4 id=&quot;毕联筹备&quot;&gt;毕联筹备&lt;/h4&gt;

&lt;p&gt;三月底，我被唐主席连哄带骗拉进了毕联筹备组，帮着做一些宣传方面的事情。刚开始做的事情就是传统的宣传，比如做宣传图、印刷品、&lt;a href=&quot;https://mp.weixin.qq.com/s/EitnSclgpnwJlMIYT5U2bg&quot;&gt;纪念衫&lt;/a&gt;等等。其中诞生出的一个非常不错的点子是毕业倒计时：把大学四年中的重要事件映射到毕业前的100天内，在公众号上推倒计时图片。图片下方的装饰线其实藏着进度条，只有把图片连着看的时候才会发现。美中不足的是最开始的十几张图用的模板有些小偏差，导致最下方的文字位置有微小的偏差。&lt;/p&gt;

&lt;p&gt;我把所有图片压成了下面的视频。这些图片最后变成了毕业纪念册里的每一页。&lt;/p&gt;

&lt;video src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/倒计时.mp4&quot; autoplay=&quot;&quot; muted=&quot;&quot; loop=&quot;&quot;&gt;&lt;/video&gt;

&lt;h4 id=&quot;毕联游戏&quot;&gt;毕联游戏&lt;/h4&gt;

&lt;p&gt;我本来以为我的任务就是帮着一起做图而已。直到四月底的有一天，唐主席和家晖把我带到 408 单独约谈，说既然毕联的名字这么像一个游戏，不如我们真的做一个游戏吧；组委会都决定了，我来当负责人。我本来想说另请高明吧，但仔细想了想，这游戏听着真的挺有意思的，而且我真的需要一些事情来缓解毕设带来的枯燥感，就接下了这口重锅。&lt;/p&gt;

&lt;p&gt;我们准备做一个文字冒险游戏（因为其它所有类型都不太现实），讲述从入学到毕业&lt;sup id=&quot;fnref:completion-not-graduation&quot;&gt;&lt;a href=&quot;#fn:completion-not-graduation&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;的故事。最后的成果就是这个网站首页上的&lt;a href=&quot;http://cst4.zecong.hu/&quot;&gt;天下大计&lt;/a&gt;同名游戏。游戏发布后获得了很高的热度，许多毕业多年的学长学姐都在玩，甚至还有同学熬夜肝这个游戏，真实爆肝。游戏上线后也暴露出了一些测试中没有发现的 bug，给了我在生产环境部署 hotfix 的宝贵体验。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/天下大计-调试.jpg&quot; alt=&quot;天下大计调试现场&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图12：艰苦卓绝的调试现场。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当然，这绝非我一人的功劳。非常感谢天天被我 push 的编写和测试剧本的同学们、统筹的唐主席、担任美工的家晖，以及两篇非常优秀的&lt;a href=&quot;https://mp.weixin.qq.com/s/qCZGCDGEsSIvSKvdfc2D2A&quot;&gt;宣传推送&lt;/a&gt;和&lt;a href=&quot;https://mp.weixin.qq.com/s/lDRfz1xPTvD-L1fLu1oVWQ&quot;&gt;攻略推送&lt;/a&gt;。这是我大四一整年参与过的所有涉及写代码的项目中，最有成就感的一个。&lt;/p&gt;

&lt;h4 id=&quot;毕联晚会&quot;&gt;毕联晚会&lt;/h4&gt;

&lt;p&gt;毕联晚会还是不错的，诞生了一些新的表情包，还有不少人看乔导的采访视频都看哭了。但对我来说重点是之后的聚餐。一如往常，聚餐在南门外的满盆香&lt;sup id=&quot;fnref:man-pen-xiang&quot;&gt;&lt;a href=&quot;#fn:man-pen-xiang&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;。这是我喝得最多的一次（对于酒量极小的我来说，这大概是两瓶啤酒），也是最开心的一次。这次也让我见识到了大家酒后的百态，包括哭得稀里哗啦的殷老师，不敬酒自己也喝的徐子南，以及喝前矜持喝后到处灌人酒的酒品贼差的白教猿。&lt;/p&gt;

&lt;p&gt;最后实在是不胜酒力，还是倩倩骑电动车送我到楼下，然后喊室友搀扶着我上楼的。&lt;/p&gt;

&lt;h2 id=&quot;旅途的终点&quot;&gt;旅途的终点&lt;/h2&gt;

&lt;p&gt;毕业的流程全部压缩在了最后一周内。这里我打算按照时间顺序，以流水账的形式回顾一下到毕业为止发生的事情：&lt;/p&gt;

&lt;p&gt;7月4日，刚刚结束毕业旅行，回来就是毕业联欢晚会和毕业聚餐。如前文所述，晚上聚餐喝得太多，回到寝室之后倒头就睡。&lt;/p&gt;

&lt;p&gt;7月5日，起床之后晕乎了一上午。下午出门买了第二天合影要穿的白衬衫。晚上和大家出去唱歌到了两点，唱的都是这四年来次次会点的怀旧金曲。&lt;/p&gt;

&lt;p&gt;7月6日，拍了一整天的照。一大早起来和校领导合影，随后紧接着是系毕业典礼，然后是系里的合影。系里合影拍了一个扔学士帽的版本，大家都笑成了表情包。下午拜托王老师帮我和倩倩拍了一组毕业纪念照。顺带一提，这组照片到现在还没修完。&lt;/p&gt;

&lt;p&gt;7月7日，下午和实验室的导师和同学合影。没想到大家都穿了学士服，就我一人穿了T恤。爸妈也在这天来了北京，晚上一起吃了饭。回来之后终于开始整理房间了。&lt;/p&gt;

&lt;p&gt;7月8日，校毕业典礼。发言比较冗长，于是我们几个玩起了你画我猜。六核十二线程拨穗&lt;sup id=&quot;fnref:multiprocess&quot;&gt;&lt;a href=&quot;#fn:multiprocess&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;结束之后，我和倩倩两家人共进了午餐。午餐比想象中的顺利，两家人似乎都对对方比较满意，也没有什么“我才不会把女儿交给你”之类的动漫定番。&lt;/p&gt;

&lt;p&gt;7月9日，跑各种毕业的手续。领了证书、照片，和纪念品，注销了校园卡和网络账号，还了宿舍钥匙，交了离校表。晚上和大家吃了临走前最后一顿聚餐，回来之后抓紧最后的时间清东西。408 被大家带不走的或有用或没用的东西给塞满了，俨然成为了有求必应屋。&lt;/p&gt;

&lt;p&gt;7月10日，搬离宿舍，下午就回到了家。这个过程实在是太突然，以至于我还没有反应过来“是真的毕业了”，就已经到家了。这几天满当当的流程，以及穿插其中的清东西，让我完全没有时间因毕业而感伤。直到回家后闲下来了，情绪才一下子涌了上来。&lt;/p&gt;

&lt;p&gt;该怎么说呢，对很多人来说高中是他们的青春，但我的高中生活几乎只有竞赛，大学才是我的青春。上大学之前的我是一个没有住过校、没有加入过社团组织、没有参与过年级活动的人，所以我才会说&lt;a href=&quot;/2015/02/06/my-1st-semester-in-college/#%E7%8F%AD%E7%BA%A7%E5%92%8C%E5%90%8C%E5%AD%A6%E4%BB%AC&quot;&gt;大学的班级真正给了我归属感&lt;/a&gt;。大学让我体会到了太多的第一次，包括&lt;a href=&quot;/2017/01/28/my-5th-semester-in-college/#%E6%96%87%E8%89%BA%E9%83%A8&quot;&gt;参与组织学生活动&lt;/a&gt;、&lt;a href=&quot;/2016/02/11/my-3rd-semester-in-college/#%E5%AD%A6%E7%94%9F%E8%8A%82-1&quot;&gt;当 DV 剧导演&lt;/a&gt;、&lt;a href=&quot;/2016/02/04/se-project-dev-log/&quot;&gt;和信任的小伙伴&lt;/a&gt;&lt;a href=&quot;/2017/01/28/my-5th-semester-in-college/#fpga-%E8%AE%BE%E8%AE%A1%E5%A4%A7%E8%B5%9B&quot;&gt;合作完成项目&lt;/a&gt;、&lt;a href=&quot;/2018/07/19/my-7th-semester-in-college/#%E6%9A%91%E7%A0%94&quot;&gt;出国交换&lt;/a&gt;等等。除了这些体验之外，大学最宝贵的财富就是收获了一群志同道合的好朋友，我从他们身上学到的东西，不少于我从课本上学到的。&lt;/p&gt;

&lt;p&gt;“丰富多彩，专注耐心”是我大一入学时辅导员告诉大家的一句话。回顾这四年的生活，我觉得我能对得起这句话。接下来要做的事，大概就是忘掉大学期间取得的成就，走出象牙塔，寻找并实现人生的下一个目标。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;大学生活，就此结束。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019/08/26/my-8th-semester-in-college/合影-计算机本科生.jpg&quot; alt=&quot;毕业合影&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图13：计四年级毕业合影。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;脚注&quot;&gt;脚注&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:case-docs&quot;&gt;
      &lt;p&gt;这是真的。我在数据中见到的错误写法有：&lt;a href=&quot;http://wenshu.court.gov.cn/content/content?DocID=fda83995-0b05-4d4a-a3a8-4a2538558838&amp;amp;KeyWord=%E6%9C%80%E9%AB%98%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD&quot;&gt;最高人民共和国&lt;/a&gt;、&lt;a href=&quot;http://wenshu.court.gov.cn/content/content?DocID=4dc977b9-e0d4-4e42-9afa-160221895b41&amp;amp;KeyWord=%E5%B1%AE%E5%8D%8E%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD&quot;&gt;屮华人民共和国&lt;/a&gt;、&lt;a href=&quot;http://wenshu.court.gov.cn/content/content?DocID=45b4fee2-2eae-49df-affa-70464606e77e&amp;amp;KeyWord=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD&quot;&gt;中国人民共和国&lt;/a&gt;、&lt;a href=&quot;http://wenshu.court.gov.cn/content/content?DocID=7906e93b-8bf4-46c1-a433-943f5a5f631a&amp;amp;KeyWord=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E5%85%B1%E5%92%8C%E5%9B%BD&quot;&gt;中国人共和国&lt;/a&gt;等等。为了证明不是我瞎编的，可以点击错误写法查看真实的法律文书。 &lt;a href=&quot;#fnref:case-docs&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:cannot-graduate&quot;&gt;
      &lt;p&gt;事实上并非如此，无法达标的话是真的毕不了业的。虽然标准相当低就是了。 &lt;a href=&quot;#fnref:cannot-graduate&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:yellow-card&quot;&gt;
      &lt;p&gt;事后证明这只是传闻而已。不过期中表现太差确实会让导师盯住你。 &lt;a href=&quot;#fnref:yellow-card&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:successful-boast&quot;&gt;
      &lt;p&gt;并不是。其实只是因为，只要划水不太过分，中期答辩都不会被追究进度。 &lt;a href=&quot;#fnref:successful-boast&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:weekly-report&quot;&gt;
      &lt;p&gt;“本周进度：复习操作系统期中考试。” &lt;a href=&quot;#fnref:weekly-report&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:bridge-cafe&quot;&gt;
      &lt;p&gt;似乎毕业后不久就关门了。这么说来我也算是最后的客户之一吧。 &lt;a href=&quot;#fnref:bridge-cafe&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:recreation-center&quot;&gt;
      &lt;p&gt;每当需要聚众吃夜宵或者打游戏，大家就会来我们寝室。 &lt;a href=&quot;#fnref:recreation-center&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:nine-masters&quot;&gt;
      &lt;p&gt;为不了解背景的各位介绍一下，去年的名字是实际上在暗讽系里硕士缩招，只有“九个硕士”名额。 &lt;a href=&quot;#fnref:nine-masters&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:completion-not-graduation&quot;&gt;
      &lt;p&gt;如果你真的玩了这个游戏，会发现大部分时候它讲的都是从入学到结业的故事。 &lt;a href=&quot;#fnref:completion-not-graduation&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:man-pen-xiang&quot;&gt;
      &lt;p&gt;记忆中我每年都来满盆香吃过一次聚餐，分别是大一班级聚餐、大二学生节聚餐、大三学生节聚餐，以及大四毕业聚餐。据说，之所以聚餐都选择这里，是因为它是学校附近唯一能营业到凌晨两点的地方。 &lt;a href=&quot;#fnref:man-pen-xiang&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:multiprocess&quot;&gt;
      &lt;p&gt;六个台子，每个台子上两名校领导，共十二名领导并行拨穗。 &lt;a href=&quot;#fnref:multiprocess&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Zecong Hu</name></author><summary type="html">系列八篇中的最后一篇。本应在暑假就写完的，结果断断续续拖了整整一年，到现在五字班都毕业了。 请允许我先用几个词概括我的大四下： 忙碌。在我的想象中，毕设不过就是几个大作业的分量，大四下应该比较轻松才对。实际的体验却并非如此。 淡出。四年来习以为常在身边的同学们，并不是像文学作品中那样，在毕业典礼之后有说有笑相互道别的。在北京工作的同学们在学期中就逐渐搬出了宿舍，其他同学则在毕业后清理了寝室，陆续离开了。这种退场方式，相比起前者更加令人感到难过。 不舍。毫不夸张地，这四年是我至今的人生中最丰富多彩、也最专注耐心的四年。有欢笑，有伤心，有许多长进，也有诸多遗憾。 tl;dr: 以上就是本篇文章的主旨。赶时间的话，读到这里就可以了。下文中有大量图片，请注意流量。</summary></entry><entry><title type="html">Inheritance for Python Namedtuples</title><link href="http://zecong.hu/2019/08/10/inheritance-for-namedtuples/" rel="alternate" type="text/html" title="Inheritance for Python Namedtuples" /><published>2019-08-10T19:05:00+00:00</published><updated>2019-08-10T19:05:00+00:00</updated><id>http://zecong.hu/2019/08/10/inheritance-for-namedtuples</id><content type="html" xml:base="http://zecong.hu/2019/08/10/inheritance-for-namedtuples/">&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; Inheritance for the Python built-in namedtuple does not work as we expect. This blog post demonstrates how to create a custom namedtuple class that supports meaningful inheritance, and more.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I’ve always under-appreciated the Python &lt;a href=&quot;https://docs.python.org/3/library/collections.html#collections.namedtuple&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;collections.namedtuple&lt;/code&gt;&lt;/a&gt; class. For those who are unfamiliar, a namedtuple is a fancier tuple, whose elements can also be accessed as attributes:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namedtuple&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namedtuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Point'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 1 2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This allows using meaningful names for the elements, rather than having to remember what are stored under each index.&lt;/p&gt;

&lt;p&gt;What I don’t like about it, however, is the ugly syntax: attribute names are stored as strings, the class name is repeated, and most importantly, refactoring is error-prone, even within powerful IDEs. You can rename class attributes and all the references easily in PyCharm, but you can’t do that for namedtuples. What I wanted was a syntax like that of the C/C++ &lt;code class=&quot;highlighter-rouge&quot;&gt;struct&lt;/code&gt;, with a default constructor to assign values to each field.&lt;/p&gt;

&lt;p&gt;Luckily, this changed in Python 3.6, with the implementation of &lt;a href=&quot;https://www.python.org/dev/peps/pep-0526/&quot;&gt;PEP 526&lt;/a&gt;. This version provides &lt;a href=&quot;https://docs.python.org/3/library/typing.html#typing.NamedTuple&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;typing.NamedTuple&lt;/code&gt;&lt;/a&gt;, a typed version of namedtuple with a brand new syntax. Instead of the example above, now you can write:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;typing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NamedTuple&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NamedTuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 1 0
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This snippet works in exactly the same way, but adds type annotations for each field, and also supports default values (but fields with default values have to follow those without, just as in a function declaration). The syntax is also much more natural (to a former C++ user, at least). But there is still something we can’t do: inheritance.&lt;/p&gt;

&lt;p&gt;If you ever tried to inherit a namedtuple, you will find that it doesn’t work as you expect. As illustrated in &lt;a href=&quot;https://stackoverflow.com/questions/42385916/inheriting-from-a-namedtuple-base-class-python&quot;&gt;this StackOverflow question&lt;/a&gt;, the new attributes added in the subclass doesn’t show up, and you’d have to manually override the constructor, which is kind of against the intention of using namedtuples in the first place.&lt;/p&gt;

&lt;p&gt;Now, you may think, let’s just hack into the internals and somehow make inheritance work. If you were ever in the mood to peek under the hood of this &lt;code class=&quot;highlighter-rouge&quot;&gt;namedtuple&lt;/code&gt; class, you’d find that it’s surprisingly complicated for what seemed like a small and easy piece of functionality. But don’t be afraid, the logic is actually pretty straightforward — it just involves some details of Python’s internal data model.&lt;/p&gt;

&lt;p&gt;Before we begin, let’s summarize what we want to achieve through this blog post:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Make inheritance work for &lt;code class=&quot;highlighter-rouge&quot;&gt;typing.NamedTuple&lt;/code&gt; as we expect.&lt;/li&gt;
  &lt;li&gt;Also allow multiple inheritance, if there are no overlaps in field names among the base classes.&lt;/li&gt;
  &lt;li&gt;Remove the constraint on ordering for fields with default values.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;instance-class-and-metaclass&quot;&gt;Instance, Class, and Metaclass&lt;/h2&gt;

&lt;p&gt;Before diving into the actual code, let’s get a couple of concepts clear. We need to know what metaclasses are, and how a class is created, before we can customize that behavior.&lt;/p&gt;

&lt;p&gt;If you’re not familiar with metaclasses, I recommend reading &lt;a href=&quot;https://blog.ionelmc.ro/2015/02/09/understanding-python-metaclasses/&quot;&gt;this wonderful article&lt;/a&gt;, which gives a comprehensive explanation of the entire topic. But here, I will try to briefly explain the concepts that will be useful for our goals.&lt;/p&gt;

&lt;h4 id=&quot;class-instance-and-the-__new__-method&quot;&gt;Class Instance and the &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method&lt;/h4&gt;

&lt;p&gt;We’re all familiar with &lt;strong&gt;class&lt;/strong&gt;es. An &lt;strong&gt;instance&lt;/strong&gt; of a class is what you’d get after calling the class constructor.&lt;/p&gt;

&lt;p&gt;You might think the Python class constructor is &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt;, but that’s not the whole story. When you construct an instance, the &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method is first called with the same arguments you pass to &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; is responsible for the actually creating an instance of the class, and that instance is then passed into &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt; as the &lt;code class=&quot;highlighter-rouge&quot;&gt;self&lt;/code&gt; argument.&lt;/p&gt;

&lt;p&gt;Note that &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; is considered a &lt;a href=&quot;https://docs.python.org/3/library/functions.html#classmethod&quot;&gt;class method&lt;/a&gt; (because the instance is not even created at the point of call), so its first argument is &lt;code class=&quot;highlighter-rouge&quot;&gt;cls&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;self&lt;/code&gt;. For most classes, the &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method just calls the super class &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt;, which all traces back to &lt;code class=&quot;highlighter-rouge&quot;&gt;object.__new__(cls)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;There are special cases though — you can return stuff that is not an instance of type &lt;code class=&quot;highlighter-rouge&quot;&gt;cls&lt;/code&gt; (or any of its subclasses), in which case, the &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt; method will not be called. A common use case for this is to entirely disable the behaviors of a class:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProgressBar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# wrap around an iterable to print a progress bar to terminal
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterable&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# progress bar disabled; don't wrap the iterable
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# `enable` must be `True`
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;metaclass&quot;&gt;Metaclass&lt;/h4&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt; built-in function shows the type of objects, &lt;em&gt;e.g.&lt;/em&gt;,&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# int
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# float
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;wow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# str
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# list
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MissileWarningSystem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# &amp;lt;class 'MissileWarningSystem'&amp;gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But what is the type of a class? Turns out, the type of a class is what we call a &lt;strong&gt;metaclass&lt;/strong&gt;, and the default metaclass (and the base for all metaclasses) is &lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt; itself. This reveals a new level of hierarchy&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; to us:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An instance is an instance of a class. The base for all classes is &lt;code class=&quot;highlighter-rouge&quot;&gt;object&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;A class is an instance of a metaclass. The base for all metaclasses is &lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just as classes control the behavior of instances, metaclasses control the behavior of classes. When a class is created, the metaclass’ &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method is called, and then its &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt; method. What’s different to classes is that you don’t get to customize the arguments received, it’s always like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Metaclass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mcs&lt;/code&gt; is the metaclass instance, in this case, &lt;code class=&quot;highlighter-rouge&quot;&gt;Metaclass&lt;/code&gt; or its potential sub-metaclasses (yes, inheritance works here).&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;typename&lt;/code&gt; is a &lt;code class=&quot;highlighter-rouge&quot;&gt;str&lt;/code&gt; storing the name of the class to create.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bases&lt;/code&gt; is a tuple of classes, containing the base classes of the class to create. This is what’s in the brackets following the class name on the first line.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;namespace&lt;/code&gt; contains all the class-level attributes, including methods and class attributes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since &lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt; is the default metaclass, we can use the same set of arguments with the &lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt; constructor to programmatically create a new class:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;MyClass&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MyClass&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;__init__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;setattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;foo&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which is equivalent to the canonical class definition syntax:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MyClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;the-namedtuple-class&quot;&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt; Class&lt;/h2&gt;

&lt;p&gt;Now that we’re equipped with the adequate knowledge, the first thing to do is look at how &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt; is implemented:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_make_nmtuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;types&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;NamedTuple('Name', [(f0, t0), (f1, t1), ...]); each t must be a type&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_type_check&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;msg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;types&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;namedtuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;types&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Prior to PEP 526, only _field_types attribute was assigned.
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Now, both __annotations__ and _field_types are used to maintain compatibility.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__annotations__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_field_types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;types&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__module__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_getframe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_globals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__name__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;AttributeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NamedTuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metaclass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NamedTupleMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_root&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Either list of fields or keywords&quot;&lt;/span&gt;
                            &lt;span class=&quot;s&quot;&gt;&quot; can be provided to NamedTuple, not both&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_make_nmtuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method here is actually not of our interest — it’s just here to provide an interface similar to &lt;code class=&quot;highlighter-rouge&quot;&gt;namedtuple&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;_make_nmtuple&lt;/code&gt; function that’s called from &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; is a utility function that internally constructs a &lt;code class=&quot;highlighter-rouge&quot;&gt;collections.namedtuple&lt;/code&gt; and adds type annotations to it. We note that what’s returned from &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; is not an instance of &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We notice that &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt; has a metaclass called &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTupleMeta&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;_root&lt;/code&gt; attribute here is important for the metaclass, and we’ll talk more of it later.&lt;/p&gt;

&lt;h2 id=&quot;the-namedtuplemeta-metaclass&quot;&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTupleMeta&lt;/code&gt; Metaclass&lt;/h2&gt;

&lt;p&gt;Now let’s take a look at the metaclass code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NamedTupleMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_root'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;types&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__annotations__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{})&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_make_nmtuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;types&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;defaults_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;types&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;default_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;defaults_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default_value&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Non-default namedtuple field {field_name} cannot &quot;&lt;/span&gt;
                                &lt;span class=&quot;s&quot;&gt;&quot;follow default field(s) {default_names}&quot;&lt;/span&gt;
                                &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;default_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;', '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaults_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__annotations__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;types&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__defaults__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_field_defaults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaults_dict&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# update from user namespace without overriding special namedtuple attributes
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_prohibited&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;AttributeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cannot overwrite NamedTuple attribute &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_special&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;nb&quot;&gt;setattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we know why there’s a &lt;code class=&quot;highlighter-rouge&quot;&gt;_root&lt;/code&gt; attribute in &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method of &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTupleMeta&lt;/code&gt; is also called when &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt; is created, but we can’t create a &lt;code class=&quot;highlighter-rouge&quot;&gt;collections.namedtuple&lt;/code&gt; for that. Thus, we check whether this special &lt;code class=&quot;highlighter-rouge&quot;&gt;_root&lt;/code&gt; attribute exists, and skips the following procedure if it does.&lt;/p&gt;

&lt;p&gt;When a subclass of &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt; is created, the &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method is also called, but this time the rest of the procedure is also executed. A couple of things happen:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Obtain the list of fields in the namedtuple definition. Since we provide an annotation for each field, they’re stored as a dictionary in the &lt;code class=&quot;highlighter-rouge&quot;&gt;__annotations__&lt;/code&gt; special attribute of the class.&lt;/li&gt;
  &lt;li&gt;Create a namedtuple class using &lt;code class=&quot;highlighter-rouge&quot;&gt;_make_nmtuple&lt;/code&gt;. Note that the returned namedtuple class does not support default values&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; or contain type annotations for the &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt; method.&lt;/li&gt;
  &lt;li&gt;Gather default values from &lt;code class=&quot;highlighter-rouge&quot;&gt;ns&lt;/code&gt; (namespace) and set annotations and default argument values for the &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method of the namedtuple class.&lt;/li&gt;
  &lt;li&gt;Add other attributes and methods to the created namedtuple class, so additional methods you defined in the &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt; subclass can also be called from the returned namedtuple class.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;inheritance-with-a-single-base-class&quot;&gt;Inheritance with a Single Base Class&lt;/h2&gt;

&lt;p&gt;Let’s first think about what we’re trying to accomplish by inheritance:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Automatically generate a constructor that sets all fields, including those from the base class.&lt;/li&gt;
  &lt;li&gt;Access methods, attributes, and properties from the base class.&lt;/li&gt;
  &lt;li&gt;Behave correctly in &lt;code class=&quot;highlighter-rouge&quot;&gt;isinstance&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;issubclass&lt;/code&gt; checks.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we don’t care about the latter two, the solution is pretty straightforward: we just gather the fields defined in the derived and base classes, and ask &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTupleMeta&lt;/code&gt; to create a &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt; based on these fields.&lt;/p&gt;

&lt;p&gt;Let’s make a first attempt at implementing this. Out of personal preference, I’m going to call our enhanced namedtuple &lt;code class=&quot;highlighter-rouge&quot;&gt;Options&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OptionsMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NamedTupleMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_root'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# The created class is `Options`, skip.
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Gather fields from annotations of current class and base class.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cur_fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__annotations__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{})&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# We only deal with single inheritance for now.
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hasattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_fields'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Base class is a concrete namedtuple.
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# Make sure not to overwrite redefined fields.
&lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__annotations__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_field_defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setdefault&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_field_defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__annotations__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Let `NamedTupleMeta` create a annotated `namedtuple` for us.
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Note that `bases` is not used there so we just set it to `None`.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metaclass&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OptionsMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_root&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Prevent instantiation of `Options` class.
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Type Options cannot be instantiated; &quot;&lt;/span&gt;
                            &lt;span class=&quot;s&quot;&gt;&quot;it can be used only as a base class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;A few things to notice here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We define a new metaclass that inherits &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTupleMeta&lt;/code&gt; so we could call its &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method that takes care of everything for us. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Options&lt;/code&gt; class doesn’t really do anything, and for simplicity, we forbid directly instantiating it like we could for &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;annotations&lt;/code&gt; must be an &lt;code class=&quot;highlighter-rouge&quot;&gt;OrderedDict&lt;/code&gt; because the ordering of fields matter — the order determines the index of the field in the underlying tuple object. Here we put base class fields in front of derived ones, but leave out ones that are redefined.&lt;/li&gt;
  &lt;li&gt;A limitation of this method is that the base class cannot contain fields with default values, unless: &lt;em&gt;a)&lt;/em&gt; they’re redefined in the base class, or &lt;em&gt;b)&lt;/em&gt; every field in the derived class also comes with a default value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you understood what we’ve learnt so far, the implementation is actually pretty straightforward. However, we encounter problems when we try to use it in practice:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;---------------------------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;                                 &lt;span class=&quot;n&quot;&gt;Traceback&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipython&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f4db6b51352e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;----&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;takes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;positional&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arguments&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;but&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;were&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;given&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The error message may seem a bit cryptic, but what happens here is that &lt;code class=&quot;highlighter-rouge&quot;&gt;DerivedOptions&lt;/code&gt; became an alias for &lt;code class=&quot;highlighter-rouge&quot;&gt;BaseOptions&lt;/code&gt;. A deeper investigation shows that &lt;code class=&quot;highlighter-rouge&quot;&gt;OptionsMeta.__new__&lt;/code&gt; is not even called when &lt;code class=&quot;highlighter-rouge&quot;&gt;DerivedOptions&lt;/code&gt; is created. How come?&lt;/p&gt;

&lt;p&gt;The truth is, the &lt;code class=&quot;highlighter-rouge&quot;&gt;nm_tpl&lt;/code&gt; returned from the constructor of &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTuple&lt;/code&gt; is of type &lt;code class=&quot;highlighter-rouge&quot;&gt;collections.namedtuple&lt;/code&gt;, and of course, the metaclass of which is not &lt;code class=&quot;highlighter-rouge&quot;&gt;OptionsMeta&lt;/code&gt;. When inheriting the &lt;code class=&quot;highlighter-rouge&quot;&gt;nm_tpl&lt;/code&gt; class, we’re actually inheriting a namedtuple, not an &lt;code class=&quot;highlighter-rouge&quot;&gt;Options&lt;/code&gt; subclass.&lt;/p&gt;

&lt;p&gt;Thus, we must create a new class using the namespace of &lt;code class=&quot;highlighter-rouge&quot;&gt;nm_tpl&lt;/code&gt;, and we do so by directly invoking the &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method of &lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt;, which is &lt;code class=&quot;highlighter-rouge&quot;&gt;NamedTupleMeta&lt;/code&gt;’s super class:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__dict__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To explain this method call:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;type.__new__&lt;/code&gt; will create a class with metaclass set to &lt;code class=&quot;highlighter-rouge&quot;&gt;mcs&lt;/code&gt; (which is &lt;code class=&quot;highlighter-rouge&quot;&gt;OptionsMeta&lt;/code&gt; in this case).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An added benefit here is that we get to set the base class of the created class, in this case, &lt;code class=&quot;highlighter-rouge&quot;&gt;BaseOptions&lt;/code&gt; (from &lt;code class=&quot;highlighter-rouge&quot;&gt;bases&lt;/code&gt;) and &lt;code class=&quot;highlighter-rouge&quot;&gt;tuple&lt;/code&gt; (from &lt;code class=&quot;highlighter-rouge&quot;&gt;nm_tpl.__bases__&lt;/code&gt;). Note that it’s essential to keep &lt;code class=&quot;highlighter-rouge&quot;&gt;tuple&lt;/code&gt; a base class, because &lt;code class=&quot;highlighter-rouge&quot;&gt;tuple.__new__&lt;/code&gt; is called when we create an instance of this namedtuple, and that requires the class to be a subclass of &lt;code class=&quot;highlighter-rouge&quot;&gt;tuple&lt;/code&gt;. If we don’t do that, we get an exception:&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DerivedOptions&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subtype&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;__dict__&lt;/code&gt; (namespace) of &lt;code class=&quot;highlighter-rouge&quot;&gt;nm_tpl&lt;/code&gt; is used as is. We do a copy because &lt;code class=&quot;highlighter-rouge&quot;&gt;type.__new__&lt;/code&gt; requires this namespace dictionary to be writable (of type &lt;code class=&quot;highlighter-rouge&quot;&gt;dict&lt;/code&gt;), but &lt;code class=&quot;highlighter-rouge&quot;&gt;__dict__&lt;/code&gt; is not (of type &lt;code class=&quot;highlighter-rouge&quot;&gt;mappingproxy&lt;/code&gt;).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since we were able to keep the actual base class (&lt;code class=&quot;highlighter-rouge&quot;&gt;BaseOptions&lt;/code&gt;) in the MRO&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; of the derived class, Python automatically takes care of the latter two functionalities we wanted to accomplish by inheritance. We can easily verify this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;property&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;multiple-inheritance&quot;&gt;Multiple Inheritance&lt;/h2&gt;

&lt;p&gt;The method above also fits for multiple inheritance — we just need to gather fields from all the base classes. However, with multiple bases come other problems that did not exist in the single inheritance case:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What if multiple base classes define the same field? Since we’re exploring uncharted waters here, we get to define the behavior, but it has to be intuitive. My opinion is that base classes must not have overlapping fields, unless they’re redefined in the derived class. This guarantees that there aren’t unexpected overwrites of fields by different orderings of the base classes. But of course, if you implement it, you’re free to choose whatever strategy that pleases you.&lt;/li&gt;
  &lt;li&gt;What if a base class is not a subclass of &lt;code class=&quot;highlighter-rouge&quot;&gt;Options&lt;/code&gt;? We should still keep it &lt;code class=&quot;highlighter-rouge&quot;&gt;bases&lt;/code&gt; so it’s kept in the MRO&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, and instances could access its methods.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, let’s try implementing this &lt;code class=&quot;highlighter-rouge&quot;&gt;OptionsMeta&lt;/code&gt; metaclass that supports multiple inheritance:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OptionsMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NamedTupleMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_root'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# The created class is `Options`, skip.
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Gather fields from annotations of current class and base classes.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;cur_fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__annotations__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{})&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;field_sources&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# which base class does the name came from
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;field_defaults&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;issubclass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hasattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_fields'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# Base class is a concrete subclass of `Options`.
&lt;/span&gt;                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cur_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;# Make sure not to overwrite redefined fields.
&lt;/span&gt;                        &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                        &lt;span class=&quot;c1&quot;&gt;# Overlapping field that is not redefined.
&lt;/span&gt;                        &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Base class {base} contains field {name}, which &quot;&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;is defined in other base class &quot;&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{field_sources[name]}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__annotations__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;field_sources&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_field_defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;field_defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_field_defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cur_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Options class must contain at least one field&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_defaults&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setdefault&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__annotations__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Let `NamedTupleMeta` create a annotated `namedtuple` for us.
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Note that `bases` is not used here so we just set it to `None`.
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Wrap the return type in `OptionsMeta` so it can be subclassed.
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Also keep base classes of the `namedtuple` (i.e., the `tuple` class),
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# so we can call `tuple.__new__`.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__dict__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This works great when we inherit from non-&lt;code class=&quot;highlighter-rouge&quot;&gt;Options&lt;/code&gt; classes, as we can see from these examples:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;property&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Mixin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mixin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DerivedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mixin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But when we try to inherit from two &lt;code class=&quot;highlighter-rouge&quot;&gt;Options&lt;/code&gt; subclasses, something weird happens:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OptionsA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OptionsB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;In&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MergedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OptionsA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OptionsB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;---------------------------------------------------------------------------&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;                                 &lt;span class=&quot;n&quot;&gt;Traceback&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipython&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;51&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d384fffb01&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;----&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MergedOptions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OptionsA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OptionsB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
      &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipython&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ff213f4a3b5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;mi&quot;&gt;43&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# so we can call `tuple.__new__`.
&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;44&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;---&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__dict__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
     &lt;span class=&quot;mi&quot;&gt;46&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiple&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;have&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conflict&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now this is something new, an error message I’ve never seen before. It turns out that I cannot inherit from multiple built-in classes that don’t go together at the C level&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;, in this case, two different subclasses of &lt;code class=&quot;highlighter-rouge&quot;&gt;tuple&lt;/code&gt;. I can see why this is a problem: such built-in types are implemented in C, with fixed memory layouts and implementations for special methods.&lt;/p&gt;

&lt;p&gt;If we can’t create the type with our bases, how about modifying the bases after creation? It turns out you can’t do that either:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipython&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;118&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d6cd3ab74257&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;mi&quot;&gt;43&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# so we can call `tuple.__new__`.
&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;44&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;options_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__dict__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;---&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;options_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;
     &lt;span class=&quot;mi&quot;&gt;46&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options_type&lt;/span&gt;
     &lt;span class=&quot;mi&quot;&gt;47&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;assignment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Options'&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;differs&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'tuple'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems that we’re out of luck. But actually, here’s some less known evil: you can &lt;a href=&quot;http://stupidpythonideas.blogspot.com/2015/12/can-you-customize-method-resolution.html&quot;&gt;override the creation of the MRO&lt;/a&gt; in the metaclass! But the crazy thing here is, we need to implement the C3 linearization algorithm ourselves. Luckily, it’s a simple algorithm:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OptionsMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NamedTupleMeta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# omitted here
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;new_namespace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__dict__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_bases'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bases&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;options_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mcs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Writing to `__bases__` triggers an MRO update. This has to be done after
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# class creation because otherwise we can't access `_bases`.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;options_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__bases__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;options_type&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;default_mro&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# `Options` does not define `_bases`, so we don't do anything about it.
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hasattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_bases'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# `default_mro` should be `[cls, tuple, object]`.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# `c3merge` and `c3mro` are implementations of the C3 linearization
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# algorithm, which unluckily aren't provided as APIs.
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;default_mro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__mro__&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_bases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;default_mro&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default_mro&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;c3merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;Adapted from https://www.python.org/download/releases/2.3/mro/&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Make sure we don't actually mutate anything we are getting as input.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Clear out blank sequences.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Find the first clean head.
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# If this is not a bad head (i.e., not in any other sequence)
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;inconsistent hierarchy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Move the head from the front of all sequences to the end of results.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;del&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Of course, this complex method is when you need to support every general case. Normally you wouldn’t have multiple layers of hierarchy for namedtuples, nor will you mix-in a bunch of other classes such that you need to be careful about the MRO.&lt;/p&gt;

&lt;h2 id=&quot;arbitrary-order-of-fields&quot;&gt;Arbitrary Order of Fields&lt;/h2&gt;

&lt;p&gt;Now, to the final goal which you’ve probably forgotten: removing the constraint on ordering for fields with default values. This is an inherent limit in Python, because method arguments with default values are treated as keyword arguments (captured by &lt;code class=&quot;highlighter-rouge&quot;&gt;**kwargs&lt;/code&gt;), and have to be declared after positional arguments (captured by &lt;code class=&quot;highlighter-rouge&quot;&gt;*args&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;To workaround this, we can declare all arguments of the constructor as keyword-only arguments. For me, not allowing positional arguments is actually better because the order of the fields can be ambiguous when you have multiple base classes.&lt;/p&gt;

&lt;p&gt;How can we programmatically create a method with custom arguments? Let’s dive into the code for &lt;code class=&quot;highlighter-rouge&quot;&gt;collections.namedtuple&lt;/code&gt;, where the magic happens. The code is pretty long so I’m just going to show the relevant parts here. Turns out magic doesn’t exist, everything’s just a hack:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# omitted
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;arg_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;repr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;'&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create all the named tuple methods to be added to the class namespace
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'def __new__(_cls, {arg_list}): return _tuple_new(_cls, ({arg_list}))'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_tuple_new'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tuple_new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__name__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'namedtuple_{typename}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Note: exec() has the side-effect of interning the field names
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__new__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__doc__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Create new instance of {typename}({arg_list})'&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__defaults__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;defaults&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__qualname__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{typename}.__new__'&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# omitted
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;class_namespace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# omitted
&lt;/span&gt;        &lt;span class=&quot;s&quot;&gt;'__new__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# omitted
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# omitted
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Yep, that’s right. The &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; method for the namedtuple is created by &lt;em&gt;writing code as a string and calling &lt;code class=&quot;highlighter-rouge&quot;&gt;exec&lt;/code&gt;&lt;/em&gt;. To be honest, that’s probably the easiest way, and we shouldn’t have gone this far if we need to talk about elegant and readable implementations.&lt;/p&gt;

&lt;p&gt;Following their lead, we can also create our own version of &lt;code class=&quot;highlighter-rouge&quot;&gt;__new__&lt;/code&gt; and overwrite theirs:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        &lt;span class=&quot;c1&quot;&gt;# Rewrite `__new__` method to make all arguments keyword-only.
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This is very hacky code. Do not try this at home.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;arg_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;', '&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# watch out for singleton tuples
&lt;/span&gt;                           &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reordered_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        def __new__(_cls, *args, {arg_list}):
            if len(args) &amp;gt; 0:
                raise TypeError(&quot;Instances of Options class must be created &quot;
                                &quot;with keyword arguments.&quot;)
            return _tuple_new(_cls, ({arg_list}))
        &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# remove incorrect indents in the string
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;new_method_namespace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'_tuple_new'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;s&quot;&gt;'__name__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'namedtuple_{typename}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_method_namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_method_namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__new__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__qualname__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{typename}.__new__'&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__doc__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__doc__&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__annotations__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__annotations__&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__kwdefaults__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                                  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields_with_default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nm_tpl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__new__&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As the comment says, this is very dangerous. Don’t try this at home.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;So far, we’ve delivered our promises. We have a super-enhanced version of namedtuple that supports multiple inheritance and arbitrary field orders. You can find the entire working code in &lt;a href=&quot;https://gist.github.com/huzecong/df51502a8a6ec0bcc0e605a2ce109008&quot;&gt;this GitHub Gist&lt;/a&gt;. It’s a bit long, but you don’t really need to know the details — do the Pythonic thing and treat it as library.&lt;/p&gt;

&lt;p&gt;But you may ask, what’s it useful for?&lt;/p&gt;

&lt;p&gt;I dunno, but it’s a pretty fun journey, isn’t it?&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;There’s actually another level called the meta-metaclass, but that’s rarely useful and I’ve never seen any practical usages. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;This is true for Python 3.6 and lower. Starting from Python 3.7, &lt;code class=&quot;highlighter-rouge&quot;&gt;collections.namedtuple&lt;/code&gt; supports an optional &lt;code class=&quot;highlighter-rouge&quot;&gt;default&lt;/code&gt; argument. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;The MRO (method resolution order) is Python’s answer to the diamond dependency problem in multiple inheritance. When we access a method of an instance, we find the first class in its MRO that defines such method, and returns the method of that class. In the single inheritance case, MRO can be thought of as the list of ancestor classes from the derived class to &lt;code class=&quot;highlighter-rouge&quot;&gt;object&lt;/code&gt;, the base class of everything. Please refer to &lt;a href=&quot;https://en.wikipedia.org/wiki/C3_linearization&quot;&gt;this Wikipedia article&lt;/a&gt; for the algorithm used to compute MRO — the C3 linearization algorithm. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;If you don’t know what this means, you have skipped &lt;a href=&quot;#fn:3&quot;&gt;footnote 3&lt;/a&gt;. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;This is a simplified explanation. &lt;a href=&quot;https://stackoverflow.com/questions/48136025/typeerror-multiple-bases-have-instance-lay-out-conflict&quot;&gt;This StackOverflow answer&lt;/a&gt; gave a pointer to the CPython source code that calculates the best “solid base” for a new class. I’m not familiar with CPython implementations, but my guess is that the solid base is the first class among the MRO with a memory layout different from its base class. Note that adding Python attributes and methods don’t affect the memory layout, because that’s equivalent to adding entries to the &lt;code class=&quot;highlighter-rouge&quot;&gt;__dict__&lt;/code&gt; dictionary.&lt;/p&gt;

      &lt;p&gt;Also note that this is not limited to CPython. Mypy also has &lt;a href=&quot;https://bitbucket.org/pypy/pypy/annotate/default/pypy/objspace/std/typeobject.py?at=default&amp;amp;fileviewer=file-view-default#typeobject.py-1064:1086&quot;&gt;a similar check&lt;/a&gt;. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Zecong Hu</name></author><summary type="html">tl;dr: Inheritance for the Python built-in namedtuple does not work as we expect. This blog post demonstrates how to create a custom namedtuple class that supports meaningful inheritance, and more. I’ve always under-appreciated the Python collections.namedtuple class. For those who are unfamiliar, a namedtuple is a fancier tuple, whose elements can also be accessed as attributes: from collections import namedtuple Point = namedtuple('Point', ('x', 'y')) p = Point(1, 2) print(p.x, p.y) # 1 2 This allows using meaningful names for the elements, rather than having to remember what are stored under each index. What I don’t like about it, however, is the ugly syntax: attribute names are stored as strings, the class name is repeated, and most importantly, refactoring is error-prone, even within powerful IDEs. You can rename class attributes and all the references easily in PyCharm, but you can’t do that for namedtuples. What I wanted was a syntax like that of the C/C++ struct, with a default constructor to assign values to each field. Luckily, this changed in Python 3.6, with the implementation of PEP 526. This version provides typing.NamedTuple, a typed version of namedtuple with a brand new syntax. Instead of the example above, now you can write: from typing import NamedTuple class Point(NamedTuple): x: int y: int = 0 p = Point(1) print(p.x, p.y) # 1 0 This snippet works in exactly the same way, but adds type annotations for each field, and also supports default values (but fields with default values have to follow those without, just as in a function declaration). The syntax is also much more natural (to a former C++ user, at least). But there is still something we can’t do: inheritance. If you ever tried to inherit a namedtuple, you will find that it doesn’t work as you expect. As illustrated in this StackOverflow question, the new attributes added in the subclass doesn’t show up, and you’d have to manually override the constructor, which is kind of against the intention of using namedtuples in the first place. Now, you may think, let’s just hack into the internals and somehow make inheritance work. If you were ever in the mood to peek under the hood of this namedtuple class, you’d find that it’s surprisingly complicated for what seemed like a small and easy piece of functionality. But don’t be afraid, the logic is actually pretty straightforward — it just involves some details of Python’s internal data model. Before we begin, let’s summarize what we want to achieve through this blog post: Make inheritance work for typing.NamedTuple as we expect. Also allow multiple inheritance, if there are no overlaps in field names among the base classes. Remove the constraint on ordering for fields with default values. Instance, Class, and Metaclass Before diving into the actual code, let’s get a couple of concepts clear. We need to know what metaclasses are, and how a class is created, before we can customize that behavior. If you’re not familiar with metaclasses, I recommend reading this wonderful article, which gives a comprehensive explanation of the entire topic. But here, I will try to briefly explain the concepts that will be useful for our goals. Class Instance and the __new__ method We’re all familiar with classes. An instance of a class is what you’d get after calling the class constructor. You might think the Python class constructor is __init__, but that’s not the whole story. When you construct an instance, the __new__ method is first called with the same arguments you pass to __init__. __new__ is responsible for the actually creating an instance of the class, and that instance is then passed into __init__ as the self argument. Note that __new__ is considered a class method (because the instance is not even created at the point of call), so its first argument is cls instead of self. For most classes, the __new__ method just calls the super class __new__, which all traces back to object.__new__(cls). There are special cases though — you can return stuff that is not an instance of type cls (or any of its subclasses), in which case, the __init__ method will not be called. A common use case for this is to entirely disable the behaviors of a class: class ProgressBar: # wrap around an iterable to print a progress bar to terminal def __new__(cls, iterable, enable=True): if not enable: return iterable # progress bar disabled; don't wrap the iterable return super().__new__(cls) def __init__(self, iterable, enable=True): # `enable` must be `True` Metaclass The type built-in function shows the type of objects, e.g., type(2) # int type(3.14) # float type(&quot;wow&quot;) # str type([1, 2, 3, 4]) # list type(MissileWarningSystem(test_run=False)) # &amp;lt;class 'MissileWarningSystem'&amp;gt; But what is the type of a class? Turns out, the type of a class is what we call a metaclass, and the default metaclass (and the base for all metaclasses) is type itself. This reveals a new level of hierarchy1 to us: An instance is an instance of a class. The base for all classes is object. A class is an instance of a metaclass. The base for all metaclasses is type. Just as classes control the behavior of instances, metaclasses control the behavior of classes. When a class is created, the metaclass’ __new__ method is called, and then its __init__ method. What’s different to classes is that you don’t get to customize the arguments received, it’s always like this: class Metaclass(type): def __new__(mcs, typename, bases, namespace): ... mcs is the metaclass instance, in this case, Metaclass or its potential sub-metaclasses (yes, inheritance works here). typename is a str storing the name of the class to create. bases is a tuple of classes, containing the base classes of the class to create. This is what’s in the brackets following the class name on the first line. namespace contains all the class-level attributes, including methods and class attributes. Since type is the default metaclass, we can use the same set of arguments with the type constructor to programmatically create a new class: MyClass = type(&quot;MyClass&quot;, (object,), { &quot;__init__&quot;: lambda self, x: setattr(self, 'x', x), &quot;foo&quot;: lambda self: print(self.x), }) which is equivalent to the canonical class definition syntax: class MyClass(object): def __init__(self, x): self.x = x def foo(self): print(self.x) The NamedTuple Class Now that we’re equipped with the adequate knowledge, the first thing to do is look at how NamedTuple is implemented: def _make_nmtuple(name, types): msg = &quot;NamedTuple('Name', [(f0, t0), (f1, t1), ...]); each t must be a type&quot; types = [(n, _type_check(t, msg)) for n, t in types] nm_tpl = collections.namedtuple(name, [n for n, t in types]) # Prior to PEP 526, only _field_types attribute was assigned. # Now, both __annotations__ and _field_types are used to maintain compatibility. nm_tpl.__annotations__ = nm_tpl._field_types = collections.OrderedDict(types) try: nm_tpl.__module__ = sys._getframe(2).f_globals.get('__name__', '__main__') except (AttributeError, ValueError): pass return nm_tpl class NamedTuple(metaclass=NamedTupleMeta): _root = True def __new__(self, typename, fields=None, **kwargs): if fields is None: fields = kwargs.items() elif kwargs: raise TypeError(&quot;Either list of fields or keywords&quot; &quot; can be provided to NamedTuple, not both&quot;) return _make_nmtuple(typename, fields) The __new__ method here is actually not of our interest — it’s just here to provide an interface similar to namedtuple. The _make_nmtuple function that’s called from __new__ is a utility function that internally constructs a collections.namedtuple and adds type annotations to it. We note that what’s returned from __new__ is not an instance of NamedTuple. We notice that NamedTuple has a metaclass called NamedTupleMeta. The _root attribute here is important for the metaclass, and we’ll talk more of it later. The NamedTupleMeta Metaclass Now let’s take a look at the metaclass code: class NamedTupleMeta(type): def __new__(cls, typename, bases, ns): if ns.get('_root', False): return super().__new__(cls, typename, bases, ns) types = ns.get('__annotations__', {}) nm_tpl = _make_nmtuple(typename, types.items()) defaults = [] defaults_dict = {} for field_name in types: if field_name in ns: default_value = ns[field_name] defaults.append(default_value) defaults_dict[field_name] = default_value elif defaults: raise TypeError(&quot;Non-default namedtuple field {field_name} cannot &quot; &quot;follow default field(s) {default_names}&quot; .format(field_name=field_name, default_names=', '.join(defaults_dict.keys()))) nm_tpl.__new__.__annotations__ = collections.OrderedDict(types) nm_tpl.__new__.__defaults__ = tuple(defaults) nm_tpl._field_defaults = defaults_dict # update from user namespace without overriding special namedtuple attributes for key in ns: if key in _prohibited: raise AttributeError(&quot;Cannot overwrite NamedTuple attribute &quot; + key) elif key not in _special and key not in nm_tpl._fields: setattr(nm_tpl, key, ns[key]) return nm_tpl Now we know why there’s a _root attribute in NamedTuple. The __new__ method of NamedTupleMeta is also called when NamedTuple is created, but we can’t create a collections.namedtuple for that. Thus, we check whether this special _root attribute exists, and skips the following procedure if it does. When a subclass of NamedTuple is created, the __new__ method is also called, but this time the rest of the procedure is also executed. A couple of things happen: Obtain the list of fields in the namedtuple definition. Since we provide an annotation for each field, they’re stored as a dictionary in the __annotations__ special attribute of the class. Create a namedtuple class using _make_nmtuple. Note that the returned namedtuple class does not support default values2 or contain type annotations for the __init__ method. Gather default values from ns (namespace) and set annotations and default argument values for the __new__ method of the namedtuple class. Add other attributes and methods to the created namedtuple class, so additional methods you defined in the NamedTuple subclass can also be called from the returned namedtuple class. Inheritance with a Single Base Class Let’s first think about what we’re trying to accomplish by inheritance: Automatically generate a constructor that sets all fields, including those from the base class. Access methods, attributes, and properties from the base class. Behave correctly in isinstance and issubclass checks. If we don’t care about the latter two, the solution is pretty straightforward: we just gather the fields defined in the derived and base classes, and ask NamedTupleMeta to create a NamedTuple based on these fields. Let’s make a first attempt at implementing this. Out of personal preference, I’m going to call our enhanced namedtuple Options. class OptionsMeta(typing.NamedTupleMeta): def __new__(mcs, typename, bases, namespace): if namespace.get('_root', False): # The created class is `Options`, skip. return super().__new__(mcs, typename, bases, namespace) # Gather fields from annotations of current class and base class. fields = collections.OrderedDict() cur_fields = namespace.get('__annotations__', {}) # We only deal with single inheritance for now. assert len(bases) == 1 base = bases[0] if hasattr(base, '_fields'): # Base class is a concrete namedtuple. for name in base._fields: # Make sure not to overwrite redefined fields. if name not in cur_fields: fields[name] = base.__annotations__[name] if name in base._field_defaults: namespace.setdefault(name, base._field_defaults[name]) fields.update(cur_fields) namespace['__annotations__'] = fields # Let `NamedTupleMeta` create a annotated `namedtuple` for us. # Note that `bases` is not used there so we just set it to `None`. nm_tpl = super().__new__(mcs, typename, None, namespace) return nm_tpl class Options(metaclass=OptionsMeta): _root = True def __new__(cls, *args, **kwargs): if cls is Options: # Prevent instantiation of `Options` class. raise TypeError(&quot;Type Options cannot be instantiated; &quot; &quot;it can be used only as a base class&quot;) return super().__new__(cls, *args, **kwargs) A few things to notice here: We define a new metaclass that inherits NamedTupleMeta so we could call its __new__ method that takes care of everything for us. The Options class doesn’t really do anything, and for simplicity, we forbid directly instantiating it like we could for NamedTuple. annotations must be an OrderedDict because the ordering of fields matter — the order determines the index of the field in the underlying tuple object. Here we put base class fields in front of derived ones, but leave out ones that are redefined. A limitation of this method is that the base class cannot contain fields with default values, unless: a) they’re redefined in the base class, or b) every field in the derived class also comes with a default value. If you understood what we’ve learnt so far, the implementation is actually pretty straightforward. However, we encounter problems when we try to use it in practice: In [1]: class BaseOptions(Options): ...: a: int ...: b: int = 2 In [2]: class DerivedOptions(BaseOptions): ...: b: float = 0.5 ...: c: float = 1.0 In [3]: BaseOptions(1) Out[3]: BaseOptions(a=1, b=2) In [4]: DerivedOptions(2) Out[4]: BaseOptions(a=2, b=2) In [5]: DerivedOptions(2, 0.3, 0.4) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &amp;lt;ipython-input-5-f4db6b51352e&amp;gt; in &amp;lt;module&amp;gt; ----&amp;gt; 1 DerivedOptions(2, 0.3, 0.4) TypeError: __new__() takes from 2 to 3 positional arguments but 4 were given The error message may seem a bit cryptic, but what happens here is that DerivedOptions became an alias for BaseOptions. A deeper investigation shows that OptionsMeta.__new__ is not even called when DerivedOptions is created. How come? The truth is, the nm_tpl returned from the constructor of NamedTuple is of type collections.namedtuple, and of course, the metaclass of which is not OptionsMeta. When inheriting the nm_tpl class, we’re actually inheriting a namedtuple, not an Options subclass. Thus, we must create a new class using the namespace of nm_tpl, and we do so by directly invoking the __new__ method of type, which is NamedTupleMeta’s super class: return type.__new__(mcs, typename, bases + nm_tpl.__bases__, nm_tpl.__dict__.copy()) To explain this method call: type.__new__ will create a class with metaclass set to mcs (which is OptionsMeta in this case). An added benefit here is that we get to set the base class of the created class, in this case, BaseOptions (from bases) and tuple (from nm_tpl.__bases__). Note that it’s essential to keep tuple a base class, because tuple.__new__ is called when we create an instance of this namedtuple, and that requires the class to be a subclass of tuple. If we don’t do that, we get an exception: TypeError: tuple.__new__(DerivedOptions): DerivedOptions is not a subtype of tuple The __dict__ (namespace) of nm_tpl is used as is. We do a copy because type.__new__ requires this namespace dictionary to be writable (of type dict), but __dict__ is not (of type mappingproxy). Since we were able to keep the actual base class (BaseOptions) in the MRO3 of the derived class, Python automatically takes care of the latter two functionalities we wanted to accomplish by inheritance. We can easily verify this: In [1]: class BaseOptions(Options): ...: a: int ...: @property ...: def foo(self): ...: return self.a In [2]: class DerivedOptions(BaseOptions): ...: b :int In [3]: x = DerivedOptions(1, 2) In [4]: x.foo Out[4]: 1 In [5]: isinstance(x, BaseOptions) Out[5]: True Multiple Inheritance The method above also fits for multiple inheritance — we just need to gather fields from all the base classes. However, with multiple bases come other problems that did not exist in the single inheritance case: What if multiple base classes define the same field? Since we’re exploring uncharted waters here, we get to define the behavior, but it has to be intuitive. My opinion is that base classes must not have overlapping fields, unless they’re redefined in the derived class. This guarantees that there aren’t unexpected overwrites of fields by different orderings of the base classes. But of course, if you implement it, you’re free to choose whatever strategy that pleases you. What if a base class is not a subclass of Options? We should still keep it bases so it’s kept in the MRO4, and instances could access its methods. Now, let’s try implementing this OptionsMeta metaclass that supports multiple inheritance: class OptionsMeta(typing.NamedTupleMeta): def __new__(mcs, typename, bases, namespace): if namespace.get('_root', False): # The created class is `Options`, skip. return super().__new__(mcs, typename, bases, namespace) # Gather fields from annotations of current class and base classes. cur_fields = namespace.get('__annotations__', {}) fields = collections.OrderedDict() field_sources = {} # which base class does the name came from field_defaults = {} for base in bases: if issubclass(base, Options) and hasattr(base, '_fields'): # Base class is a concrete subclass of `Options`. for name in base._fields: if name in cur_fields: # Make sure not to overwrite redefined fields. continue if name in fields: # Overlapping field that is not redefined. raise TypeError( f&quot;Base class {base} contains field {name}, which &quot; f&quot;is defined in other base class &quot; f&quot;{field_sources[name]}&quot;) fields[name] = base.__annotations__[name] field_sources[name] = base if name in base._field_defaults: field_defaults[name] = base._field_defaults[name] fields.update(cur_fields) if len(fields) == 0: raise ValueError(&quot;Options class must contain at least one field&quot;) for name, value in field_defaults.items(): namespace.setdefault(name, value) namespace['__annotations__'] = fields # Let `NamedTupleMeta` create a annotated `namedtuple` for us. # Note that `bases` is not used here so we just set it to `None`. print(fields) nm_tpl = super().__new__(mcs, typename, None, namespace) # Wrap the return type in `OptionsMeta` so it can be subclassed. # Also keep base classes of the `namedtuple` (i.e., the `tuple` class), # so we can call `tuple.__new__`. bases = bases + nm_tpl.__bases__ return type.__new__(mcs, typename, bases, nm_tpl.__dict__.copy()) This works great when we inherit from non-Options classes, as we can see from these examples: In [1]: class BaseOptions(Options): ...: a: int ...: @property ...: def foo(self): ...: return self.a In [2]: class Mixin: ...: def bar(self): ...: return self.a + self.b In [3]: class DerivedOptions(BaseOptions, Mixin): ...: b :int In [4]: x = DerivedOptions(1, 2) In [5]: x.foo Out[5]: 1 In [6]: x.bar() Out[6]: 3 In [7]: isinstance(x, BaseOptions) Out[7]: True In [8]: isinstance(x, Mixin) Out[8]: True But when we try to inherit from two Options subclasses, something weird happens: In [1]: class OptionsA(Options): ...: a: int ...: b: int In [2]: class OptionsB(Options): ...: c: int ...: d: int In [3]: class MergedOptions(OptionsA, OptionsB): ...: pass --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &amp;lt;ipython-input-3-51d384fffb01&amp;gt; in &amp;lt;module&amp;gt; ----&amp;gt; 1 class MergedOptions(OptionsA, OptionsB): 2 pass 3 &amp;lt;ipython-input-3-5ff213f4a3b5&amp;gt; in __new__(mcs, typename, bases, namespace) 43 # so we can call `tuple.__new__`. 44 bases = bases + nm_tpl.__bases__ ---&amp;gt; 45 return type.__new__(mcs, typename, bases, nm_tpl.__dict__.copy()) 46 TypeError: multiple bases have instance lay-out conflict Now this is something new, an error message I’ve never seen before. It turns out that I cannot inherit from multiple built-in classes that don’t go together at the C level5, in this case, two different subclasses of tuple. I can see why this is a problem: such built-in types are implemented in C, with fixed memory layouts and implementations for special methods. If we can’t create the type with our bases, how about modifying the bases after creation? It turns out you can’t do that either: &amp;lt;ipython-input-118-d6cd3ab74257&amp;gt; in __new__(mcs, typename, bases, namespace) 43 # so we can call `tuple.__new__`. 44 options_type = type.__new__(mcs, typename, nm_tpl.__bases__, nm_tpl.__dict__.copy()) ---&amp;gt; 45 options_type.__bases__ = bases 46 return options_type 47 TypeError: __bases__ assignment: 'Options' object layout differs from 'tuple' It seems that we’re out of luck. But actually, here’s some less known evil: you can override the creation of the MRO in the metaclass! But the crazy thing here is, we need to implement the C3 linearization algorithm ourselves. Luckily, it’s a simple algorithm: class OptionsMeta(typing.NamedTupleMeta): def __new__(mcs, typename, bases, namespace): ... # omitted here new_namespace = nm_tpl.__dict__.copy() new_namespace['_bases'] = bases options_type = type.__new__(mcs, typename, nm_tpl.__bases__, new_namespace) # Writing to `__bases__` triggers an MRO update. This has to be done after # class creation because otherwise we can't access `_bases`. options_type.__bases__ = tuple(nm_tpl.__bases__) return options_type def mro(cls): default_mro = super().mro() # `Options` does not define `_bases`, so we don't do anything about it. if hasattr(cls, '_bases'): # `default_mro` should be `[cls, tuple, object]`. # `c3merge` and `c3mro` are implementations of the C3 linearization # algorithm, which unluckily aren't provided as APIs. return c3merge([ default_mro[:1], *[base.__mro__ for base in cls._bases], default_mro[1:]]) return default_mro def c3merge(sequences): r&quot;&quot;&quot;Adapted from https://www.python.org/download/releases/2.3/mro/&quot;&quot;&quot; # Make sure we don't actually mutate anything we are getting as input. sequences = [list(x) for x in sequences] result = [] while True: # Clear out blank sequences. sequences = [x for x in sequences if x] if not sequences: return result # Find the first clean head. for seq in sequences: head = seq[0] # If this is not a bad head (i.e., not in any other sequence) if not any(head in s[1:] for s in sequences): break else: raise Error(&quot;inconsistent hierarchy&quot;) # Move the head from the front of all sequences to the end of results. result.append(head) for seq in sequences: if seq[0] == head: del seq[0] return result Of course, this complex method is when you need to support every general case. Normally you wouldn’t have multiple layers of hierarchy for namedtuples, nor will you mix-in a bunch of other classes such that you need to be careful about the MRO. Arbitrary Order of Fields Now, to the final goal which you’ve probably forgotten: removing the constraint on ordering for fields with default values. This is an inherent limit in Python, because method arguments with default values are treated as keyword arguments (captured by **kwargs), and have to be declared after positional arguments (captured by *args). To workaround this, we can declare all arguments of the constructor as keyword-only arguments. For me, not allowing positional arguments is actually better because the order of the fields can be ambiguous when you have multiple base classes. How can we programmatically create a method with custom arguments? Let’s dive into the code for collections.namedtuple, where the magic happens. The code is pretty long so I’m just going to show the relevant parts here. Turns out magic doesn’t exist, everything’s just a hack: ... # omitted arg_list = repr(field_names).replace(&quot;'&quot;, &quot;&quot;)[1:-1] # Create all the named tuple methods to be added to the class namespace s = f'def __new__(_cls, {arg_list}): return _tuple_new(_cls, ({arg_list}))' namespace = {'_tuple_new': tuple_new, '__name__': f'namedtuple_{typename}'} # Note: exec() has the side-effect of interning the field names exec(s, namespace) __new__ = namespace['__new__'] __new__.__doc__ = f'Create new instance of {typename}({arg_list})' if defaults is not None: __new__.__defaults__ = defaults __new__.__qualname__ = f'{typename}.__new__' ... # omitted class_namespace = { ... # omitted '__new__': __new__, } ... # omitted result = type(typename, (tuple,), class_namespace) ... # omitted Yep, that’s right. The __new__ method for the namedtuple is created by writing code as a string and calling exec. To be honest, that’s probably the easiest way, and we shouldn’t have gone this far if we need to talk about elegant and readable implementations. Following their lead, we can also create our own version of __new__ and overwrite theirs: # Rewrite `__new__` method to make all arguments keyword-only. # This is very hacky code. Do not try this at home. arg_list = ''.join(name + ', ' # watch out for singleton tuples for name in reordered_fields) s = (f&quot;&quot;&quot; def __new__(_cls, *args, {arg_list}): if len(args) &amp;gt; 0: raise TypeError(&quot;Instances of Options class must be created &quot; &quot;with keyword arguments.&quot;) return _tuple_new(_cls, ({arg_list})) &quot;&quot;&quot;).strip() # remove incorrect indents in the string new_method_namespace = {'_tuple_new': tuple.__new__, '__name__': f'namedtuple_{typename}'} exec(s, new_method_namespace) __new__ = new_method_namespace['__new__'] __new__.__qualname__ = f'{typename}.__new__' __new__.__doc__ = nm_tpl.__new__.__doc__ __new__.__annotations__ = nm_tpl.__new__.__annotations__ __new__.__kwdefaults__ = {name: namespace[name] for name in fields_with_default} nm_tpl.__new__ = __new__ As the comment says, this is very dangerous. Don’t try this at home. Summary So far, we’ve delivered our promises. We have a super-enhanced version of namedtuple that supports multiple inheritance and arbitrary field orders. You can find the entire working code in this GitHub Gist. It’s a bit long, but you don’t really need to know the details — do the Pythonic thing and treat it as library. But you may ask, what’s it useful for? I dunno, but it’s a pretty fun journey, isn’t it? Footnotes There’s actually another level called the meta-metaclass, but that’s rarely useful and I’ve never seen any practical usages. &amp;#8617; This is true for Python 3.6 and lower. Starting from Python 3.7, collections.namedtuple supports an optional default argument. &amp;#8617; The MRO (method resolution order) is Python’s answer to the diamond dependency problem in multiple inheritance. When we access a method of an instance, we find the first class in its MRO that defines such method, and returns the method of that class. In the single inheritance case, MRO can be thought of as the list of ancestor classes from the derived class to object, the base class of everything. Please refer to this Wikipedia article for the algorithm used to compute MRO — the C3 linearization algorithm. &amp;#8617; If you don’t know what this means, you have skipped footnote 3. &amp;#8617; This is a simplified explanation. This StackOverflow answer gave a pointer to the CPython source code that calculates the best “solid base” for a new class. I’m not familiar with CPython implementations, but my guess is that the solid base is the first class among the MRO with a memory layout different from its base class. Note that adding Python attributes and methods don’t affect the memory layout, because that’s equivalent to adding entries to the __dict__ dictionary. Also note that this is not limited to CPython. Mypy also has a similar check. &amp;#8617;</summary></entry><entry><title type="html">大四上总结</title><link href="http://zecong.hu/2018/07/19/my-7th-semester-in-college/" rel="alternate" type="text/html" title="大四上总结" /><published>2018-07-19T03:20:00+00:00</published><updated>2018-07-19T03:20:00+00:00</updated><id>http://zecong.hu/2018/07/19/my-7th-semester-in-college</id><content type="html" xml:base="http://zecong.hu/2018/07/19/my-7th-semester-in-college/">&lt;p&gt;大四了。不知不觉间就成了园子里最年长的本科生。&lt;/p&gt;

&lt;p&gt;大一的时候看着系里的学长，觉得他们都好厉害，厉害得遥不可及。等自己到了大四，发现身边这群逗比就是现在学弟学妹眼中厉害的人。&lt;/p&gt;

&lt;p&gt;到底是采样偏差，还是我们真的变得厉害了，只是自己没有觉得呢？&lt;/p&gt;

&lt;p&gt;或许二者皆有吧。&lt;/p&gt;

&lt;p&gt;言归正传，这一学期我不在学校。是的。&lt;/p&gt;

&lt;p&gt;但我们还是从暑研谈起吧。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;暑研&quot;&gt;暑研&lt;/h2&gt;

&lt;p&gt;这一年里改变了我人生轨迹的一件事，就是提交了 CMU 暑研的申请。&lt;/p&gt;

&lt;p&gt;得到了暑研的机会之后，填各种各样的材料、参加替小学期的答辩、办签证、租房子，这些琐事占据了大三下的相当一部分时间。历尽千辛万苦，终于在6月27号搭上了飞往纽约的飞机，在纽瓦克转机一整晚，到了匹茨堡。&lt;/p&gt;

&lt;p&gt;暑研的生活其实并不单调。我和李北辰合租了 Shadyside 的一间还不错的公寓，并在石头剪刀布的战斗中获胜，得到了较大的房间。本想趁机学学做菜，但在意识到自己厨艺堪忧，以及买厨具调料太不划算之后，打消了这个想法。工作日的时候，没有工位的几人（我、殷老师、李林翼、丁豪，和两位到现在也不知道名字的北大同学）就在 GHC 6111 &lt;del&gt;摸鱼&lt;/del&gt;干活，而我工作日的起床时间也越来越向清华作息看齐。周末的时候，大家就一块出去浪。认识了这么一群玩得来的小伙伴，大概是很棒的收获了。&lt;/p&gt;

&lt;p&gt;科研方面，由于一些机缘巧合选择了 Graham Neubig 作为导师，后来才知道他是 LTI 最火的教授之一。Graham 一开始给的 idea 是把后缀数据结构与神经网络结合，提升 language model 的效果（事实上一开始说的是 memory network，但到最后和这玩意一点关系也没有）。头两周还是在入门 NLP 和炼丹，之后开始看论文并实现模型。到最后做出来的东西其实就是一个有俩 predictor 的 Latent Predictor Network，一个做 span-level 的 prediction，一个做 character-level 的。结果非常平凡，原因有二：一方面模型确实能力有限，在增强表达能力的同时极大增加了计算代价；另一方面自己也没有足够的调参经验。&lt;/p&gt;

&lt;p&gt;对我来说最大的收获应该是入了 NLP 的门，并发现了自己对科研的兴趣。CMU 的环境很好，实验室里的其他人也都很厉害。正是这次暑研，让我决定了毕业之后要出国读研。&lt;/p&gt;

&lt;h2 id=&quot;暑研contd&quot;&gt;暑研（cont’d）&lt;/h2&gt;

&lt;p&gt;本来故事到这里就该结束了。我原本的计划是，大四上一边在刘导的实验室干活，一边去 MSRA 打工。实验室的学姐建议我，与其去 MSRA，不如申请留在 CMU 接着干。&lt;/p&gt;

&lt;p&gt;我觉得很有道理，也就这么做了。为此我做了一系列准备，包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;申请 DS-2019 的延期：&lt;/strong&gt;找导师和 CMU 的 OIE 签字填表。为此还需要一份全新的财务证明原件，是从家里寄过来的。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;找新的住处：&lt;/strong&gt;暑假住的地方是一个学长的房子，开学之后他回来了，我得换地方住。然而开学之后房源更紧张，而且大多数不接受短租。我在 Craiglist 上整整刷了一个星期，最后找到一个愿意接受短租的房间，是一个本地老爷爷房子里的一个小房间，合租的其他三人都是 CMU 的研究生。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;假装我还在清华：&lt;/strong&gt;正常的操作应当是休学一学期，但对我来说行不通，因为我还有课程没修完，休学意味着延毕。所以我必须按照正常流程注册，并伪装出我还在学校的样子。这涉及到了很多问题，包括：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;注册：&lt;/strong&gt;开学的时候我是回了一趟国的。原因有三，首先是本来就买了机票，不飞也没法退；其次是注册需要刷脸，自己刷保险一点（本来还想找在 MSRA 实习的上交同学来代我的，就算被抓到他也不会有事）；最后是想找学校的老师面谈一下推荐信的事情。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;日常活动：&lt;/strong&gt;我把校园卡留给了室友，让他们帮我没事刷刷门禁然后吃吃饭。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;体测：&lt;/strong&gt;这个是最麻烦的。幸好我有一位和我身高体重比较接近的学弟，于是拜托他帮我走完了流程。1000米直接弃跑了，总分及格了就好。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;课程和作业：&lt;/strong&gt;我这学期只有三门课：专业课媒体计算、双学位课商业伦理，以及一个叫绿色制造与可持续发展的文核。专业课不去上也没事；双学位课是后半学期的，找了同学帮我签到；最麻烦的是这个文核。这个课和环境保护的文核不太一样，需要有小组作业。还好我不是组长，最后也就和大家远程合作完成了作业。可没想到的是，组里其它的大四同学这么有干劲，作业被评为了优秀作业，需要进行展示。最后又是拜托那位体测学弟帮我做了展示。现在我大概欠他五顿饭。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;必须要强调的是，这个方法是有风险的：根据学生手册，连续6周不在学校会直接被开除。虽然实际上，保密工作做得好也不会有人知道，而且同学、辅导员，和（部分）老师总的来说还是支持的。在这里必须要感谢他们，要是没有他们我可能就凉了。&lt;/p&gt;

&lt;h3 id=&quot;在-cmu-的三个月&quot;&gt;在 CMU 的三个月&lt;/h3&gt;

&lt;p&gt;总算是留在了 CMU 继续干活。科研方面懒得细讲，做的大概是 compositional representation 的工作，结果依然很平凡。主要想说说生活方面的事情。&lt;/p&gt;

&lt;p&gt;和暑研不一样的是，小伙伴们都回国了。头几个星期大概是因为干劲比较足，还没什么感觉。接下来的两个多月里，我体会了一股前所未有的寂寞感和焦虑感。在学校的时候还好，因为大部分时间是和实验室的中国学长学姐在一块。在家里的时候，我基本上都是把自己闷在自己的小房间里，刷B站、打游戏，或者肝实验。也不止我一个人这样，另一位只身一人在 Berkeley 的同学也和我差不多。时间和国内不同步，平常和别人在网上聊天也不多。身边的人讲着另一种我无法熟练运用和表达的语言，自然感到了寂寞。&lt;/p&gt;

&lt;p&gt;焦虑则来自两方面，一方面是科研没有好结果，另一方面是申请比想象中的麻烦。在这两件事都没干完的时候，就会陷入一种不知道该先干哪个，哪个也不想干的消极状态。&lt;/p&gt;

&lt;p&gt;日常基本上就是学校和家两点一线的生活，不去学校的时候会在家附近吃顿好的。但到后面越来越懒，加之起床时间太晚甚至错过（午）饭点，也开始经常少吃一顿饭，一周可能有两三天不吃午饭，只有晚上一顿。晚上也睡不着，躺在床上也不干正事刷手机，结果也只能晚起。可想而知这样活干不完，于是又得靠组会前 rush。这种不健康的生活方式从第二个月开始逐渐加剧，持续到快回来的时候。&lt;/p&gt;

&lt;p&gt;等熬过了12月的申请 DDL 之后，到回家也只有一周左右的时间了。这一段时间其实是最轻松的：申请能做的都做了，科研反正也就这样了。没有了焦虑，其实也就没那么寂寞了，剩下的只有似箭的归心。&lt;/p&gt;

&lt;h3 id=&quot;回国后的一个月&quot;&gt;回国后的一个月&lt;/h3&gt;

&lt;p&gt;终于在12月20号回到了北京。一下飞机我就约了小伙伴们晚上吃火锅。不得不说，还是中华美食文化博大精深。&lt;/p&gt;

&lt;p&gt;学期剩下的日子其实很清闲了。看学生节、出去吃饭、看电影，还在新年的第一天脱了单。&lt;/p&gt;

&lt;p&gt;反正，就是幸福且惬意的时光了。&lt;/p&gt;

&lt;h2 id=&quot;申请&quot;&gt;申请&lt;/h2&gt;

&lt;p&gt;作为大四上的重头戏，有必要单独开一章讲讲申请。&lt;/p&gt;

&lt;p&gt;我没有找留学机构。留学机构能提供的服务无非是：帮着收集信息、填表、改文书。信息方面，反正也不准备申请太多项目，自己看也不会花太多时间；填表就更是了；文书的话，留学机构的人不见得写得比我好。当然，最重要的原因还是，这些机构真的太贵了。&lt;/p&gt;

&lt;h3 id=&quot;项目&quot;&gt;项目&lt;/h3&gt;

&lt;p&gt;首先，我觉得自己想出国读书，主要原因是想接着做一做科研。因此，我基本上只考虑了 CS 方向的 PhD 和 MS 的项目（没有考虑 MEng），并且优先了 ML/NLP 排名靠前的学校。&lt;/p&gt;

&lt;p&gt;我一共申请了11个学校：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stanford MS：斯坦福是所有人的彩票校，我自然也想碰碰运气。&lt;/li&gt;
  &lt;li&gt;CMU LTI PhD/MS, MCDS：LTI 的 MS 项目其实是我的 dream program，在 CMU 实验室的学长学姐也是这个项目的。它的好处是：大概率可以拿到 funding，而且之后可以申请转 PhD。这个项目是 PhD 和 MS 一起申请的，不过直接录为 PhD 的概率极低。MCDS 其实算是 MEng 了，但是是评价比较高，课业压力比较重的一个项目，大概是能有收获的。&lt;/li&gt;
  &lt;li&gt;UC Berkeley PhD/MS：一个事实是，像这种 PhD 和 MS 混申的项目，MS 的名额也非常少，所以这也是彩票。&lt;/li&gt;
  &lt;li&gt;Cornell MS：这是比较特殊的一个项目，因为 Cornell（包括 Cornell Tech）主打的项目其实是 PhD 和 MEng，这个 MS 项目的规模非常小（约5人），其目的在于填补助教的空缺。因此，项目对英语要求非常高（托福口语≥28，感受一下），而且学生会被当成PhD培养，似乎还有 funding。这也是我挺想去的项目。&lt;/li&gt;
  &lt;li&gt;U Washington PhD：UW 是一所 NLP 很强的学校。之所以申 PhD 是因为没有 MS 项目。&lt;/li&gt;
  &lt;li&gt;NYU PhD：同上。&lt;/li&gt;
  &lt;li&gt;Harvard PhD：同上。但哈佛其实在 NLP 这块并不牛逼，所以也是想试一试。&lt;/li&gt;
  &lt;li&gt;UIUC MS：这是一个评价不错的 general CS MS 项目。导师其实不建议我申请 UIUC，因为这所学校厉害的是系统方向而非 ML。但总之，还是试了一下。&lt;/li&gt;
  &lt;li&gt;Princeton MS：普林斯顿在理论方向很牛逼，我现在也想不通当时为什么申了这个学校。&lt;/li&gt;
  &lt;li&gt;JHU PhD：JHU 位于民风淳朴的巴尔的摩。它最厉害的两个方向是医学和 NLP，所以自然也想试一试。但其实，因为巴尔的摩过于民风淳朴，我也不是很想去。&lt;/li&gt;
  &lt;li&gt;Columbia PhD/MS：哥大的 MS 被大家戏称保底项目，但鉴于今年竞争极为激烈，能不能保到底也是个问题。总之试了试。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;材料&quot;&gt;材料&lt;/h3&gt;

&lt;p&gt;首先是&lt;strong&gt;英语&lt;/strong&gt;。自夸一下，我英语还是不错的，所以准备托福和 GRE 基本上没花时间。最后托福116（口语29），GRE 170/163/3.5。一个建议是能在国外考就在国外考，原因有三：一是价格会稍微便宜一些，二是考位远多于国内，三是我这辈子都不想再用国内的傻逼报名系统了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;推荐信&lt;/strong&gt;的话，因为我科研经历是明显不够的，因此只能拿工程经验来凑。我找了好几个老师：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;我暑研的导师 Graham。他对我的评价还不错，因此他的信是最有价值的。&lt;/li&gt;
  &lt;li&gt;我在清华的导师刘知远老师。比较尴尬的是，我在刘导实验室做的是工程，虽然做得还行，但和科研不怎么沾边。&lt;/li&gt;
  &lt;li&gt;教授软件工程课的白晓颖老师。我提前一年修了这门课，而且取得了非常好的成绩。因此这封信也只能突出工程和团队领导力。&lt;/li&gt;
  &lt;li&gt;班主任崔鹏老师。其实我和崔老师打交道不多，找崔老师要推荐信主要是为了 Cornell 的项目：我得证明自己与人沟通和表达的能力不错，曾经当过助教、班干部等等。&lt;/li&gt;
  &lt;li&gt;教授数字逻辑设计的全成斌老师。这主要是为了吹嘘一下之前 FPGA 的比赛。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;之所以找了5位老师，是因为怕被放鸽子，而且不同的项目想突出不同方面的能力。当然，Graham 的信是每个学校都发了的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SOP&lt;/strong&gt; 和 &lt;strong&gt;CV&lt;/strong&gt; 参考了实验室学长学姐的模板，他们写得都非常好。我对着好几份 SOP 疯狂 overfit，然后写出了我自己的版本。前后改了很多遍，每个学校也都插了一两段不同的信息。&lt;/p&gt;

&lt;h3 id=&quot;offer&quot;&gt;Offer&lt;/h3&gt;

&lt;p&gt;最后拿到了三个offer：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CMU LTI MS&lt;/li&gt;
  &lt;li&gt;UIUC MS&lt;/li&gt;
  &lt;li&gt;Columbia MS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CMU 的 offer 是出的最早的，所以我在等结果的时候完全没有心理压力。&lt;/p&gt;

&lt;p&gt;UIUC 的 offer 比较有意思，我先是收到了他们的拒信，然后过了几天 Jiawei Han（群）发了邮件说祝贺你被录取，然后问对他的实验室感不感兴趣。我说我还挺有兴趣的，可我没被录取。后来他告诉我，似乎是 admission 那边没沟通好，我其实是被录取了的。&lt;/p&gt;

&lt;p&gt;哥大的也比较好玩。当时已经是4月份了，身边陆续有人拿到了哥大 MS 的 offer，然而我还没有一点消息。一天收到邮件，告诉我 PhD 没录上，如果想试试MS的话就再写一份介绍。我回复说不用考虑我了谢谢，然后过几天收到了 offer，过了一会又收到邮件说以为我是要申 MS 的，无视前一封邮件就好。&lt;/p&gt;

&lt;p&gt;理所当然，最后我选择了 CMU。&lt;/p&gt;

&lt;h2 id=&quot;学习&quot;&gt;学习&lt;/h2&gt;

&lt;p&gt;即便人不在学校，也坚持上了三门课&lt;del&gt;，简直是爱学习的典范&lt;/del&gt;。&lt;/p&gt;

&lt;h4 id=&quot;媒体计算&quot;&gt;媒体计算&lt;/h4&gt;

&lt;p&gt;之所以留下了这门课而退了其它专业课，是因为这门课打分只看大作业，所以可以回来做。&lt;/p&gt;

&lt;p&gt;但还是开始得晚了。写的时候才意识到 CG 领域发个论文有多不容易：代码太难写了。尤其是需要用户交互的，还得有 GUI。我花了好些时间捡起了大一学的 Qt，然后做了一个看着还挺炫酷（但不算分）的 GUI。最后只实现了泊松融合和 PatchMatch，给分很差。&lt;/p&gt;

&lt;h4 id=&quot;商业伦理&quot;&gt;商业伦理&lt;/h4&gt;

&lt;p&gt;&lt;del&gt;双学位&lt;/del&gt;辅修的最后一门课。和之前的商法课程是同一位老师，课程形式也是上课签到然后写感悟。于是我轮流拜托各位亲朋好友帮忙签到。&lt;/p&gt;

&lt;h4 id=&quot;绿色制造与可持续发展&quot;&gt;绿色制造与可持续发展&lt;/h4&gt;

&lt;p&gt;其实我对这门课一点兴趣都没有，可它是1分的文核。我原本以为这是和环境保护差不多的签到课，没想到还得写报告。课程要求每个小组设想一种绿色节能的装置，然后写成报告。我自己随便写了一段，大意是我们搞一个中央空调，根据天气、室温、用户习惯自动调整，完了还能炼炼丹。没想到同为大四的其它组员非常认真，写了很长的报告还画了图。最后我们组被评为优秀，需要做课堂展示。&lt;/p&gt;

&lt;p&gt;我只好告诉他们我不在学校，然后找学弟代为展示。&lt;/p&gt;

&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;这篇文章的前一半是和大三下总结一起写的，不知是否能看出风格上的差异。毕竟，写完毕设论文之后讲话都变得啰嗦了起来。&lt;/p&gt;

&lt;p&gt;大四上对我来说就像是不存在的一个学期一样。在 CMU 的生活两点一线，我甚至没法区分10月和11月发生的事情；回到清华后则开始了养老生活，回忆起来也不觉得是学期中发生的事情。&lt;/p&gt;

&lt;p&gt;当然，也只有事后的现在才能这么轻描淡写地概括这半年。&lt;/p&gt;

&lt;p&gt;一如既往啰嗦了这么多。感谢你的阅读。&lt;/p&gt;</content><author><name>Zecong Hu</name></author><summary type="html">大四了。不知不觉间就成了园子里最年长的本科生。 大一的时候看着系里的学长，觉得他们都好厉害，厉害得遥不可及。等自己到了大四，发现身边这群逗比就是现在学弟学妹眼中厉害的人。 到底是采样偏差，还是我们真的变得厉害了，只是自己没有觉得呢？ 或许二者皆有吧。 言归正传，这一学期我不在学校。是的。 但我们还是从暑研谈起吧。</summary></entry><entry><title type="html">大三下总结</title><link href="http://zecong.hu/2018/02/24/my-6th-semester-in-college/" rel="alternate" type="text/html" title="大三下总结" /><published>2018-02-24T04:58:00+00:00</published><updated>2018-02-24T04:58:00+00:00</updated><id>http://zecong.hu/2018/02/24/my-6th-semester-in-college</id><content type="html" xml:base="http://zecong.hu/2018/02/24/my-6th-semester-in-college/">&lt;p&gt;这份总结实在是拖得太久了。&lt;/p&gt;

&lt;p&gt;按理说暑假就应该写的，以暑研为借口拖到了大四上开学，又以没回国为由拖到了寒假，又以科研为由拖到了开学。再拖下去就要毕业了。&lt;/p&gt;

&lt;p&gt;不过这一学期也是比较清闲的一学期。整个学期花时间最多的一件事是谈恋爱，但已经是回忆了，故此处不表。正事方面，课程不多，实验室搬砖每一到两周肝一晚上，社工处于半退休状态。半年后的今天回忆起来，竟然都想不到什么印象深刻的事情。&lt;/p&gt;

&lt;p&gt;也好，那就简单回顾一下吧。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;出路&quot;&gt;出路&lt;/h2&gt;

&lt;p&gt;日语里“&lt;ruby&gt;&lt;rb&gt;進路&lt;/rb&gt;&lt;rt&gt;しんろ&lt;/rt&gt;&lt;rb&gt;調査&lt;/rb&gt;&lt;rt&gt;ちょうさ&lt;/rt&gt;&lt;/ruby&gt;”的“&lt;ruby&gt;&lt;rb&gt;進路&lt;/rb&gt;&lt;rt&gt;しんろ&lt;/rt&gt;&lt;/ruby&gt;”，翻译过来就是出路。从大三上开始，关于未来的思考就成了贯穿学校生活的重要主题。无论是进校就目标坚定的人，还是头两年根本没往这方面想的人（我），都开始思考或者重新思考起这个问题来了。&lt;/p&gt;

&lt;p&gt;说来也是有趣，入学的时候我是非常坚定的工作党，认为读研没用，不如找工作，而且坚决不出国；大三上结束，我觉得好像读个研也是有意义的，不如试一试；而到了写总结的现在，我已经在等国外 MS 项目的申请结果了。看着我之前写的总结，感觉非常打脸。不过可能成长的一部分就是打脸吧。&lt;/p&gt;

&lt;p&gt;这个转变的过程也蛮有趣的。从大三上中旬到大三下中旬，我可以说是在恶补之前的空缺，尝试申请了不少项目。下面分门别类讲述一下。&lt;/p&gt;

&lt;h3 id=&quot;实验室本校读研&quot;&gt;实验室：本校读研&lt;/h3&gt;

&lt;p&gt;一开始只是觉得，毕业直接工作的话，就要开始操心房子问题、税率问题，以及生活中的柴米油盐。这样的转变似乎太快，让我有点措手不及；加之还没实习过，不知道工作到底是怎样的状态，于是想，说不定读研可以再缓三年。并不是觉得读研有多少用，而是单纯想要先逃避问题。&lt;/p&gt;

&lt;p&gt;之后和郭志芃聊，他强烈建议我读研，论点很传统，就是硕士文凭能让自己将来有怎样的优势。确实是有道理，于是我想，不管怎么样先去实验室感受一下吧。对，截至大三上，我既没实习又没进实验室，不知道都干了些什么。&lt;/p&gt;

&lt;p&gt;于是大三上期末的时候我找到了刘知远老师，进了他的实验室。我表达的想法是，我想做偏工程一点的东西，因为当时觉得自己对科研完全提不起劲。刘导便给了我一个改版“微博关键词”网站的锅，本质上就是个小软工。我想，也不错，感觉“不难.jpg”，于是就接下了锅，结果任务量超乎想象，这个后文再说。&lt;/p&gt;

&lt;h3 id=&quot;北美谷歌实习出国工作&quot;&gt;北美谷歌实习：出国工作&lt;/h3&gt;

&lt;p&gt;大三寒假的时候面了北美谷歌的暑期实习。这个是在10月份左右找学长帮忙内推的，理由是大三暑假不要浪费了，既然不出国那就不做暑研了，不如找个实习吧。之前也听说过有同学和学长去过谷歌在国外的办公室实习，于是也试了试。面试以算法为主，要求在 Google docs 上写代码。挺简单的，不过听说难度的方差比较大，或许也是我比较幸运。&lt;/p&gt;

&lt;p&gt;面试一周后就被告知通过了面试。当时很激动，上网查了一下谷歌工资有多少，结果也超乎想象。平均下来湾区的正式员工一年有大概12万刀的收入。当然，当时还不知道生活成本和税有多高，总之就是觉得这是一大笔钱，大概能比在国内多不少，于是萌生了毕业去国外工作的想法。不过，也就是想想而已。&lt;/p&gt;

&lt;p&gt;第一轮面试通过后就进入了匹配项目的阶段。由于实习没法替代你们系的&lt;ruby&gt;&lt;rb&gt;暑假&lt;/rb&gt;&lt;rt&gt;傻逼&lt;/rt&gt;&lt;/ruby&gt;小学期，我必须在暑假第6周再过去实习，开学一个月之后再回来。这个时间安排很不好，一方面我需要和系里请假，另一方面也和公司的秋招有部分重合，所以在共八个星期的匹配阶段中，头六个星期我都一点消息也没有。最后 Chrome OS 组的一位学姐要了我，项目是用炼丹的方法根据 commit log 和 CI log 定位可能存在错误的代码文件。可能不算是最好的选择，但其实也还挺有意思的。&lt;/p&gt;

&lt;h3 id=&quot;cmu暑研出国读研&quot;&gt;CMU暑研：出国读研&lt;/h3&gt;

&lt;p&gt;与此同时，我还了解到系里有一个跟 CMU 合作的暑研项目，大概有8个名额。当时黄老板正在进行艰苦卓绝的套磁，不知怎的，我也就觉得出去暑研可能也不错。因为嫌套磁太麻烦，我就不抱希望地申请了 CMU 的这个项目，想着反正也有谷歌实习保底。结果还真的申请上了。&lt;/p&gt;

&lt;p&gt;有了这个项目之后，实习自然就鸽了，毕竟还是 CMU 嘛。申请的时候需要选出想 match 的导师，因为我在刘知远的实验室，于是在 LTI 的 directory 里翻，瞎选了一些 NLP 方向的导师，随便排了个序。其中放在最后的是一位名叫 Graham Neubig 的 AP，是一位美国人，但在日本呆了6年，日语和 native speaker 一样，让我比较感兴趣。最后和我匹配上的也正是这位教授，想来还是挺巧的。&lt;/p&gt;

&lt;p&gt;之后就是各种繁杂的文件和手续了。再之后就是暑研了。暑研期间的事情就留到下个学期总结再提，总之就是我发现我其实对科研也还挺感兴趣的，而且也比较喜欢的 CMU 的人和环境。&lt;/p&gt;

&lt;p&gt;至此，毕业的三种主流出路我都依次考虑了一遍，最后的决定就是出国读研。&lt;/p&gt;

&lt;h2 id=&quot;社工&quot;&gt;社工&lt;/h2&gt;

&lt;p&gt;社工就没什么好说的了。本学期的我还是任着两个职位：文艺部的部长和算协的（常务）副主席。&lt;/p&gt;

&lt;p&gt;在文艺部基本上是尸位素餐，和去年一样，系歌赛交给了有留部意愿的大二小盆友，我就是每周参加一下例会，最后一起聚了个餐而已。&lt;/p&gt;

&lt;p&gt;算协这学期事还不少。上学期总结里似乎没有提，本来上学期计划办一个蛤克松的，但因为大家都很懈怠，最后告吹了。于是这一学期就说得把校赛给办好，最后的确办得还不错。因为&lt;del&gt;当了领导&lt;/del&gt;了，所以大部分事情也不是我在操行，大家都干的很不错。&lt;/p&gt;

&lt;h2 id=&quot;学习&quot;&gt;学习&lt;/h2&gt;

&lt;p&gt;这学期其实课也不少，但以非硬核专业课为主，很多任务量也不大，所以花时间不多。加之中期退了整整12学分的课，“变成了当初最讨厌的样子”，所以更加轻松了。因此本学期成绩也不错，算是达成了最开始的目标，把 GPA 从89.4拉到89.5，四舍五入好看。&lt;/p&gt;

&lt;h3 id=&quot;数字图像处理&quot;&gt;数字图像处理&lt;/h3&gt;

&lt;p&gt;92分。算是花的时间最多的课，也是唯一愿意去上的课。内容还比较有意思，主要是介绍前人留下的靠人类智慧创造出的优美 CV 算法。最后大作业是个炼丹任务，年级里各位炼金术士各显神通，结果全都被天龙用朴素方法干翻在地。&lt;/p&gt;

&lt;h3 id=&quot;数据挖掘&quot;&gt;数据挖掘&lt;/h3&gt;

&lt;p&gt;92分。很水，不知道讲了啥。大作业就是调库，也可以做 KDD Cup。作为猪队友和白教猿跟（没选课的）侯大神组了队，讨论的时候瞎逼逼了一通高论，最后也没搞出什么来。&lt;/p&gt;

&lt;h3 id=&quot;数据库专题训练&quot;&gt;数据库专题训练&lt;/h3&gt;

&lt;p&gt;98分。三个大作业，其实和数据库关系不大，更像是 OI 题。下了些功夫（根据王老师和黄老板的 idea）做优化，最后在排行榜上还算靠前。&lt;/p&gt;

&lt;h3 id=&quot;数值分析&quot;&gt;数值分析&lt;/h3&gt;

&lt;p&gt;89分。数值分析数学实验二选一，最后选了工作量较小的数值分析。属于没太学懂，考试以计算题为主，极其依赖往年题的课程。&lt;/p&gt;

&lt;h3 id=&quot;初等数论&quot;&gt;初等数论&lt;/h3&gt;

&lt;p&gt;97分。死皮赖脸手动选上的。很水。考试默写定理。&lt;/p&gt;

&lt;h3 id=&quot;博弈论&quot;&gt;博弈论&lt;/h3&gt;

&lt;p&gt;优秀。这是个记通过的文素，非常划算。内容还是挺有趣的，也学到了知识。&lt;/p&gt;

&lt;h3 id=&quot;多元文化中的音乐现象&quot;&gt;多元文化中的音乐现象&lt;/h3&gt;

&lt;p&gt;86分。两学分文素，钦老板强烈推荐，加上老师讲课有趣，便选了这课。说实话听课不太认真，到现在也不怎么记得讲了什么了，算是科普性质的课程吧。期末要求当场表演任意形式的音乐，我们组表演了车祸现场。&lt;/p&gt;

&lt;h3 id=&quot;数学实验w&quot;&gt;数学实验（W）&lt;/h3&gt;

&lt;p&gt;是的，我数值分析和数学实验都选了，然后在中期退掉了数学实验。原因有二，一是数学实验作业量也不少，二是期末就考五道题过于刺激，对于求稳的我来说还是数值分析更加合适。&lt;/p&gt;

&lt;h3 id=&quot;操作系统w&quot;&gt;操作系统（W）&lt;/h3&gt;

&lt;p&gt;认真上了前半学期，因为期中考试有点惨而退课。也不能说完全没有兴趣，但的确是比较难，细节太多，而且感觉（前半学期内容）有不少是历史包袱。据说后半学期好一些。&lt;/p&gt;

&lt;h3 id=&quot;计算机系统结构w&quot;&gt;计算机系统结构（W）&lt;/h3&gt;

&lt;p&gt;不知道存在意义是什么的课程。前半学期和计原高度重合，后半学期讲一些小众结构，学着没什么问题，但老师比较搞笑（贬义）。这门课的作业做起来也让我感到莫名难受，于是就退课了。&lt;/p&gt;

&lt;h3 id=&quot;运作管理&quot;&gt;运作管理&lt;/h3&gt;

&lt;p&gt;唯一的管双课。本来还选了几门，不过下定了决心转辅修，因此都退了。这门课其实还挺偏数学的，有一点像数学建模。最后拿了93分，成了所有管双课里分数最高的一门。&lt;/p&gt;

&lt;h2 id=&quot;其他&quot;&gt;其他&lt;/h2&gt;

&lt;h3 id=&quot;文素讲座&quot;&gt;文素讲座&lt;/h3&gt;

&lt;p&gt;可算是听完讲座了。对照清华新闻网瞎凑了一篇讲座报告。没什么意思。&lt;/p&gt;

&lt;h3 id=&quot;实验室&quot;&gt;实验室&lt;/h3&gt;

&lt;p&gt;前面也说了，在实验室主要做工程项目。项目是和钟皓曦和王老板一起做的，之所以能和钟皓曦一块是因为他想保研到我们系。王老板中途转去了别的项目，到后面开发就基本上是我和钟皓曦两人。我们合作写出了不堪入目的丑陋代码，造了很多不好用的方轮子，运用了一些不应当被用在正经工程中的 Python 黑科技（e.g. monkey patching）。因为我俩其实都没什么干劲，因此都是留到组会头天晚上肝通宵做功能。最惨的一次是周日办校赛，头一天晚上熬夜准备，办完校赛去参加庆功宴，回来为了周一组会又通宵肝代码。真的是写到怀疑人生，也是唯一一次熬夜熬到熬不动，写一个小时就要睡一个小时。&lt;/p&gt;

&lt;p&gt;最后做出来的网站界面还算炫酷，但也仅仅是能用的水平，任务队列的可用性基本上属于 demo 水平。现在这个项目大概是搁置了，不知道还会不会捡起来（但愿不吧）。&lt;/p&gt;

&lt;h3 id=&quot;英语&quot;&gt;英语&lt;/h3&gt;

&lt;p&gt;大二考过一次托福，但要出国的话还要考 GRE，总而言之先准备着。开始用扇贝记 GRE 单词，非常痛苦，大概坚持了一个月，记住了诸如“教友派信徒”（Quaker）、“延期偿付”（moratorium）的词。但也就坚持了一个月，之后基本上忘光了。&lt;/p&gt;

&lt;h3 id=&quot;体育&quot;&gt;体育&lt;/h3&gt;

&lt;p&gt;体育课选了击剑，还挺有意思的，上课还算认真，但最后练得并不好。动作会做，但反应不过来。感觉自己还是不擅长竞技类的运动，没法耍帅。&lt;/p&gt;

&lt;h3 id=&quot;教务&quot;&gt;教务&lt;/h3&gt;

&lt;p&gt;这学期和教务打交道有三次。&lt;/p&gt;

&lt;p&gt;第一次是手动选数论课，需要填特殊原因选课申请表，然后找任课老师、系教务和校教务签字。&lt;/p&gt;

&lt;p&gt;第二次是本来想用谷歌实习替代系里的暑假小学期。为此找到了教务老师，但得到的答复是除非能证明实习内容是科研，不然没法替代，估计没戏。剩下的方案是开学后再回来或者找管得松的小学期老师。前者方案我问了学长，说找教务请假即可，问题不会太大；后者方案我联系了系里比较好说话的老师，但他说系里会抓这个事，所以他没法保证，后果得自负。找老师谈话的时候顺便被他劝退读研（所以知道是哪位老师了吧）。不过鉴于后来也有&lt;ruby&gt;&lt;rb&gt; [ &lt;/rb&gt;&lt;rt&gt;手动断句&lt;/rt&gt;&lt;/ruby&gt;虽然没有替代成功，但在小学期结束前就来暑研的同学 ] ，所以估计也是可以运作的。&lt;/p&gt;

&lt;p&gt;第三次是中期退课的时候，本来数值分析也退了，但沈导找到我说，系里有一条没有落实的规定：大四下不能选超过两门专业课，不然不能做毕设。怕被系里刁难，所以权衡了一下，决定把数值分析弄回来。我又填了手动选课申请表，假装是退课的时候手抖了，最后也成功选了回来。&lt;/p&gt;

&lt;h3 id=&quot;比赛&quot;&gt;比赛&lt;/h3&gt;

&lt;p&gt;每年春季学期都是比赛季，但随着年龄的增长，OI 水平直线下降。MegCup 因为题目不怎么常规，所以拿到了名次和奖金。TCO 又一次折戟 R2。GCJ 差点没拿到T恤，最后是靠写暴力+其他人 FST 苟进了T恤线。&lt;/p&gt;

&lt;p&gt;今年怕是无望了。&lt;/p&gt;

&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;虽然还是挺啰嗦，但由于事儿少所以文章不算太长。&lt;/p&gt;

&lt;p&gt;本来想年前写的，但又拖到了年后。&lt;/p&gt;

&lt;p&gt;感谢看到这里的各位。今年的流水账不怎么好看，如果还能让你看完的话，我打心底里觉得感动。&lt;/p&gt;

&lt;p&gt;那么，下学期见。&lt;/p&gt;</content><author><name>Zecong Hu</name></author><summary type="html">这份总结实在是拖得太久了。 按理说暑假就应该写的，以暑研为借口拖到了大四上开学，又以没回国为由拖到了寒假，又以科研为由拖到了开学。再拖下去就要毕业了。 不过这一学期也是比较清闲的一学期。整个学期花时间最多的一件事是谈恋爱，但已经是回忆了，故此处不表。正事方面，课程不多，实验室搬砖每一到两周肝一晚上，社工处于半退休状态。半年后的今天回忆起来，竟然都想不到什么印象深刻的事情。 也好，那就简单回顾一下吧。</summary></entry><entry><title type="html">在 MacBook Pro 上配置使用外置显卡</title><link href="http://zecong.hu/2017/11/18/using-egpu-on-macbook-pro/" rel="alternate" type="text/html" title="在 MacBook Pro 上配置使用外置显卡" /><published>2017-11-18T17:42:05+00:00</published><updated>2017-11-18T17:42:05+00:00</updated><id>http://zecong.hu/2017/11/18/using-egpu-on-macbook-pro</id><content type="html" xml:base="http://zecong.hu/2017/11/18/using-egpu-on-macbook-pro/">&lt;p&gt;在听说 macOS High Sierra 官方支持 eGPU 之后，便一直想买一块显卡，以弥补我用 Mac 5年以来没怎么玩过大型 3D 游戏的遗憾，顺带炼一炼丹。趁着双十一这个借口，狠下心来买了一个 eGPU 盒子和一块 1080 Ti。&lt;/p&gt;

&lt;p&gt;不过配置显卡的过程及其复杂，为了方便他人，同时备自己不时之需，在此记录一下。&lt;/p&gt;

&lt;p&gt;声明：这里记载的方法是我综合网上各教程得到的，可能只适用于我自己的机型和配件，仅供参考。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;配置与环境&quot;&gt;配置与环境&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;主机：&lt;/strong&gt;2015款 MBP 15’，带 AMD R9 M370X 独显，以及 Intel Iris Pro 集显&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;系统：&lt;/strong&gt;macOS High Sierra 10.13.1 / Windows 10 Fall Creator’s Update (10.0.10586)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;eGPU盒：&lt;/strong&gt;Sonnet eGPF Breakaway Box (GPU-350W-TB3Z)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GPU：&lt;/strong&gt;EVGA GeForce GTX 1080 Ti SC2 (11G-P4-6593-KR)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;之所以选择这个盒子，是因为苹果官方提供的开发者版 eGPU 就是基于这个盒子的。毕竟官方“认证”，用着放心一些。我买的是 350W 的盒子（因为便宜），只提供了一个 8pin 和一个 6pin 电源接口，因此必须使用同样使用这种接口的 GPU。&lt;/p&gt;

&lt;p&gt;另外，由于这个盒子使用 Thunderbolt 3 接口且只附赠 TB3 公对公连接线，因此还需要自行购买转接器。市面上只有 TB3 公对 TB2 母的转接器，不过因为是双向的，可以搭配 TB2 公对公连接线使用。&lt;/p&gt;

&lt;h2 id=&quot;在-windows-上配置&quot;&gt;在 Windows 上配置&lt;/h2&gt;

&lt;p&gt;不得不说，Windows 对各类硬件的支持还是完善得多。在 Windows 上配置非常简单，由于 Boot Camp 自带 TB 驱动，eGPU 盒子即插即用，只要上 NVIDIA 官网下最新驱动安装即可。&lt;/p&gt;

&lt;p&gt;不过这里有一个很坑的地方：MBP 的两个 TB2 接口是不一样的。具体有什么差别我也没查到，但是我的盒子只有插在&lt;strong&gt;靠近电源一侧&lt;/strong&gt;的接口才可以正常工作。如果插在另一个接口，虽然可以正常识别，但是 GeForce Experience 在驱动安装完成后仍然会提示需要安装驱动，无法使用。&lt;/p&gt;

&lt;h3 id=&quot;使用内置显示器&quot;&gt;使用内置显示器&lt;/h3&gt;

&lt;p&gt;如果使用外接显示器的话，至此已经可以正常使用了。但是我们可以通过进一步的配置，让内置显示器使用外接显卡渲染。这一部分的原理似乎是，在 Mac 启动时会检测是否存在独立显卡，如果存在则不会使用集成显卡。但是为了使用 NVIDIA Optimus 来让 GPU 为内置显示器渲染，则需要让集成显卡保持运行。&lt;/p&gt;

&lt;p&gt;具体描述请参见链接&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h4 id=&quot;第一步设置启动盘&quot;&gt;第一步：设置启动盘&lt;/h4&gt;

&lt;p&gt;这一步需要在 macOS 中完成。在 System Preferences（系统偏好设置） &amp;gt; Startup Disk（启动盘）中，选择 Windows BOOTCAMP 分区作为启动盘，并重启。&lt;/p&gt;

&lt;p&gt;如果选项中没有 BOOTCAMP 分区，可能是因为第三方 NTFS 驱动（比如我使用的 Turexa NTFS）挂载了分区。以 Turexa NTFS 为例，在其设置页面中的 Volumes 页选择 BOOTCAMP 分区，勾选“Disable Turexa NTFS”，并在 Disk Utility 中卸载再挂载分区即可。&lt;/p&gt;

&lt;h4 id=&quot;第二步创建-usb-引导盘&quot;&gt;第二步：创建 USB 引导盘&lt;/h4&gt;

&lt;p&gt;这一步是为了假装是 macOS 启动。你需要一个容量不超过 4GB 的U盘，并将其格式化为 FAT 格式。如果手头只有大容量U盘，可以通过以下操作来划分一块 4GB 的分区：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;以管理员权限运行 &lt;code class=&quot;highlighter-rouge&quot;&gt;diskpart&lt;/code&gt;；&lt;/li&gt;
  &lt;li&gt;执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;list disk&lt;/code&gt;，记下U盘对应的磁盘编号（假设为 Disk 1）；&lt;/li&gt;
  &lt;li&gt;执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;select disk 1&lt;/code&gt;；&lt;/li&gt;
  &lt;li&gt;执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;clean&lt;/code&gt;，这将抹除U盘上所有的数据，并删除分区表；&lt;/li&gt;
  &lt;li&gt;执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;create partition primary size=4000&lt;/code&gt;，这将创建一个 4GB 的主分区；这一步操作后系统可能会弹出对话框询问是否需要格式化，关闭即可；&lt;/li&gt;
  &lt;li&gt;执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;format fs=fat quick&lt;/code&gt;，这将快速格式化分区为 FAT 格式；&lt;/li&gt;
  &lt;li&gt;执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;assign letter = D&lt;/code&gt;，这将为分区分配盘符 D ，以访问文件系统。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;当然，更简单的办法应该是在 macOS 下使用 Disk Utility（磁盘工具）完成上述操作。&lt;/p&gt;

&lt;p&gt;之后，下载 &lt;a href=&quot;https://github.com/0xbb/apple_set_os.efi/releases&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;apple_set_os.efi&lt;/code&gt;&lt;/a&gt;。在U盘根目录下创建目录 &lt;code class=&quot;highlighter-rouge&quot;&gt;/EFI/Boot&lt;/code&gt;，并将下载的文件重命名为 &lt;code class=&quot;highlighter-rouge&quot;&gt;bootx64.efi&lt;/code&gt; 放在目录中。&lt;/p&gt;

&lt;h4 id=&quot;第三步执行-gpu-switch&quot;&gt;第三步：执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;gpu-switch&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;下载 &lt;a href=&quot;https://github.com/0xbb/gpu-switch&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gpu-switch&lt;/code&gt;&lt;/a&gt; 的 Windows 版本。它的作用是在下次启动系统时使用集成显卡。以管理员权限执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;integrated.bat&lt;/code&gt; 即可。&lt;/p&gt;

&lt;h4 id=&quot;第四步通过-efi-boot-引导&quot;&gt;第四步：通过 EFI Boot 引导&lt;/h4&gt;

&lt;p&gt;重新启动，在开机时按住左 option 键，选择 EFI Boot 启动。此时内置显示屏就是外接显卡渲染的啦。&lt;/p&gt;

&lt;p&gt;为了验证这一点，可以在桌面右键菜单中打开 NVIDIA Control Panel。如果右键菜单中没有这一项，或者点击后弹出“没有使用 NVIDIA GPU 的显示器”，则说明配置不成功。&lt;/p&gt;

&lt;h2 id=&quot;在-macos-上配置&quot;&gt;在 macOS 上配置&lt;/h2&gt;

&lt;p&gt;现在 macOS 上已经有了 NVIDIA 的官方驱动支持。目前最新的 WebDriver 版本号为 378.10.10.10.20.107，可以在 &lt;a href=&quot;http://www.nvidia.com/download/driverResults.aspx/126538/en-us&quot;&gt;NVIDIA 官方网站&lt;/a&gt;上下载。同时需要安装对应的 CUDA 驱动。&lt;/p&gt;

&lt;p&gt;如果要在 NVIDIA 官网搜索最新版本的 macOS 驱动，则需要在产品系列选择“GeForce 600 Series”，操作系统选择“Show all Operating Systems”，然后选择对应的 macOS 系统版本。这是因为该驱动目前只为该系列显卡提供正式支持，对较新的显卡的支持还在 beta 阶段。&lt;/p&gt;

&lt;p&gt;需要注意的是，安装驱动时需要开启 System Integrity Protection（SIP）。具体方法是在开机进入 macOS 系统前按住 Cmd+R 进入恢复模式，打开命令行执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;csrutil enable&lt;/code&gt;。同理，执行 &lt;code class=&quot;highlighter-rouge&quot;&gt;csrutil disable&lt;/code&gt;则可以关闭 SIP。如果没有手动关闭过 SIP的话，默认状态下 SIP是开启的。&lt;/p&gt;

&lt;p&gt;为了使用外置 GPU，还需要做一些附加的配置。下载 &lt;a href=&quot;https://egpu.io/wp-content/uploads/wpforo/attachments/3/3858-nvidia-egpu-v2-1013-1.zip&quot;&gt;NVIDIAEGPUSupport&lt;/a&gt;，并在&lt;strong&gt;关闭 SIP&lt;/strong&gt; 的情况下安装。详细信息可以参考连接&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;不过这时，如果在启动时连接了 eGPU，则进入登录界面后会花屏。如果在启动后连接 eGPU，在系统信息中的显卡信息处只能看到“NVIDIA Chip Model”，并不会显示具体型号。解决方法和 Windows 部分使用内置显示器的方法类似：将启动盘设为 macOS 分区，执行 macOS 下的 &lt;code class=&quot;highlighter-rouge&quot;&gt;gpu-switch&lt;/code&gt;，然后重启时从 EFI Boot 启动。此时可以正常进入登录界面，登录后可以使用 &lt;a href=&quot;http://cuda-z.sourceforge.net/&quot;&gt;CUDA-Z&lt;/a&gt; 检测 GPU。&lt;/p&gt;

&lt;p&gt;需要强调的一点是：目前 macOS &lt;strong&gt;不完全支持热拔插&lt;/strong&gt;。在连接 eGPU 后断开可能导致黑屏、重启、显示“五国语言”错误界面等。&lt;/p&gt;

&lt;h3 id=&quot;使用内置显示器-1&quot;&gt;使用内置显示器&lt;/h3&gt;

&lt;p&gt;至此，虽然使用了 Windows 部分的方法，但仍然没有让内置显示器用上 eGPU。在关于本机的页面中，Built-in Display 下面显示的仍然是 Intel Iris Pro 内置显卡。&lt;/p&gt;

&lt;p&gt;链接&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;中给出了一种方法，需要用到一个 HDMI 的“空插头”。因为手头没有这种插头，我没有尝试，等以后试过了再更新这一部分。&lt;/p&gt;

&lt;h2 id=&quot;关于-thunderbolt-2-的性能损失&quot;&gt;关于 Thunderbolt 2 的性能损失&lt;/h2&gt;

&lt;p&gt;在整个显卡→PCI-E→TB3→TB2→主机的数据通道中，各部分的理论最大带宽为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PCI-E：126Gbps&lt;/li&gt;
  &lt;li&gt;TB3：32Gbps&lt;/li&gt;
  &lt;li&gt;TB2：16Gbps&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此 TB2 成为了瓶颈。实际测试在 macOS 下，传输速度约为 1200MB/s，也就是 9.6Gbps。如果使用内置显示器的话，速度会更低。根据链接&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;中的测试，在 TB2 连接下使用 GTX 1080 大概会有 40% 的性能损失，使用外置显示器可以将损失减小到 20%。&lt;/p&gt;

&lt;p&gt;另外，链接&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;中指出性能损失可能也部分来自于 &lt;code class=&quot;highlighter-rouge&quot;&gt;apple_set_os.efi&lt;/code&gt;，并给出了一个解决方法。我没有仔细阅读，大家可以自行参考。&lt;/p&gt;

&lt;p&gt;就游戏体验来说，即便只有60%的性能，大部分游戏也绰绰有余了。在 Windows 下使用 1920x1600 分辨率运行的 NieR:Automata，在开启最高画质、关闭垂直同步时仍然较为流畅（主观感受，没有实际测过帧率）。对我来说大概够了。&lt;/p&gt;

&lt;p&gt;另一方面，对于炼丹而言，计算耗时应该远高于传输耗时，因此瓶颈影响不大。不过这也只是我的猜想，还没有实测过。&lt;/p&gt;

&lt;h2 id=&quot;参考链接&quot;&gt;参考链接&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://egpu.io/forums/mac-setup/how-to-keep-mbps-irisiris-pro-activated-when-booting-into-windows-boot-camp/&quot;&gt;https://egpu.io/forums/mac-setup/how-to-keep-mbps-irisiris-pro-activated-when-booting-into-windows-boot-camp/&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://egpu.io/forums/mac-setup/wip-nvidia-egpu-support-for-high-sierra/&quot;&gt;https://egpu.io/forums/mac-setup/wip-nvidia-egpu-support-for-high-sierra/&lt;/a&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://egpu.io/how-to-egpu-accelerated-internal-display-macos/&quot;&gt;https://egpu.io/how-to-egpu-accelerated-internal-display-macos/&lt;/a&gt; &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://egpu.io/forums/mac-setup/pcie-slot-dgpu-vs-thunderbolt-3-egpu-internal-display-test/&quot;&gt;https://egpu.io/forums/mac-setup/pcie-slot-dgpu-vs-thunderbolt-3-egpu-internal-display-test/&lt;/a&gt; &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://egpu.io/forums/mac-setup/mbp-tb3-port-underperformance-16xxmibs-instead-of-22xxmibs-under-macos-or-windowsapple_set_os-efi/&quot;&gt;https://egpu.io/forums/mac-setup/mbp-tb3-port-underperformance-16xxmibs-instead-of-22xxmibs-under-macos-or-windowsapple_set_os-efi/&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Zecong Hu</name></author><summary type="html">在听说 macOS High Sierra 官方支持 eGPU 之后，便一直想买一块显卡，以弥补我用 Mac 5年以来没怎么玩过大型 3D 游戏的遗憾，顺带炼一炼丹。趁着双十一这个借口，狠下心来买了一个 eGPU 盒子和一块 1080 Ti。 不过配置显卡的过程及其复杂，为了方便他人，同时备自己不时之需，在此记录一下。 声明：这里记载的方法是我综合网上各教程得到的，可能只适用于我自己的机型和配件，仅供参考。</summary></entry><entry><title type="html">Research Notes</title><link href="http://zecong.hu/2017/08/07/research-notes/" rel="alternate" type="text/html" title="Research Notes" /><published>2017-08-07T01:53:05+00:00</published><updated>2017-08-07T01:53:05+00:00</updated><id>http://zecong.hu/2017/08/07/research-notes</id><content type="html" xml:base="http://zecong.hu/2017/08/07/research-notes/">&lt;p&gt;This post records my notes taken during summer internship @ CMU LTI.&lt;/p&gt;

&lt;p&gt;Disclaimer: These notes are not guaranteed to be correct or understandable.&lt;/p&gt;

&lt;p&gt;Note: This is a non-mobile-friendly post, mobile view is distorted due to formulae.&lt;/p&gt;

&lt;!--more--&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\renewcommand{\d}{\ \mathrm{d}}&lt;/script&gt;

&lt;h2 id=&quot;tips-in-training&quot;&gt;Tips in Training&lt;/h2&gt;

&lt;h4 id=&quot;dropout&quot;&gt;Dropout&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Apply a random mask on parameters: each parameter is zeroed with a probability of $p$, note that output would be scaled down to $1-p$ compared to values when dropout is not applied&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Inverted dropout&lt;/strong&gt;: Rescale output to $1/(1-p)$ during training, so no special treatment is required for using the models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dropout for embeddings&lt;/strong&gt;: zero out entire vectors for random word IDs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dropout for LSTMs&lt;/strong&gt;: apply to &lt;u&gt;input&lt;/u&gt; and &lt;u&gt;hidden state&lt;/u&gt;, rather than parameters. Dropout mask is the same for each time step on one training sample &lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1512.05287.pdf&quot;&gt;[Gal 2016] A Theoretically Grounded Application of Dropout in Recurrent Neural Networks&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dropout for final FC layer in LSTMs&lt;/strong&gt;: apply to &lt;u&gt;LSTM output&lt;/u&gt;, rather than FC parameters&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;evaluating-similarity&quot;&gt;Evaluating similarity&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;To evaluate similarities of $h_L$ and $h_R$ based on ratings of $[1,K]$, we can jointly train a MLP based on:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
h_\times &amp;= h_L\odot h_R \\
h_+ &amp;= \vert h_L-h_R \vert \\
h_s &amp;= \sigma\left(W^{(\times)}h_\times + W^{(+)}h_+ + b^{(h)}\right) \\
\hat{p_\theta} &amp;= \mathrm{softmax}\left(W^{(p)}h_s + b^{(p)}\right) \\
r &amp;= \{1,2,\ldots,K\} \\
\hat{y} &amp;= r^\top \hat{p_\theta}
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;i.e. &lt;u&gt;learning a evaluation criterion based on distance and angle&lt;/u&gt; between the pair, and mapping it as a weighted average of ratings. Obviously the resultant prediction $\hat{y}$ will be in the range $[1,K]$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Triplet loss&lt;/strong&gt;: &lt;em&gt;&lt;u&gt;(more details to be described)&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;gumbel-max-trick--gumbel-softmax-distribution&quot;&gt;Gumbel-max trick &amp;amp; Gumbel-Softmax distribution&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gumbel distribution&lt;/strong&gt; (unit scale, zero location, $x\in(-\infty,+\infty)$):&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;PDF&lt;/strong&gt;: $f(x) = \exp(-x-\exp(-x))$&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;CDF&lt;/strong&gt;: $F(x) = \exp(-\exp(-x))$&lt;/li&gt;
      &lt;li&gt;Property: If $U\sim \mathrm{Uniform}[0,1]$, then $-\log(-\log U)\sim \mathrm{Gumbel}(0,1)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Softmax for ${x_k}$ is equivalent to: adding independent Gumbel noise and take argmax&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;: Let $z_k = x_k + y_k,\ {y_k}\stackrel{\mathrm{i.i.d.}}{\sim}\mathrm{Gumbel}(0,1)$, then $P(z_k\text{ is max}) = \prod_{j\neq k} F(z_k-x_j)$.
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align*}
P(k\text{ is selected}) &amp;= \int_{-\infty}^{+\infty}f(z_k-x_k)P(z_k\text{ is max})\d{z_k} \\
&amp;= \int_{-\infty}^{+\infty} \exp\left(-z_k+x_k-\exp(-z_k)\sum_{j=1}^{K}\exp(x_k)\right)\d{z_k} \\
&amp;\stackrel{\text{magic}}{=} \frac{\exp(x_k)}{\sum_{j=1}^{K}\exp(x_j)}=\mathrm{softmax}\left(\{x_k\}\right)^{(k)}
\end{align*} %]]&gt;&lt;/script&gt;
where the “magic” step somehow calculates the closed-form solution of the above integration.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;See also: &lt;a href=&quot;https://hips.seas.harvard.edu/blog/2013/04/06/the-gumbel-max-trick-for-discrete-distributions/&quot;&gt;https://hips.seas.harvard.edu/blog/2013/04/06/the-gumbel-max-trick-for-discrete-distributions/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Usage&lt;/strong&gt;: Replace sampling from distribution $P(x)=\pi_x$ with argmax operation:
&lt;script type=&quot;math/tex&quot;&gt;z=\underset{i}{\arg\max}(g_i+\log\pi_i)\sim P&lt;/script&gt;
where $g_i$ are independent samples from uniform Gumbel distribution.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gumbel-Softmax distribution&lt;/strong&gt;: Softmax with temperature $\tau$ applied over Gumbel-max:
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}=\mathrm{softmax}((\log\pmb{\pi}+\mathbf{g})/\tau)&lt;/script&gt;
For lower temperatures, Gumbel-Softmax distribution is close to the one-hot distribution of the argmax element (which is the sample given by Gumbel-max trick); for higher temperatures, distribution is close to uniform. &lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1611.01144&quot;&gt;[Jang et al. 2016] Categorical Reparameterization with Gumbel-Softmax&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;This is useful when we need a differentiable sample over a discrete distribution. For sample over continuous distributions, we have the &lt;a href=&quot;#how-do-we-compute-the-lower-bound&quot;&gt;reparameterization trick&lt;/a&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;exposure-bias-and-scheduled-sampling&quot;&gt;Exposure bias and scheduled sampling&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Exposure bias&lt;/strong&gt;: In sequential models, during training, we feed the ground-truth label at the previous time step as input, no matter what the output prediction was; while during testing, we always feed the previous output. This way, the model is “exposed” to the ground-truth, even when it was not able to make such predictions. The model may also fail to capture relations between the next state and the previous output.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Scheduled sampling&lt;/strong&gt;: At each time step, use previous label by probability $1-p$, and use “teacher forcing” (feed ground-truth) by probability $p$.&lt;/p&gt;

    &lt;p&gt;$p$ is set to a high value at the beginning of training, and eventually anneal to a close to 0 value (thus the name “scheduled” sampling).
See also: &lt;a href=&quot;https://www.evernote.com/shard/s189/sh/c9ac2e3f-a150-4d0c-9a44-16657e5d42cd/5eb49d50695c903ca1b4a04934e63363&quot;&gt;https://www.evernote.com/shard/s189/sh/c9ac2e3f-a150-4d0c-9a44-16657e5d42cd/5eb49d50695c903ca1b4a04934e63363&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Drawbacks of scheduled sampling&lt;/strong&gt;: When previous label was used, we were using the result of argmax of the softmax at previous time step as input, and naturally we would like to back propagate through such calculations. However, argmax is non-differentiable.&lt;/p&gt;

    &lt;p&gt;The reason back propagating through argmax is desirable is that, the actual cause for predicting a wrong label at the current time step may be that wrong predictions were made at previous time steps (cascading error).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Other caveats&lt;/strong&gt;: see &lt;a href=&quot;http://www.inference.vc/scheduled-sampling-for-rnns-scoring-rule-interpretation/&quot;&gt;A Word of Caution on Scheduled Sampling for Training RNNs&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Soft argmax and differentiable scheduled sampling&lt;/strong&gt; &lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1704.06970.pdf&quot;&gt;[Goyal, Dyer 2017] Differentiable Scheduled Sampling for Credit Assignment&lt;/a&gt;)&lt;/em&gt;: &lt;em&gt;&lt;u&gt;(more details to be described)&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;truncated-backprop&quot;&gt;Truncated Backprop&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Concretely, for every $k_1$ time steps, train on the following $k_2$ time steps. When $k_1&amp;lt;k_2$, there’s overlap between consecutive time steps; sometimes $k_1=k_2$ is desired.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://r2rt.com/static/images/RNN_tf_truncated_backprop.png&quot; alt=&quot;truncated backprop&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Initial state may be &lt;strong&gt;zeroed&lt;/strong&gt; by a small probability, so as to bias the model towards being easily start from a zero state in test time &lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1707.05589.pdf&quot;&gt;[Melis, Dyer 2017] On the State of the Art of Evaluation in Neural Language Models&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Data preprocessing&lt;/strong&gt;: &lt;em&gt;&lt;u&gt;(more details to be described)&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;: cheaper to train (less memory consumption for computation graphs), and mitigates the vanishing gradient problem; &lt;strong&gt;Cons&lt;/strong&gt;: constrained the maximum range for dependencies&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;entropy-cross-entropy-loss-and-kl-divergence&quot;&gt;Entropy, Cross Entropy Loss, and KL-Divergence&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Shannon &lt;strong&gt;Entropy&lt;/strong&gt; of a probability distribution is defined as&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;H(p)=\mathbb{E}_p[-\log p]=-\sum_{x_i}p(x_i)\log p(x_i)&lt;/script&gt;

    &lt;p&gt;which is the expected number of bits required to represent an element in the set over which the probability distribution is defined. The lower bound for the number of bits required to represent an element $x_i$ is $\log\frac{1}{p(x_i)}=-\log p(x_i)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cross-Entropy loss&lt;/strong&gt; is defined on two distributions:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;H(p,q)=\mathbb{E}_p[-\log q]=-\sum_{x_i}p(x_i)\log q(x_i)&lt;/script&gt;

    &lt;p&gt;which can be interpreted as estimating entropy using the wrong probability $q$. When minimizing w.r.t. cross-entropy loss, we’re trying to match our predicted distribution $q$ to the true distribution $p$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;KL-divergence&lt;/strong&gt; is simply the difference between entropy and cross-entropy loss:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{KL}(p\ \Vert\  q)=H(p,q)-H(p)=\sum_{x_i}p(x_i)\log\frac{p(x_i)}{q(x_i)}&lt;/script&gt;

    &lt;p&gt;which is the number of extra bits required. Usually minimizing w.r.t. KL-divergence is equivalent to minimizing w.r.t. cross-entropy loss.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;See also: &lt;a href=&quot;https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/&quot;&gt;https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/&lt;/a&gt; and &lt;a href=&quot;https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained&quot;&gt;https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tied-input-and-output-embeddings&quot;&gt;Tied Input and Output Embeddings&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Let $L$ be the input embedding, such that input to the LSTM is $x_t = Ly^*_{t-1}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Replace the dense layer $y_t=\mathrm{softmax}(Wh_t+b)$ following the LSTM unit by the &lt;strong&gt;transpose&lt;/strong&gt; of the embedding, i.e. $y_t=\mathrm{softmax}\left(L^\top h_t\right)$ &lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1611.01462.pdf&quot;&gt;[Inan &amp;amp; Khosravi 2016] Tying Word Vectors and Word Classifiers etc.&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Since input and output are in the same space, it is reasonable to assume they’re related by a linear transformation $A$. Tying embeddings results in minimizing w.r.t. vector similarities:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Let $u_t=Ly^*_t$, i.e. the embedding of the actual output. By minimizing w.r.t. vector similarities, we would like the probability $y_t$ be related to similarity metrics, concretely $y_t=\tilde{y_t}=\mathrm{softmax}\left(L^\top u_t\right)$, where we use inner product as measurement of similarity.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;In order to minimize loss, $h_t$ would be adjusted to be closer to the appropriate column of $L$.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;If we apply KL-divergence as loss, $\tilde{y_t}$ could be used as the estimated true distribution. Other class labels are also utilized during backprop, compared to the case when one-hot encoding is used.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;softmax-approximations-by-sampling&quot;&gt;Softmax Approximations by Sampling&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Ref to: &lt;a href=&quot;http://ruder.io/word-embeddings-softmax/index.html#samplingbasedapproaches&quot;&gt;http://ruder.io/word-embeddings-softmax/index.html#samplingbasedapproaches&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Given the correct word $w$, and all candidate words $w_i$. For negative log softmax loss, the formula for loss is:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;J_w=-\log\frac{\exp(h^\top v_{w})}{\sum_{w_i}\exp(h^\top v_{w_i})}=-h^\top v_w+\log\sum_{w_i}\exp(h^\top v_{w_i})&lt;/script&gt;

    &lt;p&gt;where $v_w$ is the output embedding. Denoting $\mathcal{E}(w)=h^\top v_{w}$, taking gradients w.r.t. parameters would give:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\nabla_\theta J_w &amp; = -\nabla_\theta \mathcal{E}(w)+\nabla_\theta \log\sum_{w_i}\exp(\mathcal{E}(w_i)) \\
&amp; = -\nabla_\theta\mathcal{E}(w)+\sum_{w_i}\frac{\exp(\mathcal{E}(w_i))}{\sum_{w_i'}\exp(\mathcal{E}(w_i'))}\nabla_\theta\mathcal{E}(w_i) \\
&amp; = -\nabla_\theta\mathcal{E}(w)+\sum_{w_i}P(w_i)\nabla_\theta\mathcal{E}(w_i) \\
&amp; = -\nabla_\theta\mathcal{E}(w)+\mathbb{E}_{w_i\sim P}[\nabla_\theta\mathcal{E}(w_i)]
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;where $P(w_i)$ is the softmax probability of $w_i$.&lt;/p&gt;

    &lt;p&gt;Sampling methods reduce computational complexity by approximating the expected term.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;importance-sampling&quot;&gt;Importance sampling&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Expectation can be calculated using Monte Carlo methods: average of samples multiplied by its probability.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To avoid computing actual probabilities (which is the same as calculating softmax), sample from another distribution $Q$ similar to the target distribution $P$, for instance, the unigram distribution.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Suppose we’re to calculate $\mathbb{E}_{x\sim P}[f(x)]$, which in continuous form is equivalent to&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{x\sim P}[f(x)]=\int f(x)p(x)\d x&lt;/script&gt;

    &lt;p&gt;where $p(x)$ is the PDF of distribution $P$. We can calculate the integration w.r.t. a different distribution $Q$ with PDF $q(x)$ by evaluating:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\int f(x)p(x)\d x=\int \frac{f(x)p(x)}{q(x)}q(x)\d x=\mathbb{E}_{x\sim Q}\left[\frac{f(x)p(x)}{q(x)}\right]&lt;/script&gt;

    &lt;p&gt;When $Q$ is similar to $P$, doing Monte Carlo integration w.r.t. $Q$ can decrease variance compared to using uniform distribution.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To avoid weighting the gradients with $P$, we need to approximate $P$ as well. Denote $P(w)=\frac{\tilde{p}(w)}{Z_p}$, where $Z_p$ is the partition function, and $\tilde{p}(w)=\exp(\mathcal{E}(w))$ is the unnormalized probability of distribution $P$. We can rewrite the expectation as:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathbb{E}_{w_i\sim P}[\nabla_\theta\mathcal{E}(w_i)] &amp; = \mathbb{E}_{\tilde{w}_i\sim Q}\left[\frac{P(\tilde{w})}{Q(\tilde{w}_i)}\nabla_\theta\mathcal{E}(w_i)\right] \\
 &amp; \approx \frac{1}{m}\sum_{i=1}^{m}\frac{P(\tilde{w}_i)}{Q(\tilde{w}_i)}\nabla_\theta\mathcal{E}(\tilde{w}_i) \\
 &amp; = \frac{Z_q}{Z_p}\frac{1}{m}\sum_{i=1}^{m}\frac{\tilde{p}(\tilde{w}_i)}{\tilde{q}(\tilde{w}_i)}\nabla_\theta\mathcal{E}(\tilde{w}_i)
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;where $\tilde{w}_i$ are $m$ samples from distribution $Q$ used in a Monte Carlo estimator. We can apply the same technique in approximating the partition function:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac{Z_p}{Z_q} &amp; =\frac{1}{Z_q}\sum_{w}\tilde{p}(w) \\
 &amp; = \sum_w \frac{Q(w)}{\tilde{q}(w)}\tilde{p}(w) \\
 &amp; = \mathbb{E}_{w\sim Q}\left[\frac{\tilde{p}(w)}{\tilde{q}(w)}\right] \approx \frac{1}{m}\sum_{i=1}^{m} \frac{\tilde{p}(\tilde{w}_i)}{\tilde{q}(\tilde{w}_i)}
\end{align*} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Combining the above formulae gives us an unbiased estimator of the expectation:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathbb{E}_{w_i\sim P}[\nabla_\theta\mathcal{E}(w_i)] &amp; \approx \sum_{i=1}^{m}\frac{\tilde{p}(\tilde{w}_i)/Q(\tilde{w}_i)}{\sum_k \tilde{p}(\tilde{w}_k)/Q(\tilde{w}_k)} \nabla_\theta\mathcal{E}(\tilde{w}_i) \\
 &amp; = \sum_{i=1}^{m}\frac{\exp(\mathcal{E}(\tilde{w}_i))/Q(\tilde{w}_i)}{\sum_k \exp(\mathcal{E}(\tilde{w}_k))/Q(\tilde{w}_k)} \nabla_\theta\mathcal{E}(\tilde{w}_i) \\
 &amp; = \nabla\log\sum_{i=1}^{m}\frac{\exp(\mathcal{E}(\tilde{w}_i))}{Q(\tilde{w}_i)}
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;which gives us our actual objective:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;J_w \approx -\mathcal{E}(w) + \log\sum_{i=1}^{m}\frac{\exp(\mathcal{E}(\tilde{w}_i))}{Q(\tilde{w}_i)}=-\mathcal{E}(w) + \log\sum_{i=1}^{m}\exp(\mathcal{E}(\tilde{w}_i)-\log Q(\tilde{w}_i))&lt;/script&gt;

    &lt;p&gt;The latter form is numerically more stable, and the log-sum-exp trick could be applied.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Note that the new objective is also an approximation of the original one. We can see the denominator of softmax as an expectation w.r.t. a uniform distribution, and here we’re approximating it with distribution $Q$. But anyway, this is not very accurate, for evaluation, a full softmax is still required.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Also refer to &lt;a href=&quot;#implementation-details&quot;&gt;&lt;strong&gt;Implementation Details&lt;/strong&gt;&lt;/a&gt;. See also &lt;em&gt;Pattern Recognition and Machine Learning&lt;/em&gt; Ch. 11.1.4.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;noise-contrastive-estimation-nce&quot;&gt;Noise contrastive estimation (NCE)&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Ref to: &lt;a href=&quot;https://datascience.stackexchange.com/questions/13216/intuitive-explanation-of-noise-contrastive-estimation-nce-loss&quot;&gt;https://datascience.stackexchange.com/questions/13216/intuitive-explanation-of-noise-contrastive-estimation-nce-loss&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/1410.8251.pdf&quot;&gt;https://arxiv.org/pdf/1410.8251.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Language modeling can be seen as a multinomial classification problem (predicting the label of the next word). We can convert this into a binary classification problem.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Train the LM as is but w/o the final output layer. Jointly train an extra binary classifier to distinguish noise (randomly chosen words) against correct words $w$ given the context $c$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For each word, sample $k$ noises $\tilde{w}_{k}$ from noise distribution $Q$. Minimize per-category cross-entropy loss using logistic regression, giving the loss function, and substituting expectation with Monte Carlo sampling:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
J_w &amp; \stackrel{\phantom{M.C.}}{=} - \log P(y=1\mid w,c) - k\cdot\mathbb{E}_{\tilde{w}_{j}\sim Q}[\log P(y=0\mid \tilde{w}_{j},c)] \\
&amp; \stackrel{M.C.}{=} - \log P(y=1\mid w,c) - \sum_{j=1}^{k}\log P(y=0\mid \tilde{w}_{j},c)
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;the reason why we used expectation for the noise entropy but not for the positive entropy, is because when we sum over all training data, the positive part would be equal to the entropy calculated for the whole dataset (i.e. the entire distribution).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;So samples come from a mixture of two distributions: the actual empirical distribution $\tilde{P}$ from data (the distribution we’re trying to model), and the noise distribution $Q$. We replace the empirical distribution with the learned distribution $P_\theta$ of our model, which gives:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
P(w\mid c) &amp; = P(y=0,w\mid c)+P(y=1,w\mid c) \\
 &amp; =\frac{k}{k+1}Q(w)+\frac{1}{k+1}P_\theta(w\mid c) \\
 P(y=1\mid w,c) &amp; = \frac{P(y=1,w\mid c)}{P(w\mid c)}=\frac{P_\theta(w\mid c)}{P_\theta(w\mid c)+k\cdot Q(w)} \\
 P(y=0\mid w,c) &amp; = 1-P(y=1\mid w,c)=\frac{k\cdot Q(w)}{P_\theta(w\mid c)+k\cdot Q(w)}
\end{align*} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Substituting probabilities into the loss function, we can calculate its gradients as follows:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\nabla J_w &amp; = -\nabla\log P(y=1\mid w,c) - k\cdot\mathbb{E}_{w_j\sim Q}[\nabla\log P(y=0\mid w_j,c)] \\
 &amp; = -\nabla\log P(y=1\mid w,c) - \sum_{w_j\in V}k\cdot Q(w_j)\nabla\log P(y=0\mid w_j,c) \\
 &amp; = -\frac{k\cdot Q(w)}{P_\theta(w\mid c)+k\cdot Q(w)}\cdot\nabla\log P_\theta(w\mid c)+\sum_{w_j\in V}\frac{k\cdot Q(w_j)}{P_\theta(w_j\mid c)+k\cdot Q(w_j)}\nabla P_\theta(w_j\mid c) \\
 &amp; = -\sum_{w_j\in V}\frac{k\cdot Q(w_j)}{P_\theta(w_j\mid c)+k\cdot Q(w_j)}\left(\tilde{P}(w_j\mid c)-P_\theta(w_j\mid c)\right)\nabla\log P_\theta(w_j\mid c)
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;where the empirical distribution $\tilde{P}(w_j\mid c)$ equals 1 iff $w_j=w$.&lt;/p&gt;

    &lt;p&gt;We can observe that when $k\rightarrow\infty$, the gradient $\nabla J_w\rightarrow -\sum\left(\tilde{P}(w_j\mid c)-P_\theta(w_j\mid c)\right)\nabla\log P_\theta(w_j\mid c)$, which goes to zero as $P_\theta$ matches $\tilde{P}$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;But $P_\theta(w\mid c)=\mathrm{softmax}(h^\top v_w)$, which is what we need to estimate. We can replace it by $P_\theta(w\mid c)=\exp(h^\top v_w)/Z(c)$, where $Z(c)$ is trainable. Or simply, let $Z(c)\equiv 1$, giving $P_\theta(w\mid c)=\exp(h^\top v_w)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Performance is poor?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;negative-sampling&quot;&gt;Negative sampling&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;An approximation to NCE, by setting the most expensive term $k\cdot Q(w)\equiv1$, giving:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;P(y=1\mid w,c)=\frac{\exp(h^\top v_w)}{\exp(h^\top v_w)+1}=\frac{1}{1+\exp(-h^\top v_w)}=\sigma(h^\top v_w)&lt;/script&gt;

    &lt;p&gt;where $\sigma$ is the sigmoid function.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Equivalent to NCE only when $k=\lvert V\rvert$ and $Q$ is a uniform distribution.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Inappropriate for language modeling, because probabilistic information is lost. Good for representation learning, as in word2vec.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;locality-sensitive-hashing&quot;&gt;Locality Sensitive Hashing&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A set of hash functions for approximated nearest neighbor search&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Hyperplane LSH for cosine similarities&lt;/strong&gt;: Draw random vectors from normal distribution. For each stored point, check which side of the plane it is at (the sign of their dot product), and encode such information as a 01-string. Such string is used as the hash signature.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Results are not good.&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;For 10k 128-dim points, best point found by LSH ranked ~23 among actual NNs.&lt;/li&gt;
      &lt;li&gt;This makes it unsuitable for softmax approximations&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;xavier-initializer--he-initializer&quot;&gt;Xavier Initializer &amp;amp; He Initializer&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Xavier initializer&lt;/strong&gt; was proposed by Xavier Glorot, thus also called Glorot initializer &lt;em&gt;(ref: &lt;a href=&quot;http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf&quot;&gt;[Glorot &amp;amp; Bengio 2010] Understanding the difficulty of training …&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When applying a linear transform $W$ to vector $\mathbf{x}$, we have $\mathbf{y}=W\mathbf{x}=\sum_{i=1}^{n}W_i\mathbf{x}_i$, where $n$ is the dimensionality (or the number of input neurons to the FC layer)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Assume the input vector has zero mean, and all elements and parameters are IID, we can calculate the variance of $\mathbf{y}$ as follows:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathrm{Var}(\mathbf{y}) &amp; = \mathrm{Var}\left(\sum_{i=1}^{n}W_i\mathbf{x}_i\right)=\sum_{i=1}^{n}\mathrm{Var}(W_i\mathbf{x}_i) \\
 &amp; = \sum_{i=1}^{n}\left(\mathbb{E}[\mathbf{x}_i]^2\mathrm{Var}(W_i) + \mathbb{E}[W_i]^2\mathrm{Var}(\mathbf{x}_i)+\mathrm{Var}(W_i)\mathrm{Var}(\mathbf{x}_i)\right) \\
 &amp; = n\mathrm{Var}(W_i)\mathrm{Var}(\mathbf{x}_i)
\end{align*} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This means the variance is scaled by $n\mathrm{Var}(W_i)$ after the transform. In order to preserve variance, Xavier initializer aims to set the variance of the weights to $\mathrm{Var}(W_i)=\frac{1}{n}=\frac{1}{n_\mathrm{in}}$. If we consider backwards pass, we would find that we need $\mathrm{Var}(W_i)=\frac{1}{n_\mathrm{out}}$, so as a compromise, variance is set to:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{Var}(W_i)=\frac{2}{n_\mathrm{in}+n_\mathrm{out}}&lt;/script&gt;

    &lt;p&gt;where $n_\mathrm{in}$ and $n_\mathrm{out}$ corresponds to the dimensions $n$ and $m$ of the transform matrix.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To obtain such variance, consider a uniform distribution $U[-x,x]$ whose variance is $\mathrm{Var}(U)=\frac{x^2}{3}$. Solving the equation gives us&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;W\sim U\Bigg[-\frac{1}{f'(0)}\sqrt{\frac{6}{n+m}},\frac{1}{f'(0)}\sqrt{\frac{6}{n+m}}\Bigg]&lt;/script&gt;

    &lt;p&gt;where $f$ is the nonlinearity after the transform.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;He initializer&lt;/strong&gt; was proposed by Kaiming He et al. It simply multiplies the Xavier initializer variance by 2. This is useful for ReLU nonlinearities, whose derivative is undefined at 0. This also makes sense in ReLU’s derivative is 0 half the time and 1 for the other half. &lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1502.01852&quot;&gt;[He 2015] Delving Deep into Rectifiers…&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ref to: &lt;a href=&quot;http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization&quot;&gt;http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tuning-on-the-development-set&quot;&gt;Tuning on the Development Set&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Early-stopping&lt;/strong&gt;: When results does not get better on the dev set, simply stop training. Usually there’s a threshold (or &lt;strong&gt;patience&lt;/strong&gt;) as to how many epochs with worse results are tolerated.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Rollback&lt;/strong&gt;: When results does not get better, simply load the best previous model and decay the learning rate. Best models as usually saved to disk.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Rollback Optimizer&lt;/strong&gt;: Regarding the optimizer (we’re only concerned about the optimizer statistics, e.g. parameter momentum, but not the hyper-params e.g. learning rate), 3 strategies are possible:&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Load the optimizer at the time of the best model snapshot. This requires saving the optimizer state as well.&lt;/li&gt;
      &lt;li&gt;Reset optimizer statistics. For common optimizers this mean zeroing momentum and moments.&lt;/li&gt;
      &lt;li&gt;Use the current optimizer as-is. The current optimizer has statistics for the worse dev performance part of training.&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Usually the effectiveness of the 3 methods are in order of their numbering. However method 2 has the benefit of being able to escape out of local minima as the initial step would be a large step.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;theory--proofs&quot;&gt;Theory &amp;amp; Proofs&lt;/h2&gt;

&lt;h4 id=&quot;on-gradient-vanishingexploding-of-rnns&quot;&gt;On Gradient Vanishing/Exploding of RNNs&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1607.03474&quot;&gt;[Zilly 2016] Recurrent Highway Networks&lt;/a&gt;, chapter 2)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A vanilla RNN can be described as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y^{(t)}=f\left(Wx^{(t)}+Ry^{(t-1)}+b\right)&lt;/script&gt;

&lt;p&gt;For simplicity, suppose the loss is defined on the last state only, i.e. $\mathcal{L}=g\left(y^{(T)}\right)$. The gradient w.r.t. parameters would be&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\d\mathcal{L}}{\d\theta}=\frac{\d\mathcal{L}}{\d y^{(T)}}\frac{\d y^{(T)}}{\d \theta}=\frac{\d\mathcal{L}}{\d y^{(T)}}\sum_{t_1=1}^{T}\frac{\d y^{(T)}}{\d y^{(t_1)}}\left(\frac{\d y^{(t_1)}}{\d W}+\frac{\d y^{(t_1)}}{\d b}\right)&lt;/script&gt;

&lt;p&gt;In the formula above, the gradient is expanded using the chain rule, and then expanded along the time axis. We further expand the Jacobian $\frac{\d y^{(T)}}{\d y^{(t_1)}}$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\frac{\d y^{(T)}}{\d y^{(t_1)}}=\prod_{t_1&lt;t\leq T}\frac{\d y^{(t)}}{\d y^{(t-1)}}=\prod_{t_1&lt;t\leq T}R\cdot\mathrm{diag}\left[f'\left(Ry^{(t-1)}\right)\right] %]]&gt;&lt;/script&gt;

&lt;p&gt;Denoting $A=\frac{\d y^{(t)}}{\d y^{(t-1)}}$ as the temporal Jacobian, the upper bound for its norm would be&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Vert A\Vert\leq \Vert R\Vert \left\Vert f'\left(Ry^{(t-1)}\right)\right\Vert\leq \sigma_\max\cdot\gamma&lt;/script&gt;

&lt;p&gt;where $\sigma_\max$ is the principal singular value of $A$, and $\gamma$ is the upper bound on $f’$.&lt;/p&gt;

&lt;p&gt;As the temporal Jacobian is multiplied together, which is approximately equivalent to $A$ raised to the $T$-th power. So the conditions for vanishing/exploding gradients are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vanishing gradients&lt;/strong&gt;: $\gamma\sigma_\max&amp;lt;1$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Exploding gradients&lt;/strong&gt;: $\rho(A)=\sigma_\max&amp;gt;1$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Comparing to MLPs&lt;/strong&gt;: The reason deep CNNs/MLPs do not suffer less from gradient vanishing/exploding as RNNs do, is because MLPs use different matrices at different layers, while RNNs use the same matrix in every time step.&lt;/p&gt;

&lt;h4 id=&quot;on-the-effectiveness-of-lstms&quot;&gt;On the Effectiveness of LSTMs&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;(ref: &lt;a href=&quot;http://proceedings.mlr.press/v37/jozefowicz15.pdf&quot;&gt;[Jozefowicz 2015] An Empirical Exploration of RNN structures&lt;/a&gt;, chapter 2)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In their simplest forms, the RNN calculates the new state $h^{(t)}$ by $h^{(t)}=f(Wh^{(t-1)})$, while the LSTM (without forget gates) calculates the new state by $c^{(t)}=c^{(t-1)}+i_\mathrm{g}^{(t)}f(Wc^{(t-1)})$, $h^{(t)}=o_\mathrm{g}^{(t)}c^{(t)}$.&lt;/p&gt;

&lt;p&gt;The temporal Jacobian here would be&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\d c^{(t)}}{\d c^{(t-1)}}=1&lt;/script&gt;

&lt;p&gt;Or to put simply, to obtain the state at time step $t$, RNNs would apply $t$ times the transformation $f$, while LSTMs calculate the increment at each time step and sums them up.&lt;/p&gt;

&lt;h2 id=&quot;implementation-details&quot;&gt;Implementation Details&lt;/h2&gt;

&lt;h4 id=&quot;about-dynet&quot;&gt;About DyNet&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Transpose (&lt;code class=&quot;highlighter-rouge&quot;&gt;dy.tranpose&lt;/code&gt;) requires making a copy of the matrix, so does &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.concatenate_cols&lt;/code&gt; and similar functions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;lstm.disable_dropout&lt;/code&gt; does not work, use &lt;code class=&quot;highlighter-rouge&quot;&gt;lstm.set_dropouts(0, 0)&lt;/code&gt; instead.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Load parameters of LSTM initial state (as in truncated backprop) by:&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;npvalue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# dy.renew_cg()
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batched&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.affine_transform([b, W, x])&lt;/code&gt; for linear layer with biases, this is more efficient.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dy.log_softmax&lt;/code&gt; is more efficient than &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.log(dy.softmax(x))&lt;/code&gt;, and prevents numerical problems. Similarly, &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.pickneglogsoftmax&lt;/code&gt; is better than &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.log_softmax&lt;/code&gt; then &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.pick&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Note the difference between &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.pick&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.pick_batch&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.pick_batch_elem&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;log-probability-domain&quot;&gt;Log-probability Domain&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Addition in log domain is done by the log-sum-exp operation $\ln\sum\exp(x_i)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;DyNet has &lt;code class=&quot;highlighter-rouge&quot;&gt;dy.logsumexp&lt;/code&gt;, and so does Numpy.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;See computation tricks at &lt;a href=&quot;https://hips.seas.harvard.edu/blog/2013/01/09/computing-log-sum-exp/&quot;&gt;https://hips.seas.harvard.edu/blog/2013/01/09/computing-log-sum-exp/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;importance-sampling-1&quot;&gt;Importance Sampling&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;There’s a chance that the ground-truth $w$ is not included in the approximation of the denominator. This could lead to a negative which is bad for optimization.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For a biased solution, we can simply include all targets in the samples. Although effective, this leads to a biased estimator, and deprives the loss of its probabilistic information (it cannot be used to evaluate perplexity).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For an unbiased solution, we can modify the proposal distribution to bias towards to targets. What differs from the above solution is that we still &lt;em&gt;sample&lt;/em&gt; from the distribution, rather than forcibly modifying the samples.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For efficient calculation, we can use the same samples are shared across the mini-batch and time steps. &lt;em&gt;(ref: [[Jozefowicz et al. 2016] Exploring the Limits of Language Modeling][https://arxiv.org/pdf/1602.02410])&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;models--structures&quot;&gt;Models &amp;amp; Structures&lt;/h2&gt;

&lt;h4 id=&quot;latent-predictor-networks-by-w-ling-et-al&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1603.06744.pdf&quot;&gt;Latent predictor networks&lt;/a&gt; by W. Ling et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;When using a normal RNN model, after inference is made, we can backtrack from the final state through to the initial state, resulting in a path&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This is due to that RNNs generated one token at a time, and at each time step samples the next token according to calculated probabilities&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If RNNs can generate multiple tokens in one time step, there may be &lt;u&gt;multiple paths from the initial state to the target state, corresponding to segmentations of the sequence&lt;/u&gt;. Path counts can be exponential to its length, and the union of the paths is a directed acyclic graph&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Paper proposes a method to perform &lt;u&gt;joint training on several predictors of different granularity&lt;/u&gt;. The method introduced latent variables for deciding which predictor to use, thus giving it the name&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To calculate gradients for a time step, &lt;u&gt;summed products of probabilities on the DAG&lt;/u&gt; are required, which can be calculated using a dynamic programming algorithm&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Attention over all different fields in a structured input is used&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prediction is done using beam search&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The authors utilized this technique in code generation tasks for card games, where a character-level LSTM predictor is jointly trained with pointer networks for copying text directly from card descriptions&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;neural-lattice-language-models-by-jacob-grahams-grad-student&quot;&gt;&lt;u&gt;Neural lattice language models&lt;/u&gt; by Jacob (Graham’s grad. student)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Main idea is similar: enabling LSTM models to &lt;u&gt;generate multiple tokens in one time step&lt;/u&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Exact probability is hard to calculate as LSTMs keep track of whole context seen from the initial state, so each path would have a different state&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Paper evaluated different approaches of probability estimations and different representations of multiple-tokens in one time step &lt;em&gt;&lt;u&gt;(more details to be described)&lt;/u&gt;&lt;/em&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Ancestral sampling from “latent sequence decompositions”: just treat multiword tokens as regular tokens&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;TreeLSTM-style summation: summing predecessors’ hidden states. Cons: losses probabilistic info&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Weighted expectation: weight summations using prob. dist. learned in ancestral sampling&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Difference with “&lt;u&gt;latent predictor networks&lt;/u&gt;“&lt;/strong&gt;:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Latent predictor networks combine multiple predictor models, while this is one unified model&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The reason why probabilities are easy to calculate in said paper is due to the fact that, although predictors of different granularity are used, &lt;u&gt;all predicted tokens are in the same space, and multiple tokens are fed into the character-level network one-by-one&lt;/u&gt;. Hidden states of the char-level network is used in the pointer network in turn. So only O(length) states are required in total&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;pointer-networks-by-o-vinyals-et-al&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.03134&quot;&gt;Pointer Networks&lt;/a&gt; by O. Vinyals et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Output is the set of tokens from input, instead of fixed vocabulary&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Basically a seq2seq model with attention, but use attention weights directly as probability from predicting each input token&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Can be trained to select ordered subsets from input, even accomplish difficult tasks as convex hulls, Delauney triangulation and TSP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;See also: &lt;a href=&quot;http://fastml.com/introduction-to-pointer-networks/&quot;&gt;http://fastml.com/introduction-to-pointer-networks/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;treelstms-by-k-s-tai-r-socher-and-christopher-d-manning&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1503.00075.pdf&quot;&gt;TreeLSTMs&lt;/a&gt; by K. S. Tai, R. Socher, and Christopher D. Manning&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A natural generalization of LSTM to tree structures&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sum children hidden states as $\tilde{h}$, and replace this as $h$ in formulas for normal LSTMs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Forget gate is different for each child: use only the hidden state of child to calculate forget gate parameters&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cell state of parent is as usual, summing over cell states of each child with respective forget gates&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ordered children version exists: use different parameters for each child (depending on its index). Such model has a limit on the maximum branch factor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Benefits&lt;/strong&gt;: Can make use of sentence structures generated by parsers; better at preserving state, i.e. can cope better with long distance dependencies (since path lengths are shorter on trees)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;adapted-softmax-by-grave-et-al&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1609.04309.pdf&quot;&gt;Adapted Softmax&lt;/a&gt; by Grave et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Efficient for large vocabularies, and optimized according to empirical analysis of matrix multiplication speed on GPUs:
    &lt;ul&gt;
      &lt;li&gt;For matrices with dimensions $k$, the empirical formula for matrix multiplication time cost is $g(k)=c_\mathrm{m}+\max(0,\lambda(k-k_0))$, where typically $c_\mathrm{m}=0.40\ \mathrm{ms}$, and $k_0=50$.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Proposed structure is a two level hierarchical softmax:
    &lt;ul&gt;
      &lt;li&gt;First level contains all common words (~20% words covering ~80% corpus), and representations of clusters&lt;/li&gt;
      &lt;li&gt;Remaining words are grouped into clusters according to frequency. Words with lower frequency fall into larger clusters.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;highway-networks-by-srivastava-et-al&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1505.00387&quot;&gt;Highway Networks&lt;/a&gt; by Srivastava et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Simply put, &lt;strong&gt;Highway Networks&lt;/strong&gt; add LSTM-style input (a.k.a. transfer) and forget (a.k.a. carry) gates to normal NN layers. Proposed structures uses tied gates (i.e. $f_\mathrm{g}=1-i_\mathrm{g}$). Such structure can be applied to very deep NNs to help training.&lt;/li&gt;
  &lt;li&gt;In practice, transfer gates are initialized with a negative bias to bias the network towards carry behavior. The intuition is the same as initialize forget gates biases to 1 or 2 to enable gradient flow at early stages and preserve long term memories &lt;em&gt;(ref: &lt;a href=&quot;https://pdfs.semanticscholar.org/1154/0131eae85b2e11d53df7f1360eeb6476e7f4.pdf&quot;&gt;[Gers 1999] Learning to Forget…&lt;/a&gt;)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;topic-language-models&quot;&gt;Topic: Language Models&lt;/h2&gt;

&lt;h4 id=&quot;character-aware-neural-lm-by-kim-et-al&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1508.06615&quot;&gt;Character-Aware Neural LM&lt;/a&gt; by Kim et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Each word is fed into a character-level CNN:
    &lt;ul&gt;
      &lt;li&gt;Append SOW and EOW tokens to each word (and zero-pad for batching)&lt;/li&gt;
      &lt;li&gt;Apply 1-d convolution to low-dimension char embeddings&lt;/li&gt;
      &lt;li&gt;Max-pool over all features for each feature map, and concatenate&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Output is fed through a highway layer, i.e. feeding a part of the vector directly through to the output, and transforming the rest.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Output is then fed into an LSTM-LM, making word-level predictions. Two-layer hierarchical softmax is used for large vocabularies.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pros &amp;amp; Cons&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Fewer params than vanilla LSTM-LMs (due to the absence of word vectors).&lt;/li&gt;
      &lt;li&gt;Can deal with OOV inputs, but not outputs; good for morphologically-rich languages.&lt;/li&gt;
      &lt;li&gt;Computationally more expensive.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;topic-embeddings&quot;&gt;Topic: Embeddings&lt;/h2&gt;

&lt;h4 id=&quot;word2vec-by-mikolov-et-al&quot;&gt;&lt;u&gt;word2vec&lt;/u&gt; by Mikolov et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Reference papers: &lt;a href=&quot;https://arxiv.org/pdf/1301.3781.pdf&quot;&gt;CBOW &amp;amp; Skip-gram models&lt;/a&gt;, &lt;a href=&quot;http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf&quot;&gt;Negative sampling&lt;/a&gt;; see also: &lt;a href=&quot;http://web.stanford.edu/class/cs224n/lecture_notes/cs224n-2017-notes1.pdf&quot;&gt;CS224n Lecture Notes 1&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CBOW&lt;/strong&gt; predicts the center word given surrounding (context) words. &lt;strong&gt;Skip-gram&lt;/strong&gt; predicts surrounding words given the center word.
Both methods learn two representations $\mathcal{U}$ (output) and $\mathcal{V}$ (input) for each word, generating output probabilities by $\hat{y}=\mathrm{softmax}(\mathcal{UV}x)$, where $x$ is a one-hot vector (for skip-gram, or average of one-hot vectors for CBOW).
    &lt;ul&gt;
      &lt;li&gt;The “two representation” part, in its essence, is a rank constraint on the matrix. Or in other words, a down projection.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For &lt;strong&gt;negative sampling&lt;/strong&gt;, refer to &lt;a href=&quot;#negative-sampling&quot;&gt;previous section&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Intuition for vector additive compositionality (e.g. skip-gram):
    &lt;ul&gt;
      &lt;li&gt;Due to the linearity in the training objective, summing two vectors would result in summing log probabilities in the output layer.&lt;/li&gt;
      &lt;li&gt;This is equivalent to the product of context word distributions, so words appearing near both words have higher probabilities.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;About the impact of &lt;strong&gt;window size&lt;/strong&gt; on word representations:
    &lt;ul&gt;
      &lt;li&gt;Representations learnt with smaller windows is more aware of &lt;strong&gt;syntactic&lt;/strong&gt; relations.&lt;/li&gt;
      &lt;li&gt;With larger windows, &lt;strong&gt;semantic&lt;/strong&gt; relations are well captured.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;With &lt;strong&gt;subword information&lt;/strong&gt; &lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1607.04606&quot;&gt;[Bojanwoski 2016] Enriching Word Vectors with Subword Information&lt;/a&gt;)&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Replace word embeddings in skip-gram with the sum of n-gram embeddings.&lt;/li&gt;
      &lt;li&gt;Boundary symbols are added to begin and end of words&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/pdf/1607.01759&quot;&gt;fastText&lt;/a&gt;&lt;/strong&gt; classifier:
    &lt;ul&gt;
      &lt;li&gt;Bag of words + Bag of bigrams&lt;/li&gt;
      &lt;li&gt;Feeds average of word/n-gram embeddings through a FC layer&lt;/li&gt;
      &lt;li&gt;Uses very low dimensions (10 for sentiment, 50-200 for tags), very fast&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;context2vec-by-melamud-et-al&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/K16-1006&quot;&gt;context2vec&lt;/a&gt; by Melamud et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Run a Bi-LSTM on the sentence, and use the prefix and suffix hidden state vectors from both LSTMs as the context representation for a given word.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Compared to word2vec&lt;/strong&gt;: The two models basically does the same thing. As context2vec uses LSTMs to generate context reps, it is capable of handling larger contexts and deal with long distance relationships.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;paragraph-vector-by-le--mikolov&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1405.4053&quot;&gt;Paragraph Vector&lt;/a&gt; by Le &amp;amp; Mikolov&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Assign embeddings to each word and each paragraph. For each window, concat the paragraph vector and the first few word vectors and feed through an FC layer predict the last word. (Similar to CBOW)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To generate representation for a new paragraph, train the vector while freezing other parameters.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Another method (similar to skip-gram): sample a random window from the paragraph, and predict words in the window given the paragraph vector.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vectors learnt by the two methods are concatenated for use in downstream tasks.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;c2w-character-to-word-by-w-ling-et-al&quot;&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~lingwang/papers/emnlp2015.pdf&quot;&gt;C2W&lt;/a&gt; (character to word) by W. Ling et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Generate word representations by running a char-level Bi-LSTM.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Author does not generate embeddings directly in an unsupervised fashion; this model is used only in downstream tasks (POS-tagging, LM).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tensor-indexing-model-by-y-zhao--zhiyuan-liu&quot;&gt;&lt;a href=&quot;https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9597/9526&quot;&gt;Tensor Indexing Model&lt;/a&gt; by Y. Zhao &amp;amp; Zhiyuan Liu&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Find common two-word phrases from corpus and replace them by a single phrase token.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Train using skip-gram objective, obtaining embeddings in the same space for the whole phrase and words in the phrase.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Train a composition model approximating the phrase embedding $\mathbf{z}$ given word embeddings $\mathbf{x}$ and $\mathbf{y}$:
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{z}_i=f(\mathbf{x},\mathbf{y})=\mathbf{x}^\top W_i\mathbf{y}+(M\mathbf{x})_i+(N\mathbf{y})_i&lt;/script&gt;
and apply rank constraints on matrices $W_i$, giving $W_i\approx U_i^\top V_i+I$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Loss function is MSE of $\mathbf{z}$ and $f(\mathbf{x},\mathbf{y})$, plus a regularization factor.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;structured-word2vec-by-w-ling-et-al&quot;&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~lingwang/papers/naacl2015.pdf&quot;&gt;Structured Word2Vec&lt;/a&gt; by W. Ling et al&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Simple modifications to original word2vec model, taking &lt;strong&gt;word order&lt;/strong&gt; into consideration.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Structured Skip-gram&lt;/strong&gt;: Use different matrices for each context position.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Continuous Window&lt;/strong&gt;: Concat context vectors instead of summing them.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Such models are better at capturing syntactic information.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;sembei-segmentation-free-word-embeddings-by-t-oshikiri&quot;&gt;&lt;a href=&quot;http://aclweb.org/anthology/D17-1081&quot;&gt;sembei&lt;/a&gt; (segmentation-free word embeddings) by T. Oshikiri&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Based on skip-gram, trains n-gram embeddings.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Only consider cases when the center and context n-grams are adjacent, use separate matrices for left and right contexts (as in &lt;a href=&quot;#structured-word2vec-by-w-ling-et-al&quot;&gt;Structured Word2Vec&lt;/a&gt;).&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Theoretically capable of dealing with arbitrary sized windows, a sample is regarded as positive as long as there exists such a segmentation of the corpus into the chosen n-grams. But this is computationally expensive.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Limitations&lt;/strong&gt;: N-grams are the model’s vocabularies, i.e. it provides no means of composition, thus cannot deal with OOV words.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;topic-dependency-parsing&quot;&gt;Topic: Dependency Parsing&lt;/h2&gt;

&lt;h4 id=&quot;task-description&quot;&gt;Task Description&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Generate a tree structure over a sentence, describing dependency of words.&lt;/li&gt;
  &lt;li&gt;A directed tree, with a label for each edge, denoting the type of dependency.&lt;/li&gt;
  &lt;li&gt;There can be multiple roots for a single sentence, especially when the sentence is conjoined by conjunctions (e.g. “and”).&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;methods&quot;&gt;Methods&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Methods can be basically categorized into one of the two:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Transition-based methods&lt;/strong&gt;: Shift-reduce parsers that acts like a pushdown automata, at each time step the model can choose to either SHIFT (push word to stack), or REDUCE (pop the top two words from stack, assign one of the as the parent of the other, and push the parent back into the stack). More complicated models support other actions. These methods often make local decisions, and use greedy decoding.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Arc-factored graph-based methods&lt;/strong&gt;: Assign likelihood for each ordered pair of nodes, and for each label type. Run Chu-Liu-Edmonds’ algorithm for maximum spanning arborescence. These methods usually make global decisions.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;deep-biaffine-attention-by-t-dozat--manning&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.01734&quot;&gt;Deep Biaffine Attention&lt;/a&gt; by T. Dozat &amp;amp; Manning&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Refer to code implementations: &lt;a href=&quot;https://github.com/chantera/teras/blob/master/teras/framework/pytorch/model.py&quot;&gt;https://github.com/chantera/teras/blob/master/teras/framework/pytorch/model.py&lt;/a&gt; and &lt;a href=&quot;https://github.com/chantera/biaffineparser/blob/master/pytorch_model.py&quot;&gt;https://github.com/chantera/biaffineparser/blob/master/pytorch_model.py&lt;/a&gt; (two parts of one code)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An arc-factored graph-based method. Similar to self-attention.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Runs a Bi-LSTM over the sentence, then passes each state through 4 separate MLPs, to generate embeddings for the word, when used as both dependant and head, and when used in predicting arc head and edge label.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Recurrent state: $\mathbf{r}_i$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Embeddings: $H^{({\text{arc-dep}})} = [\cdots \mathbf{h}_i^{(\text{arc-dep})} \cdots]$, $\mathbf{h}_i^{\text{arc-dep}} = \mathrm{MLP}^{(\text{arc-dep})}(\mathbf{r}_i)$.&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;and similarly for “arc-head”, “label-dep”, and “label-head”.&lt;/li&gt;
          &lt;li&gt;This serves as dimensionality reduction.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Arc scores for word $i$ (i.e. the likelihood of each word being the dependency head of $i$), vector length = sentence length:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathbf{s}_i^{(\text{arc})} &amp; = {H^{(\text{arc-head})}}^\top \left( U^{(\text{arc-1})}\mathbf{h}_i^{(\text{arc-dep})} + \mathbf{u}^{(\text{arc-2})} \right) \\
 &amp; = {H^{(\text{arc-head})}}^\top U_b^{(\text{arc})}
        \left[\begin{matrix} \mathbf{h}_i^{(\text{arc-dep})} \\ 1 \end{matrix}\right]
\end{align*} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Score of label type $k$, for word $i$, given its &lt;u&gt;true head&lt;/u&gt; $y_i$, vector length = number of label types:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathbf{s}_i^{(\text{label}_k)} &amp; = {\mathbf{h}_{y_i}^{(\text{label-head})}}^\top U_k^{(\text{label-1})} \mathbf{h}_i^{(\text{label-dep})} + {\mathbf{u}^{(\text{label-2,1})}}^\top\mathbf{h}_i^{(\text{label-dep})} + {\mathbf{u}^{(\text{label-2,2})}}^\top\mathbf{h}_{y_i}^{(\text{label-head})} + b_k \\
 &amp; = \left[\begin{matrix} \mathbf{h}_{y_i}^{(\text{label-head})} \\ 1 \end{matrix}\right]^\top
       U_b^{(\text{label})}
       \left[\begin{matrix} \mathbf{h}_i^{(\text{label-dep})} \\ 1 \end{matrix}\right]
       - 1 + b_k
\end{align*} %]]&gt;&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Scores are equivalent to affine transformations on two vectors, hence the name.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Loss = neg log softmax of correct head for each node, plus neg log softmax of correct type for correct head for each node.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Needs to run Chu-Liu’s algorithm during prediction. Select argmax type for each predicted edge.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When the formulae are expanded, they take the same form as the &lt;a href=&quot;#tensor-indexing-model-by-y-zhao--zhiyuan-liu&quot;&gt;Tensor Indexing Model&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;topic-variational-auto-encoder&quot;&gt;Topic: Variational Auto-encoder&lt;/h2&gt;

&lt;h4 id=&quot;formulation-of-vae&quot;&gt;Formulation of VAE&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Ref to: &lt;a href=&quot;https://arxiv.org/pdf/1606.05908&quot;&gt;Tutorial on Variational Autoencoders&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;the-first-formula&quot;&gt;The first formula&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;To build a generative model, we need to approximate the distribution $P(X)$ where $X$ is our data (things to generate).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An intuitive method is to first extract features $\mathbf{z}$ from $X$’s, and use a model parameterized by $\theta$ to recover $X$ given $\mathbf{z}$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The features $\mathbf{z}$ are called &lt;strong&gt;latent variables&lt;/strong&gt; (means “hidden”) because they’re not &lt;em&gt;observed&lt;/em&gt; but &lt;em&gt;inferred&lt;/em&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Following the law of total probability, we have&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X) = \int P_\lambda(\mathbf{z}) P_\theta(X\mid\mathbf{z})\d\mathbf{z} = \mathbb{E}_{\mathbf{z}\sim P_\lambda}[P_\theta(X\mid\mathbf{z})]&lt;/script&gt;

    &lt;p&gt;where $P_\lambda(\mathbf{z})$ is our &lt;strong&gt;prior&lt;/strong&gt; knowledge of the space of latent variables, and $P_\theta(X\mid\mathbf{z})$ if the likelihood approximated by our model, parameterized by $\theta$. In modern context, $\theta$ can be seen as the &lt;strong&gt;decoder&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Naturally, our objective would be to maximize the expectation of the marginal log-probability over the data distribution, $\mathbb{E}_{X\sim D}[\log P(X)]$. This is a form of maximum likelihood estimation (MLE).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;simplify-calculations-introducing-posterior&quot;&gt;Simplify calculations: Introducing posterior&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;But such integration is intractable for three reasons:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;The space of $\mathbf{z}$ is large.&lt;/li&gt;
      &lt;li&gt;Monte Carlo sampling would not be effective because $P_\theta(X\mid\mathbf{z})$ is likely to be zero for most $\mathbf{z}$’s.&lt;/li&gt;
      &lt;li&gt;We want to run optimization in mini-batches. Consider maximizing the objective w.r.t. a single data example $X$, we’re effectively increasing the probability of $X$ given any latent $\mathbf{z}$. This is clearly counter-intuitive.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;From the second reason, it is natural to consider using &lt;strong&gt;importance sampling&lt;/strong&gt; to speed up sampling procedure. Thus we introduce a distribution $Q_\phi(\mathbf{z}\mid X)$, which gives high probability to latent $\mathbf{z}$’s that would in turn give high probability to the example $X$. This is the &lt;strong&gt;posterior&lt;/strong&gt; distribution matching its prior. In modern context, $\phi$ can be seen as the &lt;strong&gt;encoder&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;With the posterior in mind, we can rewrite the objective&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X) = \mathbb{E}_{\mathbf{z}\sim Q_\phi(\cdot\mid X)}\left[ \frac{P_\lambda(\mathbf{z})P_\theta(X\mid\mathbf{z})}{Q_\phi(\mathbf{z}\mid X)} \right]&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;simplify-calculations-log-probability-domain--kl-divergence&quot;&gt;Simplify calculations: Log-probability domain &amp;amp; KL-divergence&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;To match our objective, we try transform everything into the log-probability domain. But the logarithm function cannot be moved inside the expectation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;However, &lt;strong&gt;Jensen’s inequality&lt;/strong&gt; states that for any convex function $f$ and random variable $X$, we have $f(\mathbb{E}[X]) \leq \mathbb{E}[f(x)]$. For concave functions like $\log$, the opposite conclusion holds. Thus we derive a lower bound on $\log P(X)$:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\log P(X) &amp; \geq \mathbb{E}_{\mathbf{z}\sim Q_\phi(\cdot\mid X)}\left[ \log\frac{P_\lambda(\mathbf{z})P_\theta(X\mid\mathbf{z})}{Q_\phi(\mathbf{z}\mid X)} \right] \\
 &amp; \geq \mathbb{E}_{\mathbf{z}\sim Q_\phi(\cdot\mid X)}\left[ \log P_\lambda(\mathbf{z}) + \log P_\theta(X\mid\mathbf{z}) - \log Q_\phi(\mathbf{z}\mid X) \right]
\end{align*} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Observe that the above formulation can be rewritten as&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\log P(X) \geq \mathbb{E}_{\mathbf{z}\sim Q_\phi(\cdot\mid X)}[\log P_\theta(X\mid \mathbf{z})] - \mathrm{KL}(Q_\phi(\mathbf{z}\mid X)\Vert P_\lambda(\mathbf{z}))&lt;/script&gt;

    &lt;p&gt;where the second term is the KL-divergence given by $\mathrm{KL}(q\Vert p) = H(p,q)-H(q)$, the difference of cross-entropy and entropy.&lt;/p&gt;

    &lt;p&gt;The RHS is also known as &lt;strong&gt;Evidence Lower Bound&lt;/strong&gt; (ELBO) $\mathcal{L}(X;\phi,\theta,\lambda)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The lower bound can be interpreted as:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Maximizing the likelihood w.r.t. the posterior of latent $\mathbf{z}$ given the trained example $X$, and&lt;/li&gt;
      &lt;li&gt;Regularizing the posterior distribution by pulling it close to the prior.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;how-do-we-compute-the-lower-bound&quot;&gt;How do we compute the lower bound?&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We should first define the form for our prior and posterior. A common choice is to use a Gaussian distribution (or a mixture of Gaussians). There are two reasons for this:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;For the prior, an univariate Gaussian distribution defined on $\mathbb{R}$ is able to represent any distribution by composing the inverse CDF of the desired distribution with the CDF of a Gaussian. This also holds true for multiple dimensions. So we can trust our decoder to learn this mapping, which shouldn’t be too difficult for neural network models.&lt;/li&gt;
      &lt;li&gt;For the posterior, using a Gaussian distribution means that we only have to specify the mean $\mu$ and variance $\sigma^2$. Also, such settings gives an analytical solution to the KL-divergence term.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the first term, given the assumption that $Q_\phi$ is able to produce a nice estimate of the posterior, we can safely use Monte Carlo sampling, i.e. sample $\mathbf{z}$ from distribution $Q_\phi$, and optimize for $\log P_\theta(X\mid\mathbf{z})$.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;However, in terms of SGD, this is not acceptable, because “sampling” is indifferentiable.
        &lt;ul&gt;
          &lt;li&gt;To see why this is true, note that for the term we backprop w.r.t. the negative log likelihood, which is dependent only on $\mathbf{z}$.&lt;/li&gt;
          &lt;li&gt;However, $\mathbf{z}$ is sampled from $Q_\phi$, but it is introduced into $P_\theta$ as “input”, which has no gradient. So the gradient is cannot be backpropped through the sampling procedure.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;So a re-parameterization trick must be applied: since $Q_\phi$ is Gaussian $\mathcal{N}(\mu,\sigma^2)$, sampling $z\sim \mathcal{N}(\mu,\sigma^2)$ is equivalent to sampling $\epsilon\sim\mathcal{N}(0,1)$ and compute $z=\mu + \sigma\cdot\epsilon$. Thus gradient is able to flow through the encoder. &lt;em&gt;(ref: &lt;a href=&quot;https://arxiv.org/pdf/1312.6114&quot;&gt;[Kingma &amp;amp; Welling 2013] Autoencoding Variational Bayes&lt;/a&gt;)&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the second term, given Gaussians $P(\mathbf{z})=\mathcal{N}(0,I)$ and $Q_\phi(\mathbf{z}\mid X)=\mathcal{N}(\pmb{\mu}(X),\pmb{\Sigma}(X)=\mathrm{diag}(\pmb{\sigma}^2(X)))$, denoting $n$ as the dimensionality of $\mathbf{z}$, KL-divergence has the following analytical form
&lt;script type=&quot;math/tex&quot;&gt;\mathrm{KL}(Q_\phi(\mathbf{z}\mid X)\Vert P(\mathbf{z})) = \frac{1}{2}\sum_{i=1}^{n}\left(1+\log(\sigma_i^2) - \mu_i^2 - \sigma_i^2\right)&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;when-does-equality-hold-true&quot;&gt;When does equality hold true?&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;To investigate the problem, subtract the RHS from LHS. But first, we make the assumption that our parameterized model is able to model the ground truth likelihood. Thus in the following deduction, we omit the subscripts on $P$:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
 &amp; \phantom{=\;\;\!} \log P(X) - \mathbb{E}_{\mathbf{z}\sim Q_\phi(\cdot\mid X)}\left[ \log P(\mathbf{z}) + \log P(X\mid\mathbf{z}) - \log Q_\phi(\mathbf{z}\mid X) \right] \\
 &amp; = \log P(X) - \mathbb{E}_{\mathbf{z}\sim Q_\phi(\cdot\mid X)}\left[ \log P(\mathbf{z}) + \left(\log P(\mathbf{z}\mid X) + \log P(X) - \log P(\mathbf{z})\right) - \log Q_\phi(\mathbf{z}\mid X) \right] \\
 &amp; = \mathbb{E}_{\mathbf{z}\sim Q_\phi(\cdot\mid X)}[\log Q_\phi(\mathbf{z}\mid X) - \log P(\mathbf{z}\mid X)] = \mathrm{KL}(Q_\phi(\mathbf{z}\mid X)\Vert P(\mathbf{z}\mid X))
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;where $P(\mathbf{z}\mid X)$ is the true posterior. So the closer $Q_\phi$ matches the true posterior distribution, the tighter our lower bound is.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This also shows another reason why we choose to optimize the lower bound instead: this KL-divergence term is intractable, because we have no idea which $\mathbf{z}$’s give high probability to $X$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;faq&quot;&gt;FAQ&lt;/h5&gt;

&lt;p&gt;With the knowledge in mind, we can look back at some problems that was glossed over:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Why is a simple Gaussian sufficient for prior?&lt;/strong&gt; Apart from the “NN can learn any CDF” reason, we use Gaussian also because it is a commonly-used distribution with a non-zero probability for every point in $\mathbb{R}$. And the fact that not all distributions can be re-parameterized.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Why do we constrain the KL-divergence of posterior $Q_\phi$ and prior $P_\lambda$?&lt;/strong&gt; This does not make sense in that if this term is minimized, then the KL-divergence term on the other side of the equation, namely $\mathrm{KL}(Q_\phi(\mathbf{z}\mid X)\Vert P(\mathbf{z}\mid X))$ would be large, which gives us a loose lower bound. This term mainly serves as &lt;strong&gt;regularization&lt;/strong&gt;, for we’re using NNs for $Q_\phi$, and we should constrain its form.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;possible-issues&quot;&gt;Possible issues&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Over-regularization&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;KL-divergence takes a simple form for simplistic priors, and is much easier to learn. Encoder would quickly match the Gaussian prior.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Solutions&lt;/strong&gt;:
        &lt;ul&gt;
          &lt;li&gt;Initially set KL-divergence term to zero, and gradually anneal to a predefined scale. Can be seen as first overfitting and then regularizing.&lt;/li&gt;
          &lt;li&gt;Or, design more complex priors.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ignoring latent code&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;For sequential decoders, a simple latent code would force the model to rely on the ground truth of previous time steps, and a powerful model may learn decoding without consulting the latent code.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Solutions&lt;/strong&gt;:
        &lt;ul&gt;
          &lt;li&gt;Apply dropout on decoder inputs.&lt;/li&gt;
          &lt;li&gt;Or, constraining the amount of context that the decoder is allow to see.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;extensions&quot;&gt;Extensions&lt;/h4&gt;

&lt;h5 id=&quot;conditional-vae&quot;&gt;Conditional VAE&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Autoencode $X$ given $Y$, for instance generate user content given his previous work.&lt;/li&gt;
  &lt;li&gt;Simply change $Q_\phi$ and $P_\theta$ to conditional distributions. This means both the encoder and decoder needs to condition on $Y$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;discrete-latent-variables&quot;&gt;Discrete Latent Variables&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Reparameterization trick fails for discrete distributions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Marginalize over every possible discrete choice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Or, use the &lt;a href=&quot;#gumbel-max-trick--gumbel-softmax-distribution&quot;&gt;Gumbel-Softmax&lt;/a&gt; technique.&lt;/p&gt;

    &lt;p&gt;​&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Zecong Hu</name></author><summary type="html">This post records my notes taken during summer internship @ CMU LTI. Disclaimer: These notes are not guaranteed to be correct or understandable. Note: This is a non-mobile-friendly post, mobile view is distorted due to formulae.</summary></entry><entry><title type="html">大三上总结</title><link href="http://zecong.hu/2017/01/28/my-5th-semester-in-college/" rel="alternate" type="text/html" title="大三上总结" /><published>2017-01-28T14:24:00+00:00</published><updated>2017-01-28T14:24:00+00:00</updated><id>http://zecong.hu/2017/01/28/my-5th-semester-in-college</id><content type="html" xml:base="http://zecong.hu/2017/01/28/my-5th-semester-in-college/">&lt;p&gt;转眼间又一个学期过去了。传闻中最可怕的一个学期也就这样平安无事地度过了。大学的生活也已经过半了。&lt;/p&gt;

&lt;p&gt;感伤的事越来越多，同时也日渐对未知的未来感到恐慌。从大二思考到现在，仍然不知道该选怎样的出路。&lt;/p&gt;

&lt;p&gt;不过，或许开头应该喜庆一点，那这一部分留到最后再说好了。&lt;/p&gt;

&lt;p&gt;总之，这是事多的一学期，也是很充实很开心的一学期。这次不想事无巨细地写篇流水账了，只挑重点的讲。另外，这次准备多放点图，希望大家能看得开心。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;小学期&quot;&gt;小学期&lt;/h2&gt;

&lt;p&gt;虽然小学期不应该算在大三上里边，但我从6月底在家呆了4天就回到学校之后，直到1月中旬放寒假，期间一直没有回家。对我来说，从去台湾开始到大三上结束，整个这么一段时间都是连起来的。&lt;/p&gt;

&lt;p&gt;大二下的总结就是在 Java 小学期在台湾的时候写的，可见当时多么闲。从台湾回来之后就开始做大作业了，过上了正常的码农生活。所幸当时天龙和韦师也在学校，每天的生活不至于无聊到过不下去。大作业要写一个网络对战的翻转棋，基本上就是大一小学期的五子棋的翻版了。说实话挺没意思的，感觉不如学安卓开发有意义。但不管怎么样，这也是我花时间最多，完成度最高的一个大作业。一共花了10天的时间，写了200多KB的（Java）代码。最后的结果也算令我满意了吧，虽然只学到了一些多半派不上用场的东西。贴一下 GitHub 链接骗流量：&lt;a href=&quot;https://github.com/huzecong/ReversiDuel&quot;&gt;https://github.com/huzecong/ReversiDuel&lt;/a&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图0：大作业 ReversiDuel 截图
&lt;img src=&quot;https://github.com/huzecong/ReversiDuel/raw/master/doc/image-hd/game-board.jpg&quot; alt=&quot;ReversiDuel&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;之后就是汇编小学期了。整整5周，闲的不行。不过因为还有 FPGA 和 ACM 这两件事，所以过的也还算充实，详细的下面讲。整门课都不难，但不知道是考试粗心还是有次作业没交上= =最后分数一般。&lt;/p&gt;

&lt;h2 id=&quot;香港的奇妙-acm-比赛&quot;&gt;香港的奇妙 ACM 比赛&lt;/h2&gt;

&lt;p&gt;这个的确是机缘巧合。一天方块突然来找我，问我愿不愿意组队参加一个香港的 ACM 比赛。似乎是我校、港科技和国立清华每年会举办一场 ACM 友谊赛，每个学校派两个队。邬老师觉得方块在这方面非常积极就找了他，他就找了我。我想可以免费旅游为什么不去，于是也拉上了黄大大。后来发现还有三位三字班的学长和11也会一起去。&lt;/p&gt;

&lt;p&gt;比赛就是老年人友谊赛嘛，最后侥幸拿了第一，还获得了一些奖金。比赛的时候非常好玩，有一道裸的最大密度子图的题，我们三个老年人都觉得自己写不出网络流，就放到了比赛最后才写😂可惜没能在结束前调出来。&lt;/p&gt;

&lt;p&gt;香港的环境还是很好的，港科技的校园也很漂亮。不过香港物价是真高= =最后有一天可以用来旅游，去海洋公园转了一圈。美中不足大概就是回来的时候错过了汇编的一个 DDL 吧= =可能就是这次作业没交上。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图1：港科技校园的一部分
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/1-hkust-campus.jpg&quot; alt=&quot;港科技校园的一部分&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;fpga-设计大赛&quot;&gt;FPGA 设计大赛&lt;/h2&gt;

&lt;p&gt;这是个持续了整整半年的大坑。&lt;/p&gt;

&lt;p&gt;事情的起因是这样的。我和韦师和天龙在大二下选了《数字逻辑设计》这门课，大作业组了一队。这门课的老师安利了一个 FPGA 的设计比赛，我们几个抱着试一试的心态就参加了。结果发现最后就我们一组报名。也因此，我们在做大作业的时候用了另外一块厉害一点的板子，也定了一个比较远大的目标。到期末的时候，实际上做出来的东西比我们预期的要逊色不少，但比赛还远远没有结束，因此说暑假的时候大家早点回学校来搞板子。这也是为什么我从台湾回去的时候，韦师和天龙已经在学校了。&lt;/p&gt;

&lt;p&gt;我们的设想是做一套廉价的类似 AR 的设备。用户用一支特制的绘制笔在空中绘图，由两个摄像头捕捉画面并测距，以算出笔在现实世界中的坐标。依此用户可以绘制一些三维的模型，我们则将其渲染出来并叠加在屏幕上显示。&lt;/p&gt;

&lt;p&gt;听上去挺厉害的吧。但我们在课程结束的时候只做到了：在屏幕上显示摄像头的黑白图像，然后画一个内置图形的线框上去，还可能按概率出现各式奇妙的现象。所以我们暑假花了整整一个月的时间搞这个事情。先是修复了一大堆潜在的时序 bug，然后终于弄明白了怎么让摄像头给我们彩色图形；然后兵分三路，我写识别和测距，天龙写渲染，韦师继续肝硬件部分。到复赛提交 DDL 之前连着熬了两天，总算是弄出了个像样的玩意儿，拍了个视频交了上去。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图2：测距算法调试现场
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/2-debugging-distance-measurement.jpg&quot; alt=&quot;测距算法调试现场&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;＊&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图3：复赛版本的系统
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/3-fpga-system.jpg&quot; alt=&quot;复赛版本的系统&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当时肝完这波正好第二天就去香港打 ACM 了。等到听到进了决赛的消息已经是9月中旬了。决赛在10月中旬，也就是说我们在去比赛之前还有差不多一个月时间用来调整和包装。现在这个系统虽然能 work，但还是不太稳定，而且卖相不好。之前说的“绘制笔”，我们都是直接拿一张绿色纸片代替的；上图中连接两个摄像头的那根金属棍，其实是我买的拆机工具，拿强力胶黏上去的。&lt;/p&gt;

&lt;p&gt;李山山老师非常慷慨地让我们随便用实验室里的器材。我们用 3D 打印机打出了一个棒棒糖一样的物体来当绘制笔；然后把散成一团的杜邦线换成了自制的排线，又设计了一个摄像头支架和底座，以取代这根手一抖就掉下来了的金属棍。我们也修复了一些 bug，把界面弄得逼格高了一点，然后用上了毕生所习得的装逼技巧写了一份 paper，做了一张 poster。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图4：第一根&lt;del&gt;棒棒糖&lt;/del&gt;绘制笔，真的是个球体
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/4-first-lollipop-pen.jpg&quot; alt=&quot;棒棒糖&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;＊&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图5：仿佛是在金工实习
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/5-rough-polishing.jpg&quot; alt=&quot;金工实习&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;＊&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图6：展示现场的成品系统，左边是我们的poster
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/6-onsite-workshop.jpg&quot; alt=&quot;展示现场&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;线下的决赛在武汉。主办方提供的住宿条件不错，在那边我们又通了个宵，我在做展示幻灯片和写演讲稿，韦师和天龙在修一些奇妙的 bug。最后演讲似乎得到了外籍专家的肯定，展示也平安无事地度过了。这里有几个特别好玩的事情：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;到了现场我们才发现我们对于这个比赛设计目标的理解和其他人好像不太一样；放眼全场，基本上只有我们做的是纯 FPGA 的设计，别人都用到了板子上搭载的 Intel CPU，跑上了 Linux，然后开始搞单片机编程= =很多组也都用了很高端的外设，还有现成的机器人套装之类的。这让走纯技术路线的我们感觉格格不入。&lt;/li&gt;
  &lt;li&gt;因为我们的目标是做一套廉价 AR 设备，所以用了最便宜的摄像头（13块一个）。这个摄像头什么都好，就是看啥都是绿的；而我们的识别目标的颜色也恰好是绿的。更尴尬的是，从上图中可以看到，展示摊位所有的桌布，也都是绿的。因此我们为了在现场取得好的效果，需要派人挡住后面的桌子和（不知道为什么有时也会被认为是绿色的）墙壁。这就是为什么屏幕上显示的是三个人的胯部。&lt;/li&gt;
  &lt;li&gt;展示是一个类似 workshop 的形式，每组摆个摊，三波专家轮流转。有一位专家特别实在，在和周围人交流的时候一不小心说出了实话：“他们这个设计啊，吹的是——啊不说的是，……”这句话很好地道出了在本次比赛中，什么才是核心竞争力。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最后，鉴于我们优秀的装逼技巧和精湛的演技，我们获得了特等奖（一共三组）。总的还是很开心的（毕竟钱还不少），而且也算是对这半年断断续续的付出的一种肯定吧。虽然不知道干的这些对自己有什么用，虽然中途也遇到过瓶颈，虽然也一度觉得麻烦感到后悔，但至少，整个过程还是很开心的。我想这就够了。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图7：奖状和看上去很霸气的奖金牌子
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/7-certificate-and-prize.jpg&quot; alt=&quot;奖状和奖金&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;＊&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图8：看上去很高兴的李山山老师和不知道为什么愁眉苦脸的我们
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/8-group-photo-of-us-and-our-teacher.jpg&quot; alt=&quot;FPGA现场合影&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;文艺部&quot;&gt;文艺部&lt;/h2&gt;

&lt;p&gt;其实留在文艺部也挺偶然的。我在大二下刚开始的时候表示对文艺工作有兴趣，有留部的意向。当时枫哥就让我和玉涵、王老板和徐玥一起管系歌赛的事情。但我其实没管事，只被分配做现场的道具负责，以及负责宣传视频的拍摄和剪辑。然后我就发现，我对这类需要与很多人打交道的工作，实在是不擅长而且不感兴趣。和参赛选手联系确定拍摄时间的时候简直要把我烦炸了，而且五一去日本玩了，还拜托了好几位留在学校的同学帮忙跟拍，感觉很对不起他们。回来之后发现视频还没剪，又是家晖大腿强力 carry 我和晖榕一起剪的。最后的系歌赛，平心而论，感觉也没有达到预期的效果。这让我有点打退堂鼓，再加上这个学期课业繁重，也想在学习上多花一点时间，所以其实我当时是不想留下的。&lt;/p&gt;

&lt;p&gt;但我似乎没有和别人说这个事，因此我们四人就直接被钦定成为下任部长了。当时我的想法大概是，既然当上了部长就好好干吧，反正搞完学生节就没什么事了，而且说实话还是挺有意思的。&lt;/p&gt;

&lt;p&gt;后来面试部员的时候让我改变了想法。因为这群人实在是太有趣了，很活泼很开朗。整个面试和在科协那边面试的时候气氛完全不一样，面试的那天晚上也是赶图形学大作业那阵子最开心的一个晚上。感觉和这群人一起共事应该会很开心。&lt;/p&gt;

&lt;p&gt;一学期忙碌的社工就开始啦。虽然这么说，但最忙的还是副主席玉涵，我基本上就是每周一晚上去开个例会，然后围观分锅现场而已。舞会没什么大事，但我又一次没能去成，那个时候正好参加 FPGA 的比赛去了。&lt;/p&gt;

&lt;p&gt;学生节才是工作的重头戏。之前分工作方向的时候，我被分到的是主管宣传，其实大概就是每次去催被分到设计任务的部员，然后充当甲方的角色不断提需求给建议。&lt;/p&gt;

&lt;p&gt;宣传工作从期中就差不多开始了，一直持续到14周办完学生节。具体的事情太多了，一些小事也不太记得了。大概讲一些印象深刻的吧。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;宣传小组的第一次会&lt;/strong&gt;。小组成立一周之后 Logo 还是没有想法，于是只能在开完例会之后留下来加班加点头脑风暴。意外地，大家都提出了不错的想法，在一片欢声笑语中想出了不少不错的方案。虽然最后都被毙了，但回忆起来，这天晚上还是记忆犹新。这样的会之后也开过一两次，最后在多方努力下，终于有了我们的Logo。
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/student-gala-logo.jpg&quot; alt=&quot;Logo&quot; /&gt;
关于 Logo 设计过程中诞生的各种有趣的中间版本，如果有兴趣，可以看&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NzAyMzMxMA==&amp;amp;mid=2658640562&amp;amp;idx=1&amp;amp;sn=cc9c7714f1749e8aeb740ed46186a768&quot;&gt;这篇推送&lt;/a&gt;了解一下。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;节目三审&lt;/strong&gt;。其实确定工作方向的时候我还被分到了节目质量确保。三审那天正好还是 CCSP 比赛的日子，这个比赛非常猎奇，从早上9点打到晚上9点。但三审是下午，所以我打到一半就溜了出来，不仅放弃了获奖的机会，还花了100多块钱打车回了学校。但其实在三审现场我也没干什么，一方面提不出什么有建设性的意见，另一方面也有很多大佬在场，基本上能指出的问题都指出来了。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;系列活动&lt;/strong&gt;。其实一开始听到这个方案的时候，我的第一想法是“好蠢啊”。正好提出方案的那次例会我也不在，总之就确定成这个形式了。但意料之外的是，系列活动却大受好评，连一向觉得活动没意思的非常挑剔的室友都觉得还不错。不过的确，最后成型的样子和我们设想的也不一样，过程中我们也不断完善不断调整了活动形式。虽然中间有一些小插曲，但结果是好的就行。
于我来说，我在这里面干的活主要是搭了两个网站作为活动四和活动六。活动四是定制带 Logo 的图片，活动六是玩八数码游戏。也算是发挥作为一名前端的余热吧。顺便贴一下链接：
    &lt;ul&gt;
      &lt;li&gt;活动四：&lt;a href=&quot;https://hashtag.net9.org/&quot;&gt;https://hashtag.net9.org/&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;活动六：&lt;a href=&quot;https://hashtag.net9.org/puzzle/&quot;&gt;https://hashtag.net9.org/puzzle/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;各式宣传品&lt;/strong&gt;。大概从学生节倒数10天的时候开始，各式宣传品就分批次地送去制作了。对我来说，就是要一边催锅，一边和文印确认细节，同时还要听搜狗爸爸的话把他们的 Logo 到处加。这期间也诞生过一些令我不满意的宣传品，基本上都是我自己参与了的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;校会推送&lt;/strong&gt;。不知怎么地，我们有一部分非常苹果风的推送，于是校会推送也准备走苹果风。院长写了一些逼格很高的文案，我则仿照苹果官网的风格做图。也是从下午做到凌晨，最后发出来是学生节的前一天。阅读量还挺高的，挺欣慰的。这里也厚脸皮地贴一下&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA3NTAwMDczOA==&amp;amp;mid=2649713991&amp;amp;idx=3&amp;amp;sn=8dc7883bbae18a6e33ee817bc3f7ce06&quot;&gt;推送链接&lt;/a&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;之后就是现场工作了。我在现场是下台口负责人，但本来这次学生节的舞台类节目就少，下台口就更是闲了。基本上整场晚会我都是呆站在下台口，望着热闹非凡的上台口。中间出了个小状况，就是有一个手麦突然接触不良，临时改用了头麦。幸好大家配合默契，没有导致 bug。整场晚会还是比较平稳的吧，至少从我的视角看上去没有问题。&lt;/p&gt;

&lt;p&gt;晚会之后一起去聚餐，因为有这群会玩的人，气氛比去年要热烈不少。这次也刷新了我去年的记录，成了喝的最多的一次（但我酒量本来就小，所以其实也没喝多少），出门的时候感觉有点走不直了。之后又和大家一起在 KTV 唱到6点才回去，第一次体验到宿醉的感觉。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图9：晚会现场的文艺部合影
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/9-group-photo-of-art-dept.jpg&quot; alt=&quot;文艺部合影1&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;＊&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;图10：聚餐中的文艺部合影
&lt;img src=&quot;/assets/images/2017/01/28/my-5th-semester-in-college/10-group-photo-of-art-dept-having-dinner.jpg&quot; alt=&quot;文艺部合影&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;之后的几天真的有种怅然若失的感觉，就像是追了很久的漫画完结了一般。记得在大二上的总结里说，还想再体验一次学生节结束那一刻的喜悦。算是遂了这个愿了，只是可惜也没有机会再实现一次这个愿望了。&lt;/p&gt;

&lt;p&gt;再回到最开头。如果再让我选一次，我还会不会愿意加入文艺部？&lt;/p&gt;

&lt;p&gt;当然。几次都愿意。&lt;/p&gt;

&lt;h2 id=&quot;学习&quot;&gt;学习&lt;/h2&gt;

&lt;p&gt;下面是惯例的课程无责任吐槽时间。从上面非学习部分的篇幅就能看出，我这学期没在学习上花多少时间。说实话这学期课程门数少，但每个任务量都不小。而我仍然贯彻着一直以来“能做大作业就多做大作业”的理念，因此作死地参加了几乎所有可能的挑战项目，成为了好几个不同的组里的猪队友。&lt;/p&gt;

&lt;p&gt;而至于四大原理的期末考试，也是深刻体会到了什么叫“死猪不怕开水烫”。每门考试大概都是从考前24小时开始连轴通宵复习，中间睡大概4个小时。真的是梦回大二上。理所当然地，考试成绩很差。而且这学期的平均分似乎都很低，不知道为什么。&lt;/p&gt;

&lt;h3 id=&quot;计算机网络原理&quot;&gt;计算机网络原理&lt;/h3&gt;

&lt;p&gt;四大原理之一。84分。中位数左右。&lt;/p&gt;

&lt;p&gt;没什么可抱怨的，因为这门课真的没有学。三次实验基本上都是参考别人的写的，5次课堂小测只去了两次，作业也是一边看书现学一边看答案写的。&lt;/p&gt;

&lt;p&gt;硬要找借口的话，对网络也不太有兴趣吧。虽然觉得了解一些是必要的，但这门学科总给我一种在过去犯下的错误上不断修补的感觉。可能和工程结合紧密就是这样的吧。&lt;/p&gt;

&lt;h3 id=&quot;信号处理原理&quot;&gt;信号处理原理&lt;/h3&gt;

&lt;p&gt;四大原理之二。89分。25%左右？&lt;/p&gt;

&lt;p&gt;这个分数实在是不好看，因为我其实是做了额外的大作业的，估算应该是加了10分。期末考试分数实在太低，外加缺交了一次虽然蠢到想骂人但似乎比较关键的作业。&lt;/p&gt;

&lt;p&gt;其实这个额外的大作业很划得来，一来和信号本身关系不大，不会也能做；二来工作量也不算大，相比起加分来说性价比很高。唯一不爽的大概是得多和徐明星见几面吧。我和 wyx 一组，做的是语音和音乐的分割；找了篇论文实现了一下，瞎炼了一份丹，在吹逼达人 wyx 的 carry 下做了个逼格不错的展示。或许在这里我还算不上猪队友吧，多少有一点点贡献。&lt;/p&gt;

&lt;p&gt;这也是需要和徐明星打交道的最后一门课。感觉这个人就是很奇怪。比如那次很蠢的作业，是有一次他发现上课的人实在太少，于是在课堂上闹脾气，要大家把课件上的例题全部做了，要求是“不能和课件上的过程一模一样”。这份作业也没有在网络学堂公布，还要求来上课的同学“不要告诉没来的人”，下次上课当堂交。实在气不过，正好那天晚上熬夜有事，就没抄这份作业。&lt;/p&gt;

&lt;h3 id=&quot;计算机组成原理&quot;&gt;计算机组成原理&lt;/h3&gt;

&lt;p&gt;四大原理之三。88分。好像还是25%左右。&lt;/p&gt;

&lt;p&gt;就是传说中的“造计算机”。&lt;/p&gt;

&lt;p&gt;因为之前搞了 FPGA 嘛，自认为对硬件还是有一定了解，就和韦师搭上徐子南报了挑战性项目。挑战性项目是做一个 MIPS 架构的32位 CPU，最后需要能运行 uCore 操作系统。但事实上，整个框架都是韦师一个人搭的，代码也基本上是韦师一个人写的，我大概就负责了一些难度很低的部分，还花了很久时间。想想也是，搞 FPGA 的时候我的贡献也就在于一个有一堆时序问题的 SDRAM 控制器，以及最后跑在 CPU 上的代码而已。这里我就真的是猪队友了，没能分担工作还拖慢了进度，挺愧疚的；而且感觉自己也没学到多少东西。&lt;/p&gt;

&lt;p&gt;这课期末考试画风很奇怪，比网原还要文科。比如“通道可以分为（）、（）和（）三种“，中断处理的过程包括（9个空）等步骤”。感觉很蠢。而且考卷上一半是原题。这破考试还占总评的40%。这还造个毛计算机啊。&lt;/p&gt;

&lt;h3 id=&quot;编译原理&quot;&gt;编译原理&lt;/h3&gt;

&lt;p&gt;四大原理之四。96分。20%左右。&lt;/p&gt;

&lt;p&gt;这门课给分奇高，不过也的确水。说实话我对编原还挺有兴趣的，不知道是不是因为对语言感兴趣所以迁移过来对编译也感兴趣。课外我买了好几本有关的书看，刚开学的时候也把虎书的基础部分看完了，跟着练习题把 Tiger 编译器实现到了指令选择的阶段。&lt;/p&gt;

&lt;p&gt;但这门课要求实在太低了。大作业只是往给定的框架里填代码，只需要额外实现几个没卵用的新增语法就行。小作业就是自动机的延伸，毫无意义地把非常偏工程的语义分析等用形式语言描述一遍。考试也就是小作业的画风。&lt;/p&gt;

&lt;p&gt;寒假里其实想再学一学编原的。&lt;/p&gt;

&lt;h3 id=&quot;人工神经网络&quot;&gt;人工神经网络&lt;/h3&gt;

&lt;p&gt;91分。中位数左右。&lt;/p&gt;

&lt;p&gt;顺应炼丹大潮，本想学一点理论，可惜也没去上课。&lt;/p&gt;

&lt;p&gt;这课的小作业我觉得挺好的，让大家用 MATLAB 实现神经网络，可以加深对原理的理解。大作业就很迷了。不知道老师的实际要求是什么，给我的感觉是希望我们能在复现论文的基础上还能做出创新。太不合理了吧，本来机器学习领域就日新月异，还指望我们在课业繁重的大三搞出创新？&lt;/p&gt;

&lt;p&gt;大作业也是组队的，我和黄大大一组做 Image Captioning。这里我又当了一回猪队友。其实所有活都是黄大大干的，我只负责写报告而已。报告也是很迷，必须用 CVPR 的模板写英文的，是我从未装逼过的领域，挑战不小。最后硬凑出了6页 paper，深刻体会到了发 paper 的不容易。&lt;/p&gt;

&lt;p&gt;很奇怪的是，虽然在展示的时候老师对我们大作业评价不高，最后给分还挺好看的。不是很懂。&lt;/p&gt;

&lt;h3 id=&quot;数据库系统概论&quot;&gt;数据库系统概论&lt;/h3&gt;

&lt;p&gt;81分。倒数。&lt;/p&gt;

&lt;p&gt;我不服啊。这是我大作业做的最认真的课之一了。&lt;/p&gt;

&lt;p&gt;没怎么去上过课，不知道课讲的怎么样。有一个很迷的期中考试，感觉是在考 MySQL Server 2008 应用。大作业要求实现一个数据库系统，其实就是斯坦福 CS346 的翻版，只不过提供了一个非常难用的框架，因此我们直接用的 CS346 的框架。&lt;/p&gt;

&lt;p&gt;这个大作业其实很有意思，至少我写的很开心。和韦师一组，这次终于没有当猪队友。也是拖到最后一周才开始写的，最后到验收为止也只实现了所有基础功能。但之后我们接着往下写，加入了索引和查询优化。估计助教根本没看最后提交的代码和报告。&lt;/p&gt;

&lt;p&gt;总之我还是觉得这份大作业做的挺不错的，也是我这学期大作业中唯一放到 GitHub 上的。贴一下链接：&lt;a href=&quot;https://github.com/huzecong/rebaseDB&quot;&gt;https://github.com/huzecong/rebaseDB&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;环境保护与可持续发展&quot;&gt;环境保护与可持续发展&lt;/h3&gt;

&lt;p&gt;记通过的1学分文核。很水。前八周每周二晚上去主楼后厅听讲座，其实一次都没听过他在讲什么。报告基本上是在复述百度百科。&lt;/p&gt;

&lt;h3 id=&quot;公司金融&quot;&gt;公司金融&lt;/h3&gt;

&lt;p&gt;78分。75%左右。&lt;/p&gt;

&lt;p&gt;之前就听说公司金融不简单。的确也是，概念挺复杂的。幸好期中期末都是半开卷，公式和概念其实一个都记不住。&lt;/p&gt;

&lt;p&gt;说到期末的半开卷，非常有意思，因为老师没有限制纸的大小，所以我带了一张 A3，听说有人带 A1 = =服气。&lt;/p&gt;

&lt;h3 id=&quot;商法&quot;&gt;商法&lt;/h3&gt;

&lt;p&gt;82分。中位数左右。&lt;/p&gt;

&lt;p&gt;算是这学期最有意思的一门课吧。老师知识渊博，可以以深搜的方式给出法律概念的定义。听这些案例感觉也挺有意思的。但作业是真的不会做= =根本不会分析，想不到那么深。&lt;/p&gt;

&lt;h2 id=&quot;其他&quot;&gt;其他&lt;/h2&gt;

&lt;h3 id=&quot;学生算法与竞赛协会&quot;&gt;学生算法与竞赛协会&lt;/h3&gt;

&lt;p&gt;说来惭愧，我还在这个名字很长的协会里任副会长，也兼着在科协当分管竞赛的副主席。&lt;/p&gt;

&lt;p&gt;真的很惭愧，因为我基本上什么事没干，甚至只是偶尔去开个会而已。幸亏&lt;del&gt;聪明伶俐又可爱的&lt;/del&gt;会长 zhx，和默默 carry 一切的辅导员小旻都非常靠谱，才没有让不器用的我坏事。&lt;/p&gt;

&lt;p&gt;下学期可没有“文艺部很忙”这个借口了，也该要认真干点事了。&lt;/p&gt;

&lt;h3 id=&quot;实验室&quot;&gt;实验室&lt;/h3&gt;

&lt;p&gt;加入了刘知远老师的实验室。说实话对科研兴趣不是很大，正好听芃哥说他在刘知远老师那边干一些偏工程向的事情，就去投奔他了。现在在做一个从微博中提取信息的项目，还挺对我胃口的，下学期应该会在上面多投入一些精力。&lt;/p&gt;

&lt;h3 id=&quot;体育&quot;&gt;体育&lt;/h3&gt;

&lt;p&gt;体育课选的是健美，每周终于可以稳定去一次健身房了。感觉这么练了一个学期下来力量还是有进步，虽然成绩很一般。但自从跨年以来就再也没练过了，回去可能又废了。&lt;/p&gt;

&lt;p&gt;长跑终于还是退步了，比大一还要慢了一点。&lt;/p&gt;

&lt;h3 id=&quot;讲课&quot;&gt;讲课&lt;/h3&gt;

&lt;p&gt;这学期讲课的次数创了记录。先是国庆去济南讲了两天（可能不能算讲课），11月中旬又去安徽讲了两天，寒假初又在北京讲了一天济南讲了两天半。挣到了不少钱，也花掉了不少。&lt;/p&gt;

&lt;p&gt;其实讲课对我来说就是挣钱而已，并不是想要当老师。当然，挣钱的同时也得对学生负责。以后可能也没什么时间去讲课了吧。&lt;/p&gt;

&lt;h2 id=&quot;关于未来的打算&quot;&gt;关于未来的打算&lt;/h2&gt;

&lt;p&gt;终究还是要讲到这个沉重的话题。&lt;/p&gt;

&lt;p&gt;出路无非三种：工作、出国，或者读研。读研意味着在本校读硕士或者博士，出国意味着在国外读硕士或博士，亦或是在国外工作。&lt;/p&gt;

&lt;p&gt;其实都考虑过。说实话是不太想出国的，怎么说呢，还是在国内习惯了吧，不想离开这个舒适的文化圈。一个人在有文化壁垒的国外，真的怕自己坚持不下去。&lt;/p&gt;

&lt;p&gt;读研的话，博士肯定是不想读的。不想以后从事科研或者教学，读博或许意义不大。如果读硕士的话，对我来说也就是多了三年的缓冲，以及一张文凭而已。况且硕士名额少，自己到底有没有竞争力，其实也没底。而且，我也并不知道在这上面花三年有没有意义，听到过太多完全相反的声音，不知道哪边才对。&lt;/p&gt;

&lt;p&gt;工作其实是我最开始的想法，但也会有所担忧：毕业时才22岁的我真的可以负起对自己的责任吗？不选择深造，以后的上升空间到底有多少？之类的，非常现实的问题。甚至关于应该什么时候结婚生子也思考过，但完全没有答案。&lt;/p&gt;

&lt;p&gt;到最后选择也只有半年时间了。如果要读研，大四一开学就要考试和面试；如果要出国，大四结束就是申请 DDL；如果要工作，也是时候积累实习经验了。&lt;/p&gt;

&lt;p&gt;所以目前我的想法是：大三下好好在实验室干活，争取暑假去实习，然后在大四上给出自己的回答。有点理想化，不知道能不能实现。但或许也只能走一步看一步了。&lt;/p&gt;

&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;又啰嗦了这么多，这个毛病估计是改不掉了。&lt;/p&gt;

&lt;p&gt;本来想年前写的，但又拖到了年后。&lt;/p&gt;

&lt;p&gt;感谢看到这里的各位，谢谢你们愿意阅读我的流水账，希望多少能让你感到开心。&lt;/p&gt;

&lt;p&gt;那么，下学期见。&lt;/p&gt;</content><author><name>Zecong Hu</name></author><summary type="html">转眼间又一个学期过去了。传闻中最可怕的一个学期也就这样平安无事地度过了。大学的生活也已经过半了。 感伤的事越来越多，同时也日渐对未知的未来感到恐慌。从大二思考到现在，仍然不知道该选怎样的出路。 不过，或许开头应该喜庆一点，那这一部分留到最后再说好了。 总之，这是事多的一学期，也是很充实很开心的一学期。这次不想事无巨细地写篇流水账了，只挑重点的讲。另外，这次准备多放点图，希望大家能看得开心。</summary></entry><entry><title type="html">Codeforces Round #391</title><link href="http://zecong.hu/2017/01/14/codeforces-round-391/" rel="alternate" type="text/html" title="Codeforces Round #391" /><published>2017-01-14T05:43:00+00:00</published><updated>2017-01-14T05:43:00+00:00</updated><id>http://zecong.hu/2017/01/14/codeforces-round-391</id><content type="html" xml:base="http://zecong.hu/2017/01/14/codeforces-round-391/">&lt;p&gt;转眼之间已经到了大三，距退役已经三年了。考完期末考试，正好有一场 CF，抱着做康复训练的心态参加了比赛。&lt;/p&gt;

&lt;p&gt;结果自然是惨不忍睹……虽然是和同学开黑，却也无济于事。写了5道题，最后只过了两道。大概已经不适合快节奏地写代码了吧。&lt;/p&gt;

&lt;p&gt;但不管怎么说，这次的题目还是挺有意思的。而且我们的做法和官方做法有些差别，自认为也是很有意思的思路。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;a&quot;&gt;A&lt;/h2&gt;

&lt;p&gt;没啥好说的。把计数的数组开成了 &lt;code class=&quot;highlighter-rouge&quot;&gt;char&lt;/code&gt;，贡献了一次 WA。&lt;/p&gt;

&lt;h2 id=&quot;b&quot;&gt;B&lt;/h2&gt;

&lt;p&gt;经典题。以各种不同的方式犯傻，一共错了3次。&lt;/p&gt;

&lt;h2 id=&quot;c&quot;&gt;C&lt;/h2&gt;

&lt;p&gt;大意是，问有多少个双射 $f$ ，满足对于每个多重集 $S_i$ ， $S_i=f(S_i)$ 。&lt;/p&gt;

&lt;p&gt;其实就是对于一种元素 $x$ ，在每个多重集中，其出现次数应当等于 $f(x)$ 的出现次数。可以依次把元素划分成若干等价类，答案即等价类大小的阶乘的乘积。&lt;/p&gt;

&lt;p&gt;问题在于如何求出等价类。我们思考了各种方法，最后猜测，说不定是一个看上去很暴力，但其实复杂度可以接受的方法。于是就有了下面这个方法：&lt;/p&gt;

&lt;p&gt;用一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;vector&amp;lt;pair&amp;lt;int, int&amp;gt;&amp;gt;&lt;/code&gt; 描述元素 $x$ ：每个二元组 $(i,k)$ 代表 $S_i$ 中 $x$ 出现了 $k$ 次，如果 $k=0$ 那么不把这个二元组加入 vector。这样一来所有元素的 vector 长度之和是 $O(\sum{g_i})$ 的。之后要做的就是统计有多少不同的 vector 了。最直观的方法是排序之后扫描，实际上直接对这些 vector 进行排序复杂度也是可以接受的，但考场上没有想明白，就用了哈希的方法。有意思的是，第一次提交只使用了单关键字，之后惨遭 Hack……被迫改成了双关键字。&lt;/p&gt;

&lt;p&gt;然而最后数组开小了 RE 了……&lt;/p&gt;

&lt;p&gt;最后证明一下排序的复杂度，其实是 $O(n\log n\cdot d)$ ，其中 $d$ 为 vector 的期望长度。这个长度其实是 $O(\sum g_i/n)$ ，所以复杂度就是 $O\left((\sum g_i)\log n\right)$ 。&lt;/p&gt;

&lt;h2 id=&quot;d&quot;&gt;D&lt;/h2&gt;

&lt;p&gt;最后只剩15分钟的时候才开始想这题，还是没能在比赛结束前通过。&lt;/p&gt;

&lt;p&gt;其实很简单，因为 $n\leq 75$ ，算一算就知道合法分割里最大的数不超过20。因此可以直接状压 DP，状态 $f[i][S]$ 表示前 $i$ 个01，出现数字集合为 $S$ 时的方案数，状态空间 $O(n\cdot2^{20})$ 。而至于转移，两个切割点之间的部分，除去前导零之后长度必然不超过6，而全部为0时不转移；故转移是 $O(1)$ 的。&lt;/p&gt;

&lt;h2 id=&quot;e&quot;&gt;E&lt;/h2&gt;

&lt;p&gt;这题非常有意思。&lt;/p&gt;

&lt;p&gt;定义 $f_r(n)$ 如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
f_0(n) &amp; = \sum_{u\cdot v=n}\left[\gcd(u,v)=1\right] \\
f_{r+1}(n) &amp; = \sum_{u\cdot v=n}\frac{f_r(u)+f_r(v)}{2}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;有 $q$ 个询问，每次给定 $r$ 和 $n$ ，求 $f_r(n)$ 。所有范围均为 $10^6$ 。&lt;/p&gt;

&lt;p&gt;可以发现，记 $k$ 为 $n$ 的质因子个数，那么 $f_0(n)=2^k$ 。这是因为每个质因子要么全部属于 $u$ ，要么全部属于 $v$ 。&lt;/p&gt;

&lt;p&gt;而 $f_{r+1}$ 的式子可以改写如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{r+1}(n) = \sum_{d\mid n}f_r(d) = \sum_{d\mid n}f_r(d)\cdot 1&lt;/script&gt;

&lt;p&gt;记 $1(n)$ 为常数函数 $1(n)=1$ ，那么可以将上式表示为 Dirichlet 卷积的形式：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{r+1}=f_r\ast 1=f_0*1^r&lt;/script&gt;

&lt;p&gt;和一般卷积一样，Dirichlet 卷积也满足结合律。因此我们研究 $1^r$ 的表达式。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
1^2(n) &amp; = (1 \ast 1)(n) \\
 &amp; = \sum_{d\mid n}1\cdot 1 \\
1^3(n) &amp; = (1^2 \ast 1)(n) \\
 &amp; = \sum_{d_2\mid n}\left(\sum_{d_1\mid d_2}1\cdot 1\right)\cdot 1 \\
 &amp; \cdots \\
1^r(n) &amp; = \sum_{d_1\mid d_2\mid \cdots\mid d_{r-1}\mid n}1
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;换句话说，即求长度为 $r-1$ 的序列 $d_1,\ldots,d_{r-1}$ 的方案数，其中序列满足 $d_i\mid d_{i+1}$ ， $d_{r-1}\mid n$ 。&lt;/p&gt;

&lt;p&gt;记 $n$ 的质因数分解为 $n=\prod p_i^{k_i}$ ，仅考虑一个质因子 $p_i$ ，那么 $d_1,\ldots,d_{r-1}$ 的每个数所包含的 $p_i$ 的次数都不应大于 $k_i$ ，且前一个数的次数不应大于后一个数的次数。问题就变成了：求长度为 $r-1$ 且最大数不超过 $k_i$ 的非负非降序列的方案数。用隔板法可以知道方案数为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\binom{k_i+r-1}{r-1}&lt;/script&gt;

&lt;p&gt;那么&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;1^r(n)=\prod_i \binom{k_i+r-1}{r-1}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{r}(n) = (f_0 \ast 1^{r-1})(n) = \sum_{d\mid n}f_0(d)\cdot 1^{r-1}\left(\frac{n}{d}\right)&lt;/script&gt;

&lt;p&gt;至此，只要用筛法预处理出最小质因子，即可在 $O(\tau(n))$ （因子数）的时间内回答一个询问。但这还不够快（比赛时交的这个做法，TLE 在了 Final Test 的第52个点……）。&lt;/p&gt;

&lt;p&gt;由于 $d$ 和 $\frac{n}{d}$ 都是 $n$ 的因子，记 $d$ 的质因数分解为 $d=\prod{p_i^{q_i}}$ ，那么 $q_i\leq k_i$ ，而且 $\frac{n}{d}=\prod{p_i^{k_i-q_i}}$ 。进而我们可以将 $f_0(d)$ 表示如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_0(d) = \prod_i (1+[q_i&gt;0])&lt;/script&gt;

&lt;p&gt;带入 $f_r$ 的式子得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
f_r(n) &amp; = \sum_{d\mid n}\left(\prod_i (1+[q_i&gt;0])\right)\left(\prod_i \binom{k_i-q_i+r-1}{r-1}\right) \\
 &amp; = \sum_{d\mid n}\prod_i (1+[q_i&gt;0])\binom{k_i-q_i+r-1}{r-1} \\
 &amp; = \prod_i\sum_{q_i=0}^{k_i} (1+[q_i&gt;0])\binom{k_i-q_i+r-1}{r-1}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;因此只要对每个质因子单独计算就可以了。复杂度骤降为 $O(\log n)$ 。&lt;/p&gt;

&lt;p&gt;发现了什么吗=·=这个函数是一个积性函数……如果一开始就意识到这一点的话，整个推导其实非常简单，根本不需要考虑什么 Dirichlet 卷积的结合性……&lt;/p&gt;

&lt;p&gt;虽然绕了很大的弯路，但这个思路还是挺有趣的😂&lt;/p&gt;</content><author><name>Zecong Hu</name></author><summary type="html">转眼之间已经到了大三，距退役已经三年了。考完期末考试，正好有一场 CF，抱着做康复训练的心态参加了比赛。 结果自然是惨不忍睹……虽然是和同学开黑，却也无济于事。写了5道题，最后只过了两道。大概已经不适合快节奏地写代码了吧。 但不管怎么说，这次的题目还是挺有意思的。而且我们的做法和官方做法有些差别，自认为也是很有意思的思路。</summary></entry><entry><title type="html">大二下总结</title><link href="http://zecong.hu/2016/07/12/my-4th-semester-in-college/" rel="alternate" type="text/html" title="大二下总结" /><published>2016-07-12T16:11:00+00:00</published><updated>2016-07-12T16:11:00+00:00</updated><id>http://zecong.hu/2016/07/12/my-4th-semester-in-college</id><content type="html" xml:base="http://zecong.hu/2016/07/12/my-4th-semester-in-college/">&lt;p&gt;一个学期又过去了。大二下一结束，大学生活就过了一半了。每过一个学期，上一学期的记忆就变得模糊，也越来越难以正确地感知时间的长短。这个学期过得似乎比之前都要快，或许也是因为太闲吧？&lt;/p&gt;

&lt;p&gt;感觉上这个学期可以分成两部分，上半学期的画风和下半学期截然不同，中间正好以去日本旅行作为分隔。上半学期感觉更像是个非工科院系的学生：专业课还只是小作业的阶段，与此同时在上几门需要小组合作的管双课；下半学期开始前8周的管双课程结课，而且有数设大作业了，就变成了正常的贵系宅男。这两种画风其实我都挺喜欢的。&lt;/p&gt;

&lt;p&gt;这次的总结，我想尽量写得简洁一点，不像前几个学期那样写出一篇长篇大论来，写得累，看着也累。（事后看来，还是没能做到。辛苦大家了。）&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;学习&quot;&gt;学习&lt;/h2&gt;

&lt;p&gt;学习毕竟还是最重要的部分，就先放在这讲了。由于提前修了人智和自动机，这学期的专业课程很少，相比起大二上也更加具有专业特色。除了概率论和物理实验之外，必修课似乎只有数字逻辑的两门课。&lt;/p&gt;

&lt;p&gt;下面是惯例的晒成绩和吐槽。&lt;/p&gt;

&lt;h3 id=&quot;专业课&quot;&gt;专业课&lt;/h3&gt;

&lt;h4 id=&quot;概率论与数理统计&quot;&gt;概率论与数理统计&lt;/h4&gt;

&lt;p&gt;倒数第二门数学课。之后基本上没有需要在考试周早起跑图书馆复习的课了。&lt;/p&gt;

&lt;p&gt;概率论一直觉得是非常有用的，虽然平时学得也不是很认真。我选的是史灵生老师的课，不得不说史灵生讲课还是讲得挺好的，课件也是精心制作的 LaTeX 幻灯片，非常对我胃口。然而还是没去过几次课，有点惭愧和后悔。&lt;/p&gt;

&lt;p&gt;考试周的时候只有这一门考试，因此花了整整4天的时间复习。最后的期末考试谜之水，考到一半我都有点怀疑这门课算不算在我们培养方案里面。似乎是因为选这课的社科同学比较多，就故意放水了。虽然对我来说是再好不过的，但总感觉有点白费了复习。&lt;/p&gt;

&lt;p&gt;总评96。讲课好还给分高，这课稳赚不赔。&lt;/p&gt;

&lt;h4 id=&quot;物理实验b2&quot;&gt;物理实验B(2)&lt;/h4&gt;

&lt;p&gt;史上最没卵用的课·第二季。&lt;/p&gt;

&lt;p&gt;延续上一学期的作风，这次所有报告都是用 LaTeX 写的，坚决不写一个字。到头来的结果就是似乎花在与 LaTeX 斗争上的时间比用手抄一遍可能需要的时间还要多，但拜其所赐熟练掌握了 LaTeX 的各种表格排版技巧。&lt;/p&gt;

&lt;p&gt;至于实验，基本上不需要预习。现场听老师讲一讲，不会的时候抱老师大腿就好。做完实验之后还是不知道怎么回事，和做之前没什么差别。&lt;/p&gt;

&lt;p&gt;总评88。果然没有期末考分数就上去了。之后再也没有物理课了，完结撒花。&lt;/p&gt;

&lt;h4 id=&quot;数字逻辑设计&quot;&gt;数字逻辑设计&lt;/h4&gt;

&lt;p&gt;本学期花时间最多的一门课。数设和数字逻辑电路是二选一的课，区别在于数电是纯理论，而数设则是数电+大作业。前八周教完数电的基础理论之后，后八周用开发板完成一个项目。&lt;/p&gt;

&lt;p&gt;数电这套理论其实我挺喜欢的，虽然听到身边不少人都表示反感。硬件开发门槛的确比软件高，而且出错也不好调试，在做项目的时候深有体会。不过即便如此，我还是觉得数电有其独特的魅力与挑战，或许也是因为我在学理论的时候感觉顺风顺水。&lt;/p&gt;

&lt;p&gt;前八周的学习非常顺利，没遇到什么问题，期中考（相当于数电期末）也感觉差不多是满分水平（这也说明数电完全没必要16周来学，建议大家选数设以度过一个充实的大二下）。&lt;/p&gt;

&lt;p&gt;至于后八周的项目，我和韦师和天龙组了一对。我们同时报名参加了老师安利的一个 FPGA 设计大赛，准备拿我们的项目同时作为参赛作品。因此我们没有局限于大作业给的平台，设计了一个宏伟的项目。从老师那里拿到开发板已经是五一结束后了，之后我们遵循软工开发的经验，按照每周一次通宵的进度进行开发。但事实证明我们大大低估了硬件开发的难度，开发过程中遇到了各种令人摸不着头脑的玄学问题，结果变成了天龙沉溺在超难用的 Nios 开发工具中无法自拔，我和韦师对着各种时序图微调延时。最后在 DDL 前，我们连续肝了三天，通过无数次瞎调参数然后等六分钟编译测试，终于在结课展示前1个小时得到了一个若干错误叠加导致负负得正的能 work 的 demo。可以算是最有惊无险的一次赶 DDL 了。&lt;/p&gt;

&lt;p&gt;然而这门课还没有结束！我们还有比赛的大坑等着填。自己挖的坑，哭着也要填上。&lt;/p&gt;

&lt;p&gt;总评96。有点坑爹，因为96是最高分，而数电不低于96分的足足有30人。之前老师还跟我们说数设虽然工作量大，但给分高。感觉被骗。&lt;/p&gt;

&lt;h4 id=&quot;数字逻辑实验&quot;&gt;数字逻辑实验&lt;/h4&gt;

&lt;p&gt;数电的配套课程，差不多是超级弱化入门版的数设实验。&lt;/p&gt;

&lt;p&gt;对我来说，这课有两个好处。第一个自然是为数设实验打下了基础，没有数电实验的话一开始想必会走更多弯路。第二个则是数电实验发了一个非常炫酷的实验箱，看上去非常像影视作品中黑帮交易里装钱的箱子。每次领着箱子在主干道上飙车的时候，都感觉自己是在出发去拯救世界。&lt;/p&gt;

&lt;p&gt;这课也非常水，基本上是把前八周的课程强行拉伸到了全周，和数电一个尿性。平时实验我做的非常认真，也写了非常装逼的报告。但这课的期末考试非常逗，基本上是考察插线手速，插出来的东西如下图所示。而实际插线的时候还因为设错了示波器导致查了好久插线的错误，浪费了很多时间。因此最后总评只有93。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2016/07/12/my-4th-semester-in-college/1-digital-circuit-exp-set.jpg&quot; alt=&quot;数电实验的实验箱&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;计算机图形学基础&quot;&gt;计算机图形学基础&lt;/h4&gt;

&lt;p&gt;唯一一门非必修专业课。其实是非常好玩的一门课，但因为学期中太浪，加养成了赶 DDL 的陋习，导致考试周才开始做大作业，也就没法做出一个令自己满意的东西。&lt;/p&gt;

&lt;p&gt;大作业要求实现网格简化算法和一个简单的真实感渲染器。网格简化的算法论文前半学期就看完了，但因为觉得简单一直拖着没有写。而渲染器则是在 DDL 之前写了4天写出来的，最后只有一个朴素的路径追踪，外加一些看起来炫酷但其实非常好写的贴图效果，都不支持复杂物体。整个框架基本上是参考了各种代码，东拼西凑出来的。&lt;/p&gt;

&lt;p&gt;其实我觉得图形学是非常有意思的，至少做出来的东西看得见摸得着，能让人有很强的成就感。而图形学背后有一整套的数学理论，在我写代码的时候根本没有理解，只是依葫芦画瓢地模仿而已。如果以后有时间了，还是想好好学一学的。&lt;/p&gt;

&lt;p&gt;总评88，所幸上了平均分。&lt;/p&gt;

&lt;h3 id=&quot;第二学位课程&quot;&gt;第二学位课程&lt;/h3&gt;

&lt;p&gt;其实现在自己对于双学位的看法很奇怪。自己报双学位的初衷其实是真的想学一点什么，而不是混一个文凭，因为自己觉得这种文凭根本没有什么含金量。但实际上自己又没怎么听课，而这种课和理工科课程不一样，属于不听就很难学到东西的。另一方面，这些学科大多是经验学科，不怎么严谨，让我也有点难以接受。有时候还会纠结学这个双学位到底有没有意义，但因为双学位的课分数实在是低，要是退了的话这些课都会算进一学位任选里，迅速拉低 GPA，所以想了想还是只能坚持。&lt;/p&gt;

&lt;p&gt;抱怨了这么多，双学位还是有一些好处的。至少可以让我认识一些本来基本上没机会认识的其他院系的同学。&lt;/p&gt;

&lt;h4 id=&quot;组织行为学&quot;&gt;组织行为学&lt;/h4&gt;

&lt;p&gt;后八周周六下午的课程。从这个时间安排上就能看出不会去上几次课。实际上也是，不仅和一些 DDL 重合，也和一些其他活动完美冲突，导致八节课中我一共去了大概四节。事实上，每次上课的人也非常少，硕大一个6A017的教室只能坐上不到一半。这门课给分也非常奇葩，有25分是上课发言获得的，而且是按照发言次数经过某种函数计算给分，但无论如何，一次都不发言就一定是0分。&lt;/p&gt;

&lt;p&gt;这门课本身是比较好玩的，通过设计一系列那种看上去不知所云的实验来分析人们的行为模式，老师讲的也还可以。但实际上由于基本上没听课，导致我什么都没学到。唯一的收获大概是写团队报告的时候看了一篇论文而已。&lt;/p&gt;

&lt;p&gt;非常奇怪的是，最后总评拿到了84，高于平均分。或许是同组的同学帮我签了到吧，感人肺腑。&lt;/p&gt;

&lt;h4 id=&quot;营销管理&quot;&gt;营销管理&lt;/h4&gt;

&lt;p&gt;同样是没怎么听课。胡左浩老师讲课非常有激情，但就是没怎么听。因为复习数设期中考不慎翘掉一次小测，成绩也就没法高了。期末考也很迷，基本上是选择题，而且允许开卷，还允许上网，感觉考察的是信息检索能力。因此我非常炫酷地提前交了卷。但实际上还是什么都不会。&lt;/p&gt;

&lt;p&gt;总评给了82，虽然已经是倒数了。&lt;/p&gt;

&lt;h4 id=&quot;创业领导力&quot;&gt;创业领导力&lt;/h4&gt;

&lt;p&gt;前八周的课程。可以算是这学期最好玩的一门课了。这门课全程是组队干活，上课内容千奇百怪，好几次需要我们在一张巨大白纸上画图。虽然感觉对实际创业和领导力开发没太大帮助（也没太听课），但认识了一些非常有趣的其他院系的同学，也见识到了很多同龄人的口才和表达能力。&lt;/p&gt;

&lt;h4 id=&quot;互联网商业模式创新&quot;&gt;互联网商业模式创新&lt;/h4&gt;

&lt;p&gt;好像是学校外的某个投资基金的主管来学校开的课。身边很多人都评价他讲的好，有人格魅力，但这课开在周六早上第一节= =所以还是没怎么听。看了一小部分 MOOC，感觉讲的还是很有道理的。&lt;/p&gt;

&lt;p&gt;这课需要小组合作完成一份商业计划书。其实我对于这种创业类的作业和比赛一向是比较反感的，可能也是我个人的偏见，但我觉得这种很多都是纸上谈兵，又没有技术又没有真正可行的盈利模式，谈什么创业。所以这个大作业我是准备随便糊弄掉的。但因为一些机缘巧合我成了组长，而组里招的两个美院同学比我还咸鱼，所以最后还是我挑起了大梁，强行瞎逼逼凑出了一篇计划书。最后老师给的评价挺低的，说是没有深入思考，的确也是。可能因为组长有加成，最后给分还可以。不过最后没有挂掉任何一个人，祝那位美院大四的同学顺利毕业吧。&lt;/p&gt;

&lt;h3 id=&quot;其他课程&quot;&gt;其他课程&lt;/h3&gt;

&lt;h4 id=&quot;毛泽东思想和中国特色社会主义理论体系概论&quot;&gt;毛泽东思想和中国特色社会主义理论体系概论&lt;/h4&gt;

&lt;p&gt;毛概。本来是大三下的课程，提到这个学期先修掉了。结果只有82分，拿到了四门政治课中最低的分数。不过也没什么可抱怨的，毕竟完美避开了签到，期中期末论文写得也一般。&lt;/p&gt;

&lt;p&gt;不过此后再也没有智障政治课了。完结撒花。&lt;/p&gt;

&lt;h4 id=&quot;数学模型&quot;&gt;数学模型&lt;/h4&gt;

&lt;p&gt;文核补完计划其一。听说给分高，但其实并不是很高。和大一那门“数学建模导论”不太一样，似乎是面向非新生的，课程任务量也更大。一共要做三次建模，前两次都是谜之比赛题，最后一个是自选。&lt;/p&gt;

&lt;p&gt;我和黄大大和他的一个大腿同学一队。前两次作业都是黄大大和同学完成高逼格建模之后，由我进行高逼格排版，换句话说就是我完全不会建模。第三次由于是自选，就把之前做的离散大作业包装了一下直接丢了上去，进行了合理的代码复用。&lt;/p&gt;

&lt;p&gt;总评90。感觉并不是很高，毕竟第二次作业用黄大大同学给的巨牛逼模型还拿到了学校建模比赛的奖。虽然我毛都没看懂，但公式都是我排版的呀。&lt;/p&gt;

&lt;h4 id=&quot;工业生产概论1&quot;&gt;工业生产概论(1)&lt;/h4&gt;

&lt;p&gt;文核补完计划其二。其实选课的时候完全不知道这课是干什么的，只是因为是文核而且俩室友也选了才选的。事实上，现在我还是不知道这课是干什么的。&lt;/p&gt;

&lt;p&gt;我对于这课全程都抱着水水过的想法，最后也得到了一个水水的分，似乎是非五字班的倒数第一。感觉我们小组里的人也都是类似的想法，而且都把组内其他人当 sb，这样合作起来就非常愉快，因为完全不用考虑把事情做好，只要把自己该干的干了就行。&lt;/p&gt;

&lt;h4 id=&quot;学术英语听说2综述&quot;&gt;学术英语听说（2）—综述&lt;/h4&gt;

&lt;p&gt;最后一门英语课，随便选了个稳上的听说水课。Olbrich 老爷爷也的确是个比较慈祥的人，课也很水，基本上没有作业。做 presentation 的时候上台装了一回逼，似乎留下了还不错的印象。&lt;/p&gt;

&lt;p&gt;最后拿了91分，还是非五字班第二。不知道是不是现在英语课给分都这么低了。&lt;/p&gt;

&lt;h4 id=&quot;射击&quot;&gt;射击&lt;/h4&gt;

&lt;p&gt;拿一志愿拼上的课，属于培养方案外。一直都想上的课。&lt;/p&gt;

&lt;p&gt;通过这门课，我意识到了，手抖还是不要妄想可以玩枪耍帅了。真的，手太抖了，完全瞄不准。最后也拿了非五字班最低分。&lt;/p&gt;

&lt;h3 id=&quot;课业之外的事情&quot;&gt;课业之外的事情&lt;/h3&gt;

&lt;p&gt;课业之外与学习相关的事情，大概就是比赛和考试了。&lt;/p&gt;

&lt;p&gt;网上的编程比赛基本上都参加了，但都没去年走得远。GCJ 还是止步于 R3，这次试着打了一下 Distributed GCJ，感觉还挺有意思，但肯定是止步于 R2 了。TCO 打了两盘 R2，都只靠 cha 人拿了分。感觉是这辈子都拿不到 TCO 的T恤了。别的比赛都中道崩殂或半路弃疗。&lt;/p&gt;

&lt;p&gt;此外还参加了一个名为蓝桥杯的 sb 比赛。题目又 sb，参赛费还贵，幸好是院里面报销的。最后水了个一等奖，听说有奖品（还是奖金？），但现在连影子都没见到。&lt;/p&gt;

&lt;p&gt;考试的话，考了5月22日的托福。本来想着从日本回来就开始复习，结果一拖再拖，最后只做了两套 TPO。幸好考了个不用再考的分数。&lt;/p&gt;

&lt;h2 id=&quot;社工&quot;&gt;社工&lt;/h2&gt;

&lt;p&gt;这学期的社工就相对咸鱼了，没做什么事情。也差不多处于一个怠倦期了。&lt;/p&gt;

&lt;h3 id=&quot;班级工作&quot;&gt;班级工作&lt;/h3&gt;

&lt;p&gt;班级工作还是一些例行公事，素拓团日之类的，还有每周开会。其实这些事情我都没怎么管了，都是王晨阳在实力 carry，我只是在需要我的时候做一些微小的贡献而已，很惭愧。在实力 carry 之下我们拿到了甲团，还是非常可喜可贺的。&lt;/p&gt;

&lt;h3 id=&quot;文艺部&quot;&gt;文艺部&lt;/h3&gt;

&lt;p&gt;这学期的工作就主要是系歌赛了。由于开学的时候和枫哥说对文艺工作还有兴趣，就和玉涵王老板徐玥一起被拉着参与策划，然而我只在其中划了下水，基本上没干事。最后做歌赛视频的时候组织了一下前期拍摄，有幸得到大家的大力相助才得以完成。这也让我觉得和人打交道特别麻烦和心累。说来，一开始加入社工组织就是想要锻炼人际交往能力，到现在还是没太大长进，或许我还是适合搬砖吧。&lt;/p&gt;

&lt;p&gt;最后因为种种原因还是留在了部里，大三上本来由于先修软工而空出来的时间又要被填满了。不过想想，可以再参与一次学生节的举办，还是挺令人激动的。&lt;/p&gt;

&lt;h3 id=&quot;竞赛部&quot;&gt;竞赛部&lt;/h3&gt;

&lt;p&gt;竞赛部这个学期干的最主要的事情就是办 ACM 校赛了。由于校赛当天我就去日本旅游了，所以主要是负责物资采购和印刷品设计。设计印刷品虽然费时，但也挺好玩的，而且看到自己设计的东西被印出来也挺有成就感的。物资采购和预算则出了不少 bug，这里就不说了= =&lt;/p&gt;

&lt;p&gt;下学期竞赛部从科协独立了出来，成为了学生算法与竞赛协会，我也成了副会长。其实对于这份工作还挺没底的，不知道该怎么带一个新的组织。只能一步一步来吧。&lt;/p&gt;

&lt;h3 id=&quot;团委实践口&quot;&gt;团委实践口&lt;/h3&gt;

&lt;p&gt;团委实践口那边这个学期基本上没事了。学期中有一次实践风采展示，代表我们支队去讲了一些人生经验，但其实和实践口的工作没啥关系。&lt;/p&gt;

&lt;h2 id=&quot;科研&quot;&gt;科研&lt;/h2&gt;

&lt;p&gt;这里的科研特指 SRT。学术新星完全没有进展，因此星火计划也退了=。=只剩 SRT 苟延残喘了。&lt;/p&gt;

&lt;p&gt;这学期最认真搞 SRT 的只有开学第一周。当时刚开学，还有学习热情，第一次炼丹，训出了一个比已有成果更差劲的网络。在开了第一次组会之后，就没怎么干活了，只是看了若干篇论文而已。但纸上谈兵是没有效果的，到现在自己的炼丹水平还是非常拙计，几乎和没有一样。之后开组会前都只是临时赶工，装作自己做了事情一样。&lt;/p&gt;

&lt;p&gt;SRT 快要结题了，有点慌了。暑假除了数设比赛，还是得认真弄一弄这个的。&lt;/p&gt;

&lt;h2 id=&quot;体育&quot;&gt;体育&lt;/h2&gt;

&lt;p&gt;这学期去健身房也没有上学期勤了，基本上是想起来才去，每次去都能体验到肌肉酸痛。力气是不如以前了，跑步也有点上气不接下气，跑完 3km 都比较困难。&lt;/p&gt;

&lt;p&gt;但非常神奇的是，这丝毫没有影响我的引体向上成绩。这说明学校的引体向上考核方式和臂力基本无关，更多的是考察体重和姿势。由于专项选了巨水无比的游泳初级班，体育分数非常漂亮，达到了史无前例的94分。不过由于之前的体育成绩太差，四学期平均分还是没有上80。&lt;/p&gt;

&lt;p&gt;现在健身房的年卡也过期了，自考试周开始也再没锻炼过了。回学校后准备办一张两年的年卡，在暑假期间抓紧锻炼锻炼。&lt;/p&gt;

&lt;h2 id=&quot;娱乐&quot;&gt;娱乐&lt;/h2&gt;

&lt;p&gt;这学期在娱乐方式和水平上达到了登峰造极的水平。Steam 上的游戏数突破了50，五一的时候一行人去日本自助游了5天，暑假也在台湾进行为期19天的养老生活。&lt;/p&gt;

&lt;p&gt;去日本旅行大概是这学期最开心的事情了。游记不准备写了，放一张拼贴画吧。 不得不说日本人民的总体素质还是很高的，整趟旅游下来体验非常好。不过出发前自以为自己可以听懂日语口语，到了才发现自己还是幼稚。因此下学期想好好学一下日语，反正英语也考完了，不用担心会把两门语言混起来了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2016/07/12/my-4th-semester-in-college/2-japan-trip-collage.jpg&quot; alt=&quot;日本旅行&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而台湾的养老小学期是暑期 Java 小学期的替代课。其实来之前有点纠结的，因为不知道能收获什么，但不管怎么样还是报名了。来之后发现：的确毛都学不到，但台湾也难得来一次，体验一下旅个游也好啊。之所以今天写这个总结，也是因为实在是闲的没事干，而又早早开始犯困，因此没法干正事，但这个点睡觉也睡不着，所以就来写总结了。台湾从事服务业的人们素质也非常高，体验很好。如果不是这边经常下雨，过于潮湿，虫子比较多之外，生活其实挺不错的。也懒得写什么别的了，接着放图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2016/07/12/my-4th-semester-in-college/3-taiwan-trip-collage.jpg&quot; alt=&quot;台湾旅行&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中左上角那张图是 Google Photos 从所有照片中推荐的自动加了滤镜的图。感觉谷歌的黑科技还是厉害啊。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;一不小心还是写了这么多，啰嗦的毛病改不掉啊。&lt;/p&gt;

&lt;p&gt;本来给这个学期定的大方向是搞学术，认真做 SRT。然而实际上的大方向是浪，外加折腾硬件。或许也是我的修为不够，总感觉机器学习这个领域现在的成果都不怎么讲道理，过于玄学，而顶尖的成果都需要海量数据和企业级计算能力。这也让我有点犹豫。但不管怎么说，这也不是这个学期颓废的借口。总之，SRT 还是得好好收个尾的。&lt;/p&gt;

&lt;p&gt;这里就不做更多展望了，之前三个学期的展望没有一次是实现了的。只讲一下大致的方向吧。&lt;/p&gt;

&lt;p&gt;大三上多半是没有时间干别的了。纵使没了软工，也还有别的硬课等着我，而且还有学生节要办，还有算协的锅。寒假和大三下或许可以尝试去实习，如果可以的话，想做一些设计算法、搭架构的事情，虽然也不是很懂。总之不是很想炼丹或者写前端。&lt;/p&gt;

&lt;p&gt;就到这吧。下学期见。&lt;/p&gt;</content><author><name>Zecong Hu</name></author><summary type="html">一个学期又过去了。大二下一结束，大学生活就过了一半了。每过一个学期，上一学期的记忆就变得模糊，也越来越难以正确地感知时间的长短。这个学期过得似乎比之前都要快，或许也是因为太闲吧？ 感觉上这个学期可以分成两部分，上半学期的画风和下半学期截然不同，中间正好以去日本旅行作为分隔。上半学期感觉更像是个非工科院系的学生：专业课还只是小作业的阶段，与此同时在上几门需要小组合作的管双课；下半学期开始前8周的管双课程结课，而且有数设大作业了，就变成了正常的贵系宅男。这两种画风其实我都挺喜欢的。 这次的总结，我想尽量写得简洁一点，不像前几个学期那样写出一篇长篇大论来，写得累，看着也累。（事后看来，还是没能做到。辛苦大家了。）</summary></entry><entry><title type="html">大二上总结</title><link href="http://zecong.hu/2016/02/11/my-3rd-semester-in-college/" rel="alternate" type="text/html" title="大二上总结" /><published>2016-02-11T04:01:00+00:00</published><updated>2016-02-11T04:01:00+00:00</updated><id>http://zecong.hu/2016/02/11/my-3rd-semester-in-college</id><content type="html" xml:base="http://zecong.hu/2016/02/11/my-3rd-semester-in-college/">&lt;p&gt;如果要用一个词来形容这个学期的话，大概就是忙碌吧。&lt;/p&gt;

&lt;p&gt;虽然还是感觉时间过得很快——仿佛小学期就在昨天——但这个学期发生的事情比大一加起来还要多。&lt;/p&gt;

&lt;p&gt;之所以发生了这么多事，主要还是因为社工的原因。为了体验各种各样的大学生活，我在本学期加入了许多社工组织，参加了许多活动，接了许多锅。同时，因为在学习上画的时间少了，因此成绩大跳水。&lt;/p&gt;

&lt;p&gt;简而言之就是这样了，详情的话，还请往下读。一如既往的流水账风格，这次瞎逼逼了差不多一万字。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;事件&quot;&gt;事件&lt;/h2&gt;

&lt;h3 id=&quot;暑期程序设计小学期&quot;&gt;暑期程序设计小学期&lt;/h3&gt;

&lt;p&gt;2学分。100分。&lt;/p&gt;

&lt;p&gt;开学前时长三周的小学期。每周几次小作业，一个大作业，一次考试。据说直接把一名转系生吓回去了……&lt;/p&gt;

&lt;p&gt;这三周是过得比较辛苦的，主要是因为我喜欢赶 DDL，所以通宵了好几天。&lt;/p&gt;

&lt;p&gt;第一周学的是 Qt，写 FlowFree 的大作业通宵了一天。第二周学的是基于 Qt 的网络编程，写五子棋的大作业通宵了两天。第三周学的是基于 Python 和 Django 的网页开发，其实是不用熬夜写的，但暑假里完全没有剪实践的纪录片，这周就遭报应了……于是又熬了一天。这天其实是最惨的，因为我头天晚上把片子剪完了，然后开始写大作业写到早上7点，睡了一个小时，然后起床来打 ACM 网络赛……&lt;/p&gt;

&lt;p&gt;虽然是辛苦，但非常好玩，学的都是感兴趣而且有意思的东西。而且我个人还比较喜欢这种一周学一个东西的学习模式。&lt;/p&gt;

&lt;p&gt;顺便贴一下代码求关注：&lt;/p&gt;

&lt;p&gt;第一周：&lt;a href=&quot;https://github.com/huzecong/FlowFree&quot;&gt;huzecong/FlowFree&lt;/a&gt;；&lt;/p&gt;

&lt;p&gt;第二周：&lt;a href=&quot;https://github.com/huzecong/GomokuDuel&quot;&gt;huzecong/GomokuDuel&lt;/a&gt;；&lt;/p&gt;

&lt;p&gt;第三周做的太丑就没放了。&lt;/p&gt;

&lt;p&gt;&lt;del&gt;（这么说来，暑期实践的文章好像真的坑掉了。）&lt;/del&gt;&lt;/p&gt;

&lt;h3 id=&quot;学生节&quot;&gt;学生节&lt;/h3&gt;

&lt;p&gt;学生节是两方面的忙碌：作为文艺部干事帮忙做准备，作为班上节目的导演拍片。前者会在后面社工的部分里讲，这里就讲讲班上节目的事情。&lt;/p&gt;

&lt;p&gt;大一的时候就忙过班上学生节，现在关系要好的朋友也大多是那个时候熟的。搞完那届学生节之后就说，来年一定不参和学生节的事情了，因为要花太多时间，太费精力了。结果呢=_=&lt;/p&gt;

&lt;p&gt;本来只是作为班长要带一带节奏，呼吁大家来一起出主意，同时希望感兴趣的同学都来参与一下节目制作。第一次讨论的时候的确也来了不少人，大家一起开了不少不错的脑洞，也差不多奠定了节目的基础。但后来来的人就越来越少了，基本上每次都能来的就只有我、韦师、文委潘立航，以及被钦定为女主的童皓玥。&lt;/p&gt;

&lt;p&gt;我们最后决定下来的是拍一个悬疑类的 DV，最开始给了一个非常牛逼的时空穿越能力的设定，之后又想把剧情往女主和神秘组织斗智斗勇这个方向上引，结果最后收不了尾了。后来为了强行收尾，只能削设定；因为不能超时，所以又砍情节，斗智斗勇也变成了中二嘴炮😂。&lt;/p&gt;

&lt;p&gt;其实在整个节目的策划上还是有很大的问题的。首先是想做的东西过于庞大，以至于我们的制作团队中没有人能很好地驾驭；其次就是思路不清晰，因为（以我为主的）拖延导致大家赶不太上 DDL，所以只能一边构思一边拍摄，这也就导致有很多片段需要重拍，也有很多片段最后没用上；最后就是在一些细枝末节的地方过于纠结。我们一开始甚至花了一些时间思考人物性格，以及这样的角色会如何说话，但从最后的成品来看，16分钟的故事其实是体现不出性格的，对话更多地都是在讲述剧情而不是塑造人物。&lt;/p&gt;

&lt;p&gt;总之确定了大致思路、写了头几幕的剧本、找到了对应演员之后就开始拍了。不知为何拍摄也变成了我，最后也就变成我在导演了。我还记得第一次拍摄是男生节当天上午。那天是个周四，所以是刚通宵写完了软工，吃了早饭，看了会剧本，稍微睡了一会儿，就去拍摄了。当时只借到了相机，没借到三脚架，所以晃得不行；而且是在寝室内拍的片段，光线昏暗，最后根本没法用。等到二审展示完片段后，就被责令整改。&lt;/p&gt;

&lt;p&gt;之后借到了三脚架，在室内拍摄的时候会在床上架充电台灯补光。前半段剧情都是女主在寝室里，这里又有大概一半的时间有女主的室友出现，所以拍摄得找女主和大牌女二都有空的时间，基本上一周就只能拍一两次。拍完差不多就赶上了下一次审查，所以又得熬夜剪辑。第一次剪出来的东西基本上没法看，全都是意义不明而冗长的无对话片段。文艺部的各位前辈给了很低的评价，而同时展示的二班的 DV 剧已经有了相当高的完成度。虽然后面副主席向我们保证说不会砍四字班的节目，但总还是放不下心。&lt;/p&gt;

&lt;p&gt;当时的心情不好描述，总之比较低落。有时候我也会想，自己在这件事上投入这么多时间，也耽误大家这么多时间，到底有什么必要，到底值得吗？做一个学生节的节目到底图什么？能给自己和周围的人带来什么？我为什么不拿这个时间去写些作业，甚至去玩会游戏？当时差不多也是期中，然后又是软工差不多结项的日子，所以曾一度想要甩手不干，想要放弃。&lt;/p&gt;

&lt;p&gt;后面也想通了。因为这件事很有趣。就是这样。难得有机会让我名正言顺地任性一次，和大家合作完成一部片子，在紧张的学期生活中腾出这么一大块时间，为了自己的满足感而奋斗。另一方面想，这学期如果不把握住的话，这样的机会还能有几次呢？大三大家不会有时间的吧，大四太不好预料了。每当想要放弃的时候，这么想一想，咬咬牙，又坚持下去了。&lt;/p&gt;

&lt;p&gt;最后也还是一直坚持了下去。拍完了室内场景之后我们拍了外景的一段动作戏（女主跑来跑去），然后又偷偷溜进刚修好的李兆基楼拍 boss 战（嘴炮）的部分，最后又拍了车祸现场，并补拍了之前的室内片段。真的得好好感谢各位演员，愿意听我这个不专业的导演的各种乱七八糟的要求，愿意在这件事情上花这么多时间。拍完之后就开始了紧张且日渐乏味的后期制作。这里还得感谢韦师，帮我分担了后半段的剪辑。虽然剪得很累，但中途剪预告片和做特效（尤其是车祸那段）还是很开心的。&lt;/p&gt;

&lt;p&gt;这里还有一段轶事。DV 终审的时候我差点没赶上 DDL，在预定时间前半个小时不到才剪完开始渲染。眼看渲染要来不及了，我只好抱起电脑出门，一边骑车一边抱着电脑，还不能合上盖子，怕合上之后就暂停渲染了，就这么骑到了东主楼，正好渲染完。这大概是这学期最逗的一次赶 DDL 了。&lt;/p&gt;

&lt;p&gt;另外得吐槽一下名字。我们这个剧名字叫《W》，之所以叫这个不明觉厉的名字，其实是因为这部剧一直没有名字。到了最后文艺部催预告片要做宣传了，不得不起名字了，才开始想。而我其实是先想到预告片一堆单词的创意之后，才想到可以用单个字母当标题的（之前还想过用《T》，但感觉可能没那么好），最后也是我拍脑袋决定了就用《W》。这个取名方法叫做面向预告片的命名。&lt;/p&gt;

&lt;p&gt;等到最后把最终版的成片渲染出来，已经是学生节当天的凌晨3点了，差点没被视频口的徐子南打死。&lt;/p&gt;

&lt;p&gt;现场放映的时候其实是比较紧张的。当时我是上台口道具负责，也就没去观众席那边看，呆在上台口听声音，顺便在微信群里和剧组吐槽。虽然只能听到声音，但剪辑的时候也看了太多遍，基本上能直接想起画面。其实完整版的视频剧组里也没几个人看过，大家纷纷表示看到自己的时候感觉非常羞耻，而且后面车祸过于惊悚。这让我感觉非常开心。最后也获得了不少好评，总的来说，还是觉得值得的。&lt;/p&gt;

&lt;p&gt;顺便在此放一下视频链接（&lt;a href=&quot;http://v.qq.com/boke/page/c/o/n/c0176zn74on.html&quot;&gt;预告片&lt;/a&gt;；&lt;a href=&quot;http://v.qq.com/boke/page/g/r/g/g0177wul1rg.html&quot;&gt;正片&lt;/a&gt;）。正片本来说好系公众号要推的，结果也没推，就只能在这里首发了😂。&lt;/p&gt;

&lt;p&gt;另外，本来说想趁着寒假剪一个花絮，结果也因为太懒放弃了_(:з」∠)_&lt;/p&gt;

&lt;h3 id=&quot;一二九合唱&quot;&gt;一二·九合唱&lt;/h3&gt;

&lt;p&gt;一二九的合唱排练贯穿了半个学期。似乎是从第五周开始，到第十二周结束，每周的周五傍晚和周日下午都会花两个小时进行合唱的排练，偶尔会因为老师来不了而暂停。似乎有不少同学比较反感这个活动，毕竟会花时间，而且是强制参加的。但我个人觉得还是挺有意思的，本来也喜欢唱歌，排练老师也比较风趣。&lt;/p&gt;

&lt;p&gt;我们系唱的是《共青团员之歌》的俄文版，一共四个声部，我被分到了二声部，大概就是女低音（考虑到我系男女比例，女生全都唱的一声部女高音）。排练的时候一般和韦师坐一块，经常被他的声乐水平震撼到。倒数第几次排练的时候一组一组地考察，还因为唱的比较好而且其他二声部的小组全都走了，而被留下来一遍一遍地配合唱。演出时女生穿着蓝色的长裙，男生穿着标准服务生打扮，被强迫化上了谜之妆容，留下了一辈子的黑历史。最后演出的时候我站在最后一排的最左边，从观众席上看就是右上角。音乐响起后，脑袋里就什么都没想了，只剩下歌词和旋律，我也用了从来没使出过的劲，唱出了自己最洪亮的声音。&lt;/p&gt;

&lt;p&gt;虽然最后我们系只拿到了综合二等奖，与投入有点不成正比。但对我来说，这个过程已经充分享受了。&lt;/p&gt;

&lt;h3 id=&quot;中厅讲座&quot;&gt;中厅讲座&lt;/h3&gt;

&lt;p&gt;因为去年三字班举办过这样的活动，因此这学期我们也学着办了。主要是针对 PA 各题的讲座，其实和大一上的程设模拟考差不多，只不过去掉了考试，然后把地点挪到了410中厅。&lt;/p&gt;

&lt;p&gt;整个学期应该举办过三四轮讲座吧，但我参加的只有两轮。就和到外面讲课差不多，只不过在这边讲课遇到自己想不出来的东西时没法糊弄过去= =。&lt;/p&gt;

&lt;p&gt;不过从班委的角度来看，这个活动在组织上还不够优秀。有些场次的讲座人数爆满，而有些场次根本没人来听，感觉有点尴尬。下学期不知道还有没有讲座的需求呢。&lt;/p&gt;

&lt;h2 id=&quot;社工&quot;&gt;社工&lt;/h2&gt;

&lt;p&gt;社工是这学期的主要部分。因为我们系大二才允许加入社工组织，从来没做过社工的我出于好奇加了各式各样的组织，也算是过的丰富多彩了吧。这学期我当了我们班的班长、加了学生会文艺部、团委实践口，和科协竞赛部。听上去还挺多的。&lt;/p&gt;

&lt;h3 id=&quot;班级相关&quot;&gt;班级相关&lt;/h3&gt;

&lt;p&gt;大一的时候也尝试竞选了班干部，但最后没有当上。这学期换届前我就在想，要不要去竞选一下？其实是有点犹豫的，因为从来没当过班干部，不知道自己有没有这个能力。后来乔导也来找我，建议我参选，我也就去竞选了班长，结果就当上了。当时的感想是，第一次听自己的名字被念这么多遍。&lt;/p&gt;

&lt;p&gt;虽然当上了，但还是很虚的，因为完全没有经验。所以我去找了前班长党员同志提升知识水平，拿到了一些往届的资料。幸好支书王晨阳和组委邵哥去年也是班委，能力也很强，在开会和举办活动的时候经常能 carry。&lt;/p&gt;

&lt;p&gt;但其实班长要做的事情也不算太多，每周开几个会，偶尔串串寝，然后一个学期举办一次素拓和团日。这里很多工作是和班委的大家一起做的，而书面材料大多数则是辛苦支书。这个学期班内举办的活动主要就是三个：素测、素拓和团日。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;素测&lt;/strong&gt;是最先举办的，也是最轻松的一个。往年校级需要打分的素测活动已经取消了，只是辅导员希望我们能办一个班内的素拓，大家相互交流一下过去一个学期干的事情，每个人上台讲5分钟而已。其实也并没有太多需要我们准备的事情。我个人觉得这种形式还是不错的，也是难得的可以聚在一起的机会。这一次是整个学期聚得最齐的一次（除了期末考试之后的年级会）。&lt;/p&gt;

&lt;p&gt;然后就是&lt;strong&gt;团日&lt;/strong&gt;。为了配合一二九的大主题，我们的团日也被要求和一二九有关。最后我们选择了大富翁形式的知识竞赛，先是介绍一二九的背景知识，然后分组掷骰子在地图上前进，然后答题。中途还可能遇到各种各样的事件和道具。整个活动气氛比较轻松愉快，大家都比较开心，我个人认为算是本学期最成功的一次活动。&lt;/p&gt;

&lt;p&gt;顺便贴一下团日上用的&lt;a href=&quot;https://github.com/huzecong/contest-129&quot;&gt;网页版答题大富翁的代码&lt;/a&gt;。如果大家看了之前软工那篇日志的话，可以发现是直接用当时的项目改的😂。这个网页也是团日头一天上午开始写，写了一天一夜，在团日前一个小时写完的，代码完全不可维护。现场的时候中途出了一点 bug（挺严重的），导致游戏没法继续进行，只能刷新重来，比较尴尬，还现场调了几个 bug。现在贴上去的版本应该是没有大问题的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;素拓&lt;/strong&gt;因为要避开一二九排练，所以拖到了第十三周才举行。我们选择的是去七九八艺术区进行定向越野，要求找到指定的地标并作出指定姿势拍照。素拓其实主要是其他班委在忙，因为当时我还在为学生节焦头烂额。最后活动还是可以的，去的人数也不少，虽然天冷但还是挺有意思的。&lt;/p&gt;

&lt;p&gt;其他的就是一些日常琐事了，不说也罢。这一个学期的确锻炼了我，但各方面也还有待提高。希望下个学期能把工作做好吧。&lt;/p&gt;

&lt;h3 id=&quot;团委实践口&quot;&gt;团委实践口&lt;/h3&gt;

&lt;p&gt;之前听人安利说团委是锻炼人的地方，外加有学长钦定我，所以我就报了团委。但最后好像也没到那位学长钦定的部门去。谜=。=&lt;/p&gt;

&lt;p&gt;实践口主要负责系内的实践活动，因为活动主要集中在暑假（暑期实践），所以学期中其实很闲。感觉干的事情只有刚开学暑期实践评选和风采展示的事情。主要也就是通知各位支队长，然后风采展示做了八份书签。这么一看，这学期干的都是美工呢😂。&lt;/p&gt;

&lt;p&gt;因为很闲所以也没法怎么评价。事情也没多大压力，所以还算有趣吧。&lt;/p&gt;

&lt;h3 id=&quot;科协竞赛部&quot;&gt;科协竞赛部&lt;/h3&gt;

&lt;p&gt;这个是被副主席P神强行安利的。在这里干的事情主要是写科普文，以及做宣传出推送。出推送没太大难度，只是我文笔也不好，只能靠标题党吸引人。科普文的话，自认为写的还不错，虽然目前也就写了一篇（再次无耻安利：&lt;a href=&quot;/2015/09/19/what-you-dont-know-about-templates&quot;&gt;《你所不知道的 Template》&lt;/a&gt;；原文发表在 Contest9 上，现在网站整个挂了），也是熬夜肝出来的，唉。&lt;/p&gt;

&lt;p&gt;别的事情也没什么了，也就偶尔开一开部会吧。记得有一次开完会之后和P神和钟皓曦一起吃小桥（还没带钱……），然后一边散步一边谈人生到差不多一点才会寝室。还是挺好玩的。&lt;/p&gt;

&lt;h3 id=&quot;学生会文艺部&quot;&gt;学生会文艺部&lt;/h3&gt;

&lt;p&gt;文艺部算是本学期社工的重头戏了，所以放在最后面。大一搞学生节的时候虽然说再也不搞班级节目（唉），但也对文艺部的工作产生了兴趣。抱着这样的兴趣，我加入了文艺部。&lt;/p&gt;

&lt;p&gt;这个部是今年系内各组织各部门中最庞大的一个，包括副主席和部长一共23人。刚进的时候基本上认识不到几个人，一起奋斗过学生节之后，到现在全都比较熟了。&lt;/p&gt;

&lt;p&gt;就我能回忆起来的，本学期文艺部的主要活动就是新生舞会和学生节了。下面分别写一写。&lt;/p&gt;

&lt;h4 id=&quot;新生舞会&quot;&gt;新生舞会&lt;/h4&gt;

&lt;p&gt;今年的新生舞会是四系合办的，和人文、水利和社科一起。我们系出了出钱外，还负责宣传工作。自从剪完实践纪录片后就发誓不再剪片（唉），可最后还是被分到了宣传视频组，毕竟推送我也写不好。&lt;/p&gt;

&lt;p&gt;视频组由玉涵领导，有我们这边的六人，以及人文的一名部长（也是大二的）。最后我们视频的剧情和分镜是由人文的同学提供的，拍摄主要在十一期间，但当时我要去外面讲课，所以没有跟着去拍摄。我负责后期（就是剪片，唉），同样负责后期的还有晖榕。等我开始剪的时候素材已经筛完整理好，时间线也标出来了，而且素材的质量较之于之前剪的片子要高太多了，在剪的时候感觉相当顺心。虽然现在回头来看，这个视频还是挺粗糙、挺不明觉厉的，但据说现场效果还可以，也就可以啦。&lt;/p&gt;

&lt;p&gt;说到现场，其实挺遗憾的，因为当时是周五晚上，我有会原的课所以没去现场帮忙。现在回想起来超级后悔。&lt;/p&gt;

&lt;p&gt;最后一次贴链接：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NzAyMzMxMA==&amp;amp;mid=218352022&amp;amp;idx=1&amp;amp;sn=ad1d8b8cf957a6686c4a22d4b1aa0f67&quot;&gt;视频宣传推送&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&quot;学生节-1&quot;&gt;学生节&lt;/h4&gt;

&lt;p&gt;这个就是重头戏了。不过说实话，前期准备我基本上没参与。因为我负责了班上的节目，大家都还比较照顾我，也没给我分多少锅。我领到的锅只有汇报自己班上节目的进度而已，沉重的宣传任务完全没有分给我。除此之外，也就是在节目审查的时候去现场围观一下罢了。而学生节现场的话，我和颖超一起负责道具，我负责上台口，他负责下台口。台口舞监也是颖超做的。&lt;/p&gt;

&lt;p&gt;虽然分掉了这么多锅。第十四周还是完全被学生节占据了。每天晚上都有例会对舞监表（顺便吃一大堆零食，然后听隔壁房间主持人一遍一遍报幕），还得剪班级节目，毕竟周日是死的 DDL。而周日一整天则是彩排，大部分时候我还是比较闲的，只有换到下一个节目彩排的时候需要上去确认道具需求，然后打舞台胶。不过也还是站了一天，到学生节正式开始前脚就已经酸了。&lt;/p&gt;

&lt;p&gt;这届学生节的道具压力比较小，而且舞监指挥也站在上台口，所以其实没有多少出错的空间。即便如此，每到要搬道具的时候内心还是会紧张起来。晚会的最后，主持人在台上念出“祝大家晚安”，“晚安”这两个字我是在台下跟着一起吼出来的。当时激动的心情没法用我贫瘠匮乏的文字描述。那天晚上的聚餐多半也是酒量特别小的我喝得最多的一次。&lt;/p&gt;

&lt;p&gt;大概就如乔导那天晚上所说：“你们之前付出了这么多，花了这么多时间。但是，我就问你们一句，你们觉得，值吗？”我的回答，自然是值的。即便只是为了结束那一刻激动的心情，亦或是能收获的那份成就和满足感，我觉得也是值的。毕竟这和班级节目一样，是属于我们自己的狂欢，是难得的任性的机会。&lt;/p&gt;

&lt;p&gt;这么一说，大三都有点想要继续干了呢。&lt;/p&gt;

&lt;h2 id=&quot;学习&quot;&gt;学习&lt;/h2&gt;

&lt;p&gt;这学期的成绩用一个字来形容，就是惨。&lt;/p&gt;

&lt;p&gt;可能也是因为上学期成绩太好了吧，有些过于自信了。还真以为考前突击一天就能上平均分。&lt;/p&gt;

&lt;p&gt;综合起来 GPA 大概85分，这还是有三学分的软工加成之后的分数。总 GPA 被往下拉了快3分。不过，考虑到这个学期的实际投入，拿到这个成绩也没太多话说。&lt;/p&gt;

&lt;p&gt;这个学期的学习态度也的确很不认真。学期开始的时候说前两周不翘课，结果第一周就开始翘了。这倒不是很大的问题，但由于部分课程考核中不含作业分，因此作业也没有写了，这就直接导致了期末的悲惨生活。这也怪不了老师，还是自己作死。&lt;/p&gt;

&lt;p&gt;上学期的总结里就说了期末有多惨，然而这个学期比上学期还要惨。学生节十四周周日结束，本来打算十五周就开始复习，结果因为种种原因拖到十六周周二才开始。而且这个学期的考试又开始的特别早，还是隔一天考一门。因此结果就是，每门考试前都在通宵复习，也就是隔一天通宵一次。在考完大物之后我好好睡了一觉，从晚上7点睡到第二天早上9点，才算恢复了一些。&lt;/p&gt;

&lt;p&gt;但其实说白了，也都是自己作死。上半学期明明没多少事，却浪费了大把的时间。当时还莫名入了炉石的坑，玩了大概一个月，后面弃坑了，主要是因为水平差而且太耗时间。下半学期虽然事情多，但也不是真的没空到作业都没法写。様を見ろ。&lt;/p&gt;

&lt;p&gt;这种学习方法是纯粹为了应付考试的学习方法，其实什么都学不到。前两个学期学的东西虽然也有很多忘了，但硬要回忆也还能记起来。这学期学的东西已经完全忘光了，比如复变我只记得复数运算了。&lt;/p&gt;

&lt;p&gt;不过话说回来，这学期的课程在无聊程度、无用程度，和考核方式的猎奇程度上都创了新高。虽然这不是学不好的借口，但还是会让人怀疑自己，在这些课程上投入精力到底有什么用。&lt;/p&gt;

&lt;h4 id=&quot;复变函数导论&quot;&gt;复变函数导论&lt;/h4&gt;

&lt;p&gt;2学分。91分。看着很高的分数，但其实还没到中位数。&lt;/p&gt;

&lt;p&gt;本学期唯一的一门数学课。&lt;/p&gt;

&lt;p&gt;其实复变和微积分线代一样，应该属于很重要的学科基础。但这门课程的设置让我怎么也感觉不到它的重要性。&lt;/p&gt;

&lt;p&gt;首先是考试分数占总评的100%。明明有作业却不算分，所以我这种偷懒的人只写了前3章的作业就再没写过了。这其实没什么，毕竟如果学生自觉的话还是没有影响的。但是考试全部考原题这点没法理解了。即便是只做了几套往年题的我都能看出卷子上70%的题是陈题，而据看了许多资料的室友说其实所有题都是陈题。这考的是什么？书法吗？&lt;/p&gt;

&lt;p&gt;说真的，题目其实不简单，如果不是陈题的话，估计平均分上不了70分。但如果是怕挂科率太高，与其出陈题，为什么不改变考核方式？更可怕的是老师根本不以此为耻。&lt;/p&gt;

&lt;p&gt;不过我也没什么好愤愤不平的。毕竟和这位老师只有一面之缘，考试周也只复习了一天半。&lt;/p&gt;

&lt;h4 id=&quot;数据结构&quot;&gt;数据结构&lt;/h4&gt;

&lt;p&gt;4学分。91分。看不到排名，所以不知道到底是怎样的水平。&lt;/p&gt;

&lt;p&gt;这课其实还是不错的。虽然没怎么上过课，但是邓公讲的还是不错的，而且课件非常良心。&lt;/p&gt;

&lt;p&gt;但这门课的教学目标到底是什么，这个问题我一直没有想通。笔试部分和上机部分完全是两个极端：前者是纯粹的理论分析，后者则是竞赛那套理论。笔试的考题比较偏而且难，虽然不乏好题，但也有很多无论是理论还是实践中都想不出有何意义的题目。而要写代码的 PA 则是由之前几届所谓“因材施教A类”（也就是小教员）出的题目，说白了就是竞赛题。这种东西除了提高代码能力和调试能力外，就真的是毫无意义了。我搞了这么多年竞赛也没想出线段树这种结构在实践中到底有什么用，结果 PA 的15道题中就有3道线段树，其中还有一道可持久化的。与其出这种题，真的还不如直接要求实现课件里的若干种数据结构。&lt;/p&gt;

&lt;p&gt;说到这个因材施教，我一开始其实是不想报名的，毕竟当年给徐明星当小教员就没落下什么好下场。不过徐 boss 好歹是总评给满分（听说今年不是了），但邓公只是 PA 给满分。听上去还不错是吧，毕竟 PA 占总评的45%，但我们还得给别人讲题啊，这些题目自己不写一写怎么给别人讲啊。最坑的是：小教员不·调·分。受到这样的待遇，真的也不能怪我们出竞赛题了。&lt;/p&gt;

&lt;h4 id=&quot;软件工程&quot;&gt;软件工程&lt;/h4&gt;

&lt;p&gt;详见&lt;a href=&quot;/2016/02/04/se-project-dev-log/&quot;&gt;上一篇日志&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&quot;电子学基础&quot;&gt;电子学基础&lt;/h4&gt;

&lt;p&gt;3学分。85分。似乎高于中位数。&lt;/p&gt;

&lt;p&gt;谜。&lt;/p&gt;

&lt;p&gt;太谜了。&lt;/p&gt;

&lt;p&gt;为什么会有这样课。&lt;/p&gt;

&lt;p&gt;为什么要找这样的老师来上课。&lt;/p&gt;

&lt;p&gt;我知道电原是电路的基础，我知道模电无法完全被数电取代，虽然我不知道学这些有什么用，但我也不是不愿意学。&lt;/p&gt;

&lt;p&gt;可好歹挑个像样的老师吧？电子系这么多人，非得挑个张雷？&lt;/p&gt;

&lt;p&gt;这人什么水平？答疑时经常找不到人；被助教私底下嘲笑；能把 lemma 翻译成拉曼准则。最后这个真是能笑一学期。&lt;/p&gt;

&lt;p&gt;牢骚发完了。以我对待这门课的态度，可能也没有太多资格发这通牢骚。&lt;/p&gt;

&lt;p&gt;这门课期中之前教电原，期中之后教模电。其实无论是哪部分都是完全可以拆成一门单独的3学分的课来上的，但这课非要揉到一起当成一节课上，结果就是知识密度高，讲的很不详细。不是大家想自学，是上课基本上是张雷在自娱自乐（听学长说的），作业里还有很多和课件上不一样的东西。&lt;/p&gt;

&lt;p&gt;期中之前虽然作业都是赶着 DDL 做的，但也好歹算做了。期中复习也花了不少功夫，但最后还是没有上平均分。期中之后的模电则是从一开始就处于弃疗的状态，作业能抄则抄，懒得抄干脆不交。到了考试周才开始学，大概花了整整五天才学明白，结果期末考试又简单无比。顺带一提，这门课考试可以带一张 A4 纸的资料，期末之所以能考出这样的成绩，其实很大程度上是考了复印的室友复印的室友复印的他们班同学的 A4 纸。&lt;/p&gt;

&lt;p&gt;其实最坑爹的在于，之前说好可以缺交3次作业，到了期末变成了只能缺交1次。于是就被多扣了4分总评。&lt;/p&gt;

&lt;h4 id=&quot;电子学基础实验&quot;&gt;电子学基础实验&lt;/h4&gt;

&lt;p&gt;1学分。84分。分不高，但也无所谓了。&lt;/p&gt;

&lt;p&gt;这学期有两门实验课，其实我都没什么兴趣。毕竟只是玩一玩那些没见过的仪器，其实对实验原理完全不了解。所以实验课也就是混一混，实验数据自己整理，结论抄一抄，随便凑一篇报告交上去，拿一个随便的分数。&lt;/p&gt;

&lt;p&gt;幸好电子学实验是组队，因此整学期都在抱徐子南大腿，基本上做实验就是他连线接板子，我画画表格抄抄数据。最后的综合大实验挺坑的，花了我不少考试周的时间，非常不爽。&lt;/p&gt;

&lt;h4 id=&quot;大学物理b2&quot;&gt;大学物理B(2)&lt;/h4&gt;

&lt;p&gt;4学分。70分。血崩。&lt;/p&gt;

&lt;p&gt;先引用一下上学期总结里的话：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;大物我选的是魏斌的，因为之前听说李列明讲的很差（虽然水），我就没选。等后来领悟到计算机系学大物的真谛之后想改李列明已经晚了。&lt;/p&gt;

  &lt;p&gt;……&lt;/p&gt;

  &lt;p&gt;于是选了李列明准备体验一下。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;于是这学期血崩。&lt;/p&gt;

&lt;p&gt;李列明讲的到底多差，我也不知道，因为只听过半节课。但李列明也是个不算书面作业分的，助教网上的选择填空题虽然算分，但不管正确与否，填了就有分，所以我也没做。即便如此，我还经常忘记填，最后也被扣了分。&lt;/p&gt;

&lt;p&gt;期中之前学的是电磁学，期中之后学的是光学和量子力学。期中复习了一天半，期末复习了一天。就凭这点努力，拿到这个成绩实属意料之中，也不能怎么怪李列明。可能我也不太适应这种只看答案的物理考试吧，期中的时候没有领悟到量纲法蒙答案，期末有那么几道题能写出大概一半的过程，但推不出答案。&lt;/p&gt;

&lt;p&gt;至于期中考太难所以期中分数改成只占总评20%这种事情，虽然挺逗的，但考了32分的我也没吃亏，所以也无所谓了。&lt;/p&gt;

&lt;p&gt;不过倒也有令人开心的事情：再也不用学物理了！哈哈哈！！&lt;/p&gt;

&lt;p&gt;最后，给各位选了李列明的学弟送一个助教网的一键填涂插件（虽然还是建议大家认真做作业）：&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;querySelector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[name=rightFrame]&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;contentDocument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;querySelectorAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;input[type=radio][value=E]&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;checked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;querySelectorAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;td[colspan='8']&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;querySelectorAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;input[type=text]&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;物理实验b1&quot;&gt;物理实验B（1）&lt;/h4&gt;

&lt;p&gt;1学分。76分。差不多能排进全校倒数15%的成绩。&lt;/p&gt;

&lt;p&gt;但这门课拿多少分我都无所谓。本来就是最没用的课程之一。&lt;/p&gt;

&lt;p&gt;完全不懂实验原理，做实验全靠老师讲解和依葫芦画瓢。实验报告全靠抄，数据处理基本靠别人的 Excel 表格，到后面懒得写都直接打印了。理论考试啥都不会，计算题还算错，拿了45分。能有76分已经可以了。&lt;/p&gt;

&lt;p&gt;但这么傻逼的课居然还有“（2）”。干脆下学期连数据一起抄算了。&lt;/p&gt;

&lt;h4 id=&quot;马克思主义基本原理&quot;&gt;马克思主义基本原理&lt;/h4&gt;

&lt;p&gt;4学分。83分。&lt;/p&gt;

&lt;p&gt;选的韦奶奶的课。不知道这门课讲了什么。前八周线下加全周 MOOC，MOOC 反正是没听。线下课没有点名，只靠下课前交一份命题作文当做签到。所以我只听了第一周，之后每周都在旁边教室自习，下课前把作文写了，趁着下课的混乱混进去交作文。作文也是乱写的，拿到这个分数也没什么可抱怨的。&lt;/p&gt;

&lt;p&gt;不过韦奶奶也真是良心，全班最低分都有80。&lt;/p&gt;

&lt;h4 id=&quot;学术英语专项技能批判性思维&quot;&gt;学术英语专项技能——批判性思维&lt;/h4&gt;

&lt;p&gt;2学分。88分。&lt;/p&gt;

&lt;p&gt;似乎学校开始限制90分以上的数量了，这个分数也不算低了。&lt;/p&gt;

&lt;p&gt;这门课上主要是讲一些谜之哲学问题，比如“你知道的真的是你知道的吗”、“你怎么证明你看到的东西真的存在”之类不明觉厉的东西，我听得也不是非常认真，课堂论文和期末论文也是比较应付地写了。这节课是 Nathan Francois 在清华的最后一节课，下学期他好像就要回国了。&lt;/p&gt;

&lt;h4 id=&quot;软件理论基础2函数式语言程序设计&quot;&gt;软件理论基础(2):函数式语言程序设计&lt;/h4&gt;

&lt;p&gt;2学分。86分。&lt;/p&gt;

&lt;p&gt;这门课其实是软院的限选课，属于计算机系培养方案之外。但我（自认为）对函数式编程还有兴趣，于是就去抱老师大腿强行扩容了一个名额。&lt;/p&gt;

&lt;p&gt;但这门课其实不怎么样。讲的内容基本上停留在 Haskell 语法的层面，基本上是完全没有涉及函数式的理论部分。我对这门课的态度也很迷，明明认识的人里就我一个在上，却也不去听课，作业也偶尔迟交。最重要的是：不听任选课，我选了干嘛啊。最后也没学到什么东西，只能说是对语法稍微熟悉一点了。&lt;/p&gt;

&lt;p&gt;而说实话，我现在对于函数式的理解，也大概就停留在 Haskell 中语法糖的层面。函数式也是个大坑……还是先放一放吧。&lt;/p&gt;

&lt;h4 id=&quot;宗教学基础知识-w&quot;&gt;宗教学基础知识 [W]&lt;/h4&gt;

&lt;p&gt;3学分。补退选刷上的课。在课上还碰到了王可预。&lt;/p&gt;

&lt;p&gt;但最后这门课也没有坚持上下来，主要是这学期课程太多，这门课考核要求又太多，加之发现自己也没有想象中那么感兴趣。&lt;/p&gt;

&lt;h4 id=&quot;交响音乐赏析-w&quot;&gt;交响音乐赏析 [W]&lt;/h4&gt;

&lt;p&gt;1学分。补退选刷上的课。只上了一节就退了。主要是因为不想上一门只有我一个人上的文素。老师讲课也感觉比较谜。&lt;/p&gt;

&lt;h2 id=&quot;双学位&quot;&gt;双学位&lt;/h2&gt;

&lt;p&gt;对待双学位的态度其实是比较弃疗的，属于混文凭的态度，而且这个双学位的考核要求也很水。&lt;/p&gt;

&lt;h4 id=&quot;经济学原理&quot;&gt;经济学原理&lt;/h4&gt;

&lt;p&gt;3学分。89分。&lt;/p&gt;

&lt;p&gt;这大概是唯一一门认真学了的课。主要是觉得经济学比较有趣，外加曼昆那本书虽然啰嗦但保证能看懂。虽然也没怎么去上课，作业也都是 DDL 前熬夜写的。&lt;/p&gt;

&lt;h4 id=&quot;会计学原理&quot;&gt;会计学原理&lt;/h4&gt;

&lt;p&gt;3学分。80分。&lt;/p&gt;

&lt;p&gt;有两位老师都开了这门课，我们系除了我都选的杜胜利，但我选的郝振平，我也不记得为什么。郝振平用的是他自己的教材，那本教材给人的感觉就是百度百科式的知识点罗列，根本没法看。而他的上课风格也就是声音单调低沉的 PPT 慢速朗读，PPT 也就是教材上的内容。&lt;/p&gt;

&lt;p&gt;不过郝振平的考核很水。期中考试非常简单，而且还是开卷。开卷到什么程度呢，甚至可以看电脑里的资料。期末则是带回家做的，基本上和“大作业”没什么区别。总评中作业和签到占20%，其中签到我一次没去，作业三次只交了一次。感受一下这个得分。&lt;/p&gt;

&lt;p&gt;但说实话，还是挺后悔选了郝振平的。因为真的什么都没学到。&lt;/p&gt;

&lt;h4 id=&quot;管理学商学导论&quot;&gt;管理学（商学导论）&lt;/h4&gt;

&lt;p&gt;3学分。77分。差不多是垫底了。&lt;/p&gt;

&lt;p&gt;这门课其实是双学位，甚至可以说整个学期，的所有课程中最有意思的一门，但也是我学的最不认真的一门。这门课的授课老师朱恒源老师是个非常有趣的人，讲课也很有激情很幽默风趣。他也想把课程教好，也希望大家能认真学，但说实话，包括我在内，很多上双学位的人其实不是来学东西的。有一次他在课堂上问大家，是希望学的难一些还是水一些，大家一致回答水一些。想必老师也不太好受吧。&lt;/p&gt;

&lt;p&gt;即便是讲课这么好的一位老师，我也没有怎么认真听课，真是很惭愧。甚至最后的组队大作业都是别人帮我完成的，自己什么都没有做。拿到这个几乎垫底的分数，真的只能怪我自己。&lt;/p&gt;

&lt;p&gt;不过这门课也属于比较玄的，我也不知道要学什么，买来的书一页也没有翻过。课上似乎更加注重案例分析，而基本上没有讲理论。还是什么时候把书给看了吧。&lt;/p&gt;

&lt;h2 id=&quot;科研&quot;&gt;科研&lt;/h2&gt;

&lt;p&gt;这个学期其实什么科研都没有做，只是因为是申请季所以申报了一些东西而已。下个学期打算认真搞一搞科研，也算是尝试新的方向吧。&lt;/p&gt;

&lt;h4 id=&quot;srt&quot;&gt;SRT&lt;/h4&gt;

&lt;p&gt;和钟皓曦一起报了一个名为“面部细微特征分析算法研究”的 SRT。其实挺谜的，不知道是干什么的一个项目。参加项目的人都是其他系的，除了钟皓曦感觉都是咸鱼（包括我；其他人反正也没加他们 QQ，随便说了）。这个项目说是要用炼丹术做人脸的细微特征识别，然后基于这一算法做出一些应用，像微软之前那个猜年龄的网站之类的。&lt;/p&gt;

&lt;p&gt;但估计大家都像我一样“很忙”，完全没有在 SRT 上花时间。后面老师布置了一个有奖的参加 Kaggle 比赛的任务，只有钟皓曦一个人参加了。其他人估计和我差不多，都没学会基础炼丹术。&lt;/p&gt;

&lt;p&gt;说实话我对于自己在项目里的不作为还是感到挺不好意思的，所以寒假里还是在认真学炼丹。但老师又给我丢了一些莫名其妙的感觉和项目完全无关的锅= =唉。&lt;/p&gt;

&lt;h4 id=&quot;学术新星计划&quot;&gt;学术新星计划&lt;/h4&gt;

&lt;p&gt;这是系内的学术训练计划，让学生跟随导师去做一些事情。我被分到了做 NLP 的刘洋老师组，老师也给了我一些可以做的项目，但出于和 SRT 同样的原因，也没有干活。&lt;/p&gt;

&lt;p&gt;不过，我用其中一个项目申报了星火计划，下学期还是要认真对待。&lt;/p&gt;

&lt;h4 id=&quot;星火计划&quot;&gt;星火计划&lt;/h4&gt;

&lt;p&gt;这是校内和思源、薪火齐名的校级计划，也是培养科研人才的。其实也就是抱着试一试的态度报名的。&lt;/p&gt;

&lt;p&gt;说到这个，还得感谢乔导。星火的系内报名截止是12月20日，系内要在22号交材料。11月份的时候就说了这个事情，但因为种种琐事缠身我没有报名，系内似乎也没有人报名。12月份的时候乔导还特意来每个寝室串寝安利这个计划。我其实是想报名的，在听说有这个计划之后就去找P神聊了，因为他入选了上期的星火。但还是因为“琐事缠身”，我没有填写报名表。乔导听后特意将报名时间延到了系内交材料的22号，让我赶完了报名表。&lt;/p&gt;

&lt;p&gt;不过现在这个项目也完全没有进展。&lt;/p&gt;

&lt;h2 id=&quot;体育&quot;&gt;体育&lt;/h2&gt;

&lt;p&gt;似乎上学期总结的展望部分里提到要坚持健身，然而……&lt;/p&gt;

&lt;p&gt;这个学期只有开始小学期的时候能坚持一周去两次左右，开学之后一周都难得去一次。基本上是感觉“啊，太久没去了，不行了”才会去一次，大概也就是半个月一次的样子，真的是不定期体验肌肉酸痛。&lt;/p&gt;

&lt;p&gt;体育课的话，因为想学一点实用技能，所以报了散手，似乎就是散打。但其实还是没法实战，只是学了一些姿势而已。而且这个班都是体霸，还是挺吓人的。&lt;/p&gt;

&lt;p&gt;这个学期的 3km 测试应该是最后一次了。本来说是在第10周左右测的，但当时西操还没修好，所以推迟了。后来又开始下雪……最后到了第13周才在紫操测的。那一阵子正好是熬完一大波夜，身体比较虚的时候。身边测完的同学也纷纷表示自己比上学期退步好多，所以我最开始的目标是能及格就行。跑的时候的感觉就不描述了，京城雪融的冬日大家都懂。不得不说这个班还真是体霸，等我还剩一圈的时候就已经有人到了。最后跑了第12名，时间居然奇迹般地只有12分55秒。甚至有一名发烧的同学都在15分半内跑完了😂。&lt;/p&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;

&lt;p&gt;啰啰嗦嗦写了一大堆，自己都觉得烦了。如果真的有人能一字一句看到这里，那一定是我的真爱粉。&lt;/p&gt;

&lt;p&gt;要总结的话，这个学期还算是过的比较丰富多彩，参与了社工，做了感兴趣的项目，但放下了学习。干了很多事，但时间似乎过得比以往都要快。看上去取得了许多成就，但一开始定的目标几乎都没达到。比如，特意买了一个床头灯，想坚持早睡，睡前稍微看一会书，结果只这么做了两次。从图书馆借了好几本书，结果看都没看就到期了。&lt;/p&gt;

&lt;p&gt;如果把这个学期比作一幅画的话，那大概是一幅远看色彩五彩斑斓，近看线条杂乱无章的画吧。&lt;/p&gt;

&lt;h2 id=&quot;展望&quot;&gt;展望&lt;/h2&gt;

&lt;p&gt;一期一度的无责任插旗环节。&lt;/p&gt;

&lt;p&gt;根据这一年的经验，写在这里的东西基本上都实现不了。&lt;/p&gt;

&lt;p&gt;尽管如此，还是认真写写吧。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;下学期的重点应该会放在科研上了。好好学一学炼丹术，把两个项目给做了。星火计划的话，能走到哪步算哪步吧。&lt;/li&gt;
  &lt;li&gt;花点时间看看书，即便是小说或者 paper 也好。&lt;/li&gt;
  &lt;li&gt;尽量早点睡，可以再尝试一下睡前看书。&lt;/li&gt;
  &lt;li&gt;在健身房年卡过期前多去几次。&lt;/li&gt;
  &lt;li&gt;平时认真做作业。毕竟过了下学期之后，要手写的作业应该就不多了。&lt;/li&gt;
  &lt;li&gt;把分内的工作做好。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;就这样吧。我们下学期见。&lt;/p&gt;</content><author><name>Zecong Hu</name></author><summary type="html">如果要用一个词来形容这个学期的话，大概就是忙碌吧。 虽然还是感觉时间过得很快——仿佛小学期就在昨天——但这个学期发生的事情比大一加起来还要多。 之所以发生了这么多事，主要还是因为社工的原因。为了体验各种各样的大学生活，我在本学期加入了许多社工组织，参加了许多活动，接了许多锅。同时，因为在学习上画的时间少了，因此成绩大跳水。 简而言之就是这样了，详情的话，还请往下读。一如既往的流水账风格，这次瞎逼逼了差不多一万字。</summary></entry></feed>